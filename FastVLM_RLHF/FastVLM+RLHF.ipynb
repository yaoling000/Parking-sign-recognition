{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fastvlm + RLHF(SFT+DPO)"
      ],
      "metadata": {
        "id": "uEDECVouvIxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, json, torch, random, glob, math, types, re, unicodedata, csv, time\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as T\n",
        "from pathlib import Path\n",
        "from importlib.machinery import ModuleSpec\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from collections import Counter, defaultdict\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from llava.model.builder import load_pretrained_model\n",
        "from peft import PeftModel, LoraConfig, get_peft_model\n",
        "from collections import Counter\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "EpteDpRewh_v"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fastvlm_1.5b_stage3 Model Local Offline Loading"
      ],
      "metadata": {
        "id": "FR8BkVsMurJC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0DM8k747ARv",
        "outputId": "0b709b50-d176-49f9-8b6f-67eddf1f6b61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive is already mounted\n",
            "Model directory exists: /content/drive/MyDrive/FastVLM_RLHF/ml-fastvlm/checkpoints/llava-fastvithd_1.5b_stage3\n",
            "BEFORE vision_tower: None\n",
            "AFTER vision_tower: None\n",
            "Local package already exists, no need to reinstall.\n",
            "Unpacking complete: model=LlavaQwen2ForCausalLM, tokenizer=Qwen2Tokenizer, image_processor=int, extra=0\n",
            "Model successfully loaded, device: cuda:0\n",
            "dtype = torch.float16\n",
            "FastVLM is now ready for subsequent RLHF or evaluation tasks (no inference test required).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print(\"Google Drive is already mounted\")\n",
        "\n",
        "# Path configuration\n",
        "PROJECT = \"/content/drive/MyDrive/FastVLM_RLHF\"\n",
        "ML_FASTVLM = os.path.join(PROJECT, \"ml-fastvlm\")\n",
        "CKPT_DIR = os.path.join(ML_FASTVLM, \"checkpoints\", \"llava-fastvithd_1.5b_stage3\")\n",
        "\n",
        "assert os.path.exists(CKPT_DIR), f\"Model path not found: {CKPT_DIR}\"\n",
        "print(\"Model directory exists:\", CKPT_DIR)\n",
        "\n",
        "# Enforce offline mode — disable Hugging Face access\n",
        "os.environ[\"HF_HUB_OFFLINE\"] = \"1\"\n",
        "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# Check vision_tower configuration\n",
        "CFG = os.path.join(CKPT_DIR, \"config.json\")\n",
        "with open(CFG) as f:\n",
        "    cfg = json.load(f)\n",
        "\n",
        "print(\"BEFORE vision_tower:\", cfg.get(\"vision_tower\"))\n",
        "if cfg.get(\"vision_tower\") is None:\n",
        "    pass\n",
        "print(\"AFTER vision_tower:\", cfg.get(\"vision_tower\"))\n",
        "\n",
        "# Load the local ml-fastvlm package\n",
        "if ML_FASTVLM not in sys.path:\n",
        "    sys.path.append(ML_FASTVLM)\n",
        "\n",
        "# Install dependencies only on first run to avoid redundant installs\n",
        "if not os.path.exists(os.path.join(ML_FASTVLM, \"llava.egg-info\")):\n",
        "    print(\"First run: installing local ml-fastvlm package...\")\n",
        "    !cd {ML_FASTVLM} && pip install -e . -q\n",
        "else:\n",
        "    print(\"Local package already exists, no need to reinstall.\")\n",
        "\n",
        "# Load the model (fp16 to avoid triggering bitsandbytes)\n",
        "from llava.model.builder import load_pretrained_model\n",
        "import torch\n",
        "\n",
        "ret = load_pretrained_model(\n",
        "    model_path=CKPT_DIR,\n",
        "    model_base=None,\n",
        "    model_name=\"FastVLM-1.5B\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "# Adaptive unpacking logic\n",
        "def pick_roles(items):\n",
        "    mdl = tok = proc = None\n",
        "    extra = []\n",
        "    for x in items:\n",
        "        if hasattr(x, \"generate\") and mdl is None:\n",
        "            mdl = x\n",
        "        elif hasattr(x, \"encode\") and tok is None:\n",
        "            tok = x\n",
        "        elif proc is None:\n",
        "            proc = x\n",
        "        else:\n",
        "            extra.append(x)\n",
        "    return mdl, tok, proc, extra\n",
        "\n",
        "if not isinstance(ret, tuple):\n",
        "    raise RuntimeError(f\"Unexpected return from load_pretrained_model: {type(ret)}\")\n",
        "\n",
        "model, tokenizer, image_processor, extra = pick_roles(ret)\n",
        "\n",
        "print(f\"Unpacking complete: model={type(model).__name__}, tokenizer={type(tokenizer).__name__}, \"\n",
        "      f\"image_processor={type(image_processor).__name__ if image_processor else None}, extra={len(extra)}\")\n",
        "print(\"Model successfully loaded, device:\", model.device)\n",
        "\n",
        "# Quantization safeguard — ensure the model is not in 4/8-bit mode\n",
        "if getattr(model, \"is_loaded_in_4bit\", False) or getattr(model, \"is_loaded_in_8bit\", False):\n",
        "    raise RuntimeError(\"Detected a 4-bit or 8-bit quantized model. Please use an fp16 base model before applying LoRA-SFT.\")\n",
        "print(\"dtype =\", getattr(model, \"dtype\", \"unknown\"))\n",
        "\n",
        "print(\"FastVLM is now ready for subsequent RLHF or evaluation tasks (no inference test required).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construction of the FastVLM/LLaVA SFT Dataset"
      ],
      "metadata": {
        "id": "26YQ8ZxkwUVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT = \"/content/drive/MyDrive/FastVLM_RLHF\"\n",
        "IMG_DIR = f\"{PROJECT}/images\"\n",
        "GT_DIR  = f\"{PROJECT}/gt_json\"\n",
        "OUT_DIR = f\"{PROJECT}/sft_data\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "TRAIN_JSON = f\"{OUT_DIR}/train.json\"\n",
        "VAL_JSON   = f\"{OUT_DIR}/val.json\"\n",
        "\n",
        "# Supported image extensions\n",
        "IMG_EXTS = [\".JPG\", \".jpeg\", \".png\", \".webp\", \".bmp\"]\n",
        "\n",
        "def find_image_for(basename: str):\n",
        "    for ext in IMG_EXTS:\n",
        "        p = Path(IMG_DIR) / f\"{basename}{ext}\"\n",
        "        if p.exists():\n",
        "            return str(p)\n",
        "    return None\n",
        "\n",
        "def load_gt(path: str):\n",
        "    with open(path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Flatten into a list of (key, value) pairs\n",
        "    kvs = []\n",
        "    for item in data:\n",
        "        if not isinstance(item, dict):\n",
        "            continue\n",
        "        for k, v in item.items():\n",
        "            # v looks like \"type=No parking\" or \"times=8AM-10PM\"\n",
        "            if isinstance(v, str) and \"=\" in v:\n",
        "                kk, vv = v.split(\"=\", 1)\n",
        "                kvs.append((k if k else kk, vv))\n",
        "            else:\n",
        "                kvs.append((k, v))\n",
        "\n",
        "    # Generate natural language text\n",
        "    # Example: \"No parking(left), 2P, 8AM-10PM; area: AUTHORISED COUNCIL VEHICLES EXCEPTED; info: TICKET\"\n",
        "    pieces = []\n",
        "    arrows = []\n",
        "    for k, v in kvs:\n",
        "        lk = k.lower()\n",
        "        if \"arrow\" in lk:\n",
        "            arrows.append(v)\n",
        "        elif \"sign\" in lk and isinstance(v, str):\n",
        "            pieces.append(v)\n",
        "        elif isinstance(v, str):\n",
        "            pieces.append(v)\n",
        "        else:\n",
        "            pieces.append(f\"{k}: {v}\")\n",
        "    if arrows:\n",
        "        pieces.append(f\"arrows: {', '.join(arrows)}\")\n",
        "    nl_answer = \"; \".join(pieces)\n",
        "\n",
        "    kv_json = {k: v for k, v in kvs}\n",
        "    return nl_answer, kv_json\n",
        "\n",
        "def make_llava_sample(image_path: str, answer_text: str, basename: str):\n",
        "    prompt = \"Describe all parking rules and info in this image.\"\n",
        "    return {\n",
        "        \"id\": basename,\n",
        "        \"image\": image_path,\n",
        "        \"conversations\": [\n",
        "            {\"from\": \"human\", \"value\": f\"<image>\\n{prompt}\"},\n",
        "            {\"from\": \"gpt\",   \"value\": answer_text}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "# Collect samples\n",
        "pairs = []\n",
        "for json_path in glob.glob(f\"{GT_DIR}/*.json\"):\n",
        "    base = Path(json_path).stem\n",
        "    img_path = find_image_for(base)\n",
        "    if not img_path:\n",
        "        continue\n",
        "    answer_text, _kv = load_gt(json_path)\n",
        "    sample = make_llava_sample(img_path, answer_text, base)\n",
        "    pairs.append(sample)\n",
        "\n",
        "print(f\"Matched samples: {len(pairs)}\")\n",
        "\n",
        "# Split into train/val (95/5)\n",
        "random.seed(42)\n",
        "random.shuffle(pairs)\n",
        "n = len(pairs)\n",
        "k = max(1, int(n * 0.05))\n",
        "val_set = pairs[:k]\n",
        "train_set = pairs[k:]\n",
        "\n",
        "# Save\n",
        "with open(TRAIN_JSON, \"w\") as f:\n",
        "    json.dump(train_set, f, ensure_ascii=False, indent=2)\n",
        "with open(VAL_JSON, \"w\") as f:\n",
        "    json.dump(val_set, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"Saved{len(train_set)}training samples → {TRAIN_JSON}\")\n",
        "print(f\"Saved{len(val_set)}validation samples → {VAL_JSON}\")\n",
        "\n",
        "# Print one sample for verification\n",
        "if pairs:\n",
        "    print(\"Sample:\")\n",
        "    print(json.dumps(pairs[0], ensure_ascii=False, indent=2)[:800])"
      ],
      "metadata": {
        "id": "l7GO60Bj8dVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad9ab35-1af6-4993-b08d-7406ec0c7add"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched samples: 20\n",
            "Saved19training samples → /content/drive/MyDrive/FastVLM_RLHF/sft_data/train.json\n",
            "Saved1validation samples → /content/drive/MyDrive/FastVLM_RLHF/sft_data/val.json\n",
            "Sample:\n",
            "{\n",
            "  \"id\": \"IMG_6486\",\n",
            "  \"image\": \"/content/drive/MyDrive/FastVLM_RLHF/images/IMG_6486.JPG\",\n",
            "  \"conversations\": [\n",
            "    {\n",
            "      \"from\": \"human\",\n",
            "      \"value\": \"<image>\\nDescribe all parking rules and info in this image.\"\n",
            "    },\n",
            "    {\n",
            "      \"from\": \"gpt\",\n",
            "      \"value\": \"parking; DISABLE PEOPLE ONLY; PARALLEL PARKING; arrows: left, left\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FastVLM LoRA-SFT Training"
      ],
      "metadata": {
        "id": "WIyEKBT6xOXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Completely disable bitsandbytes\n",
        "print(\"Configuring environment...\")\n",
        "\n",
        "# Remove any existing bitsandbytes modules\n",
        "for module_name in list(sys.modules.keys()):\n",
        "    if module_name == \"bitsandbytes\" or module_name.startswith(\"bitsandbytes.\"):\n",
        "        del sys.modules[module_name]\n",
        "\n",
        "# Create a complete fake bitsandbytes module\n",
        "class FakeBnbModule(types.ModuleType):\n",
        "    def __init__(self, name):\n",
        "        super().__init__(name)\n",
        "        self.__spec__ = ModuleSpec(name, None)\n",
        "        self.__version__ = \"0.0.0\"\n",
        "        self.__file__ = \"<fake>\"\n",
        "        self.__package__ = name.split(\".\")[0]\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        return None\n",
        "\n",
        "# Register the fake module\n",
        "bnb = FakeBnbModule(\"bitsandbytes\")\n",
        "bnb.nn = FakeBnbModule(\"bitsandbytes.nn\")\n",
        "bnb.functional = FakeBnbModule(\"bitsandbytes.functional\")\n",
        "\n",
        "sys.modules[\"bitsandbytes\"] = bnb\n",
        "sys.modules[\"bitsandbytes.nn\"] = bnb.nn\n",
        "sys.modules[\"bitsandbytes.functional\"] = bnb.functional\n",
        "\n",
        "print(\"bitsandbytes has been disabled\")\n",
        "\n",
        "# Step 2: Basic setup\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Step 3: Path configuration\n",
        "PROJECT = \"/content/drive/MyDrive/FastVLM_RLHF\"\n",
        "TRAIN_JSON = f\"{PROJECT}/sft_data/train.json\"\n",
        "VAL_JSON = f\"{PROJECT}/sft_data/val.json\"\n",
        "OUT_DIR = f\"{PROJECT}/outputs/sft_lora\"\n",
        "\n",
        "# Verify required files\n",
        "print(\"\\nVerifying files...\")\n",
        "required_files = {\n",
        "    \"Training data\": TRAIN_JSON,\n",
        "    \"Validation data\": VAL_JSON,\n",
        "}\n",
        "\n",
        "for name, path in required_files.items():\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"{name} not found: {path}\")\n",
        "    print(f\"{name}: {path}\")\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "print(f\"Output directory: {OUT_DIR}\")\n",
        "\n",
        "# Step 4: Install and import dependencies\n",
        "print(\"\\nChecking dependencies...\")\n",
        "\n",
        "try:\n",
        "    import peft\n",
        "    print(f\"PEFT version: {peft.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"Installing PEFT...\")\n",
        "    import subprocess\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"peft\", \"-q\"], check=True)\n",
        "    import peft\n",
        "    print(f\"PEFT installed: {peft.__version__}\")\n",
        "\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as T\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from PIL import Image\n",
        "\n",
        "# Check transformers version\n",
        "from transformers import __version__ as tf_version\n",
        "print(f\"Transformers version: {tf_version}\")\n",
        "\n",
        "# Detect if using new evaluation API\n",
        "use_new_eval_api = tuple(map(int, tf_version.split('.')[:2])) >= (4, 33)\n",
        "print(f\"Using {'new' if use_new_eval_api else 'old'} API version\")\n",
        "\n",
        "# Step 5: Verify model is loaded\n",
        "print(\"\\nVerifying model...\")\n",
        "\n",
        "required_vars = ['model', 'tokenizer']\n",
        "missing_vars = [v for v in required_vars if v not in globals()]\n",
        "\n",
        "if missing_vars:\n",
        "    raise RuntimeError(\n",
        "        f\"Missing required variables: {', '.join(missing_vars)}\\n\"\n",
        "        \"Please run the model loading script first to get model and tokenizer.\"\n",
        "    )\n",
        "\n",
        "# Prevent quantized models\n",
        "if getattr(model, \"is_loaded_in_4bit\", False):\n",
        "    raise RuntimeError(\"Detected a 4-bit quantized model. Please use an FP16 base model.\")\n",
        "if getattr(model, \"is_loaded_in_8bit\", False):\n",
        "    raise RuntimeError(\"Detected an 8-bit quantized model. Please use an FP16 base model.\")\n",
        "\n",
        "print(f\"Using device: {model.device}\")\n",
        "print(f\"Model dtype: {getattr(model, 'dtype', 'unknown')}\")\n",
        "\n",
        "# Step 6: Build image preprocessor\n",
        "print(\"\\nConfiguring image preprocessor...\")\n",
        "\n",
        "def build_preprocess():\n",
        "    # Get image size\n",
        "    vision_config = getattr(model.config, \"vision_config\", {})\n",
        "    img_size = getattr(vision_config, \"image_size\", 336) or 336\n",
        "\n",
        "    # Prefer image_processor if available\n",
        "    if 'image_processor' in globals() and callable(getattr(image_processor, \"__call__\", None)):\n",
        "        def _proc(pil_img):\n",
        "            px = image_processor(pil_img, return_tensors=\"pt\")[\"pixel_values\"]\n",
        "            return px[0]\n",
        "        print(f\"Using image_processor (size={img_size})\")\n",
        "        return _proc, img_size\n",
        "\n",
        "    # Fallback with torchvision transforms\n",
        "    preprocess = T.Compose([\n",
        "        T.Resize(img_size, interpolation=T.InterpolationMode.BICUBIC),\n",
        "        T.CenterCrop(img_size),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(\n",
        "            [0.48145466, 0.4578275, 0.40821073],\n",
        "            [0.26862954, 0.26130258, 0.27577711]\n",
        "        ),\n",
        "    ])\n",
        "\n",
        "    def _proc(pil_img):\n",
        "        return preprocess(pil_img)\n",
        "\n",
        "    print(f\"Using torchvision transforms (size={img_size})\")\n",
        "    return _proc, img_size\n",
        "\n",
        "img_proc, IMG_SIZE = build_preprocess()\n",
        "\n",
        "# Step 7: Build dataset\n",
        "print(\"\\nBuilding dataset...\")\n",
        "\n",
        "class LlavaSFTDataset(Dataset):\n",
        "    def __init__(self, json_path, tokenizer, img_proc):\n",
        "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            self.samples = json.load(f)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.img_proc = img_proc\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ex = self.samples[idx]\n",
        "        img_path = ex[\"image\"]\n",
        "        conv = ex[\"conversations\"]\n",
        "\n",
        "        assert conv[0][\"from\"] == \"human\", \"The first turn must be from 'human'\"\n",
        "        assert conv[1][\"from\"] == \"gpt\", \"The second turn must be from 'gpt'\"\n",
        "\n",
        "        prompt = conv[0][\"value\"]\n",
        "        answer = conv[1][\"value\"]\n",
        "\n",
        "        # Tokenize\n",
        "        tok_prompt = self.tokenizer(prompt, add_special_tokens=False)\n",
        "        tok_answer = self.tokenizer(answer, add_special_tokens=False)\n",
        "\n",
        "        input_ids = tok_prompt[\"input_ids\"] + tok_answer[\"input_ids\"]\n",
        "        attn_mask = [1] * len(input_ids)\n",
        "        labels = [-100] * len(tok_prompt[\"input_ids\"]) + tok_answer[\"input_ids\"]\n",
        "\n",
        "        # Load image\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        px = self.img_proc(img)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(attn_mask, dtype=torch.long),\n",
        "            \"labels\": torch.tensor(labels, dtype=torch.long),\n",
        "            \"images\": px,\n",
        "        }\n",
        "\n",
        "# Collator\n",
        "def collate_fn(batch):\n",
        "    input_ids = [b[\"input_ids\"] for b in batch]\n",
        "    attention_mask = [b[\"attention_mask\"] for b in batch]\n",
        "    labels = [b[\"labels\"] for b in batch]\n",
        "    max_len = max(x.size(0) for x in input_ids)\n",
        "\n",
        "    def pad_to(x, pad_val):\n",
        "        out = torch.full((len(x), max_len), pad_val, dtype=x[0].dtype)\n",
        "        for i, t in enumerate(x):\n",
        "            out[i, :t.size(0)] = t\n",
        "        return out\n",
        "\n",
        "    pad_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else 0\n",
        "    input_ids = pad_to(input_ids, pad_id)\n",
        "    attention_mask = pad_to(attention_mask, 0)\n",
        "    labels_out = pad_to(labels, -100)\n",
        "\n",
        "    model_dtype = getattr(model, \"dtype\", torch.float16)\n",
        "    images = torch.stack([b[\"images\"] for b in batch], dim=0)\n",
        "    images = images.to(dtype=model_dtype, non_blocking=True)\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"labels\": labels_out,\n",
        "        \"images\": images,\n",
        "    }\n",
        "\n",
        "# Create datasets\n",
        "train_ds = LlavaSFTDataset(TRAIN_JSON, tokenizer, img_proc)\n",
        "val_ds = LlavaSFTDataset(VAL_JSON, tokenizer, img_proc)\n",
        "\n",
        "print(f\"Training set: {len(train_ds)} samples\")\n",
        "print(f\"Validation set: {len(val_ds)} samples\")\n",
        "\n",
        "# Step 8: Configure LoRA\n",
        "print(\"\\nConfiguring LoRA...\")\n",
        "\n",
        "target_modules = [\n",
        "    \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "    \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "]\n",
        "\n",
        "lora_cfg = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=target_modules,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "# Inject LoRA\n",
        "model = get_peft_model(model, lora_cfg)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# Step 9: Training configuration\n",
        "print(\"\\nConfiguring training parameters...\")\n",
        "\n",
        "# Hyperparameters\n",
        "bsz = 2\n",
        "grad_acc = 4\n",
        "max_epochs = 3\n",
        "warmup_ratio = 0.1\n",
        "lr = 2e-4\n",
        "\n",
        "print(f\"  - Batch size: {bsz}\")\n",
        "print(f\"  - Gradient accumulation: {grad_acc}\")\n",
        "print(f\"  - Effective batch size: {bsz * grad_acc}\")\n",
        "print(f\"  - Epochs: {max_epochs}\")\n",
        "print(f\"  - Learning rate: {lr}\")\n",
        "\n",
        "# Build training arguments\n",
        "training_kwargs = {\n",
        "    \"output_dir\": OUT_DIR,\n",
        "    \"per_device_train_batch_size\": bsz,\n",
        "    \"per_device_eval_batch_size\": bsz,\n",
        "    \"gradient_accumulation_steps\": grad_acc,\n",
        "    \"num_train_epochs\": max_epochs,\n",
        "    \"learning_rate\": lr,\n",
        "    \"weight_decay\": 0.0,\n",
        "    \"warmup_ratio\": warmup_ratio,\n",
        "    \"logging_steps\": 5,\n",
        "    \"eval_steps\": 20,\n",
        "    \"save_strategy\": \"steps\",\n",
        "    \"save_steps\": 50,\n",
        "    \"save_total_limit\": 2,\n",
        "    \"bf16\": False,\n",
        "    \"fp16\": True,\n",
        "    \"report_to\": \"none\",\n",
        "    \"remove_unused_columns\": False,\n",
        "    \"dataloader_num_workers\": 2,\n",
        "    \"dataloader_pin_memory\": True,\n",
        "}\n",
        "\n",
        "# Use correct argument name based on version\n",
        "if use_new_eval_api:\n",
        "    training_kwargs[\"eval_strategy\"] = \"steps\"\n",
        "else:\n",
        "    training_kwargs[\"evaluation_strategy\"] = \"steps\"\n",
        "\n",
        "args = TrainingArguments(**training_kwargs)\n",
        "\n",
        "# Step 10: Patch model and create Trainer\n",
        "print(\"\\nPatching model compatibility...\")\n",
        "\n",
        "import functools\n",
        "import inspect\n",
        "\n",
        "# Directly patch model forward method\n",
        "def patch_model_forward(model):\n",
        "    \"\"\"Patch the model's forward method to remove incompatible arguments\"\"\"\n",
        "    # Locate the actual model\n",
        "    if hasattr(model, 'base_model'):\n",
        "        target_model = model.base_model.model if hasattr(model.base_model, 'model') else model.base_model\n",
        "    else:\n",
        "        target_model = model\n",
        "\n",
        "    # Save original forward\n",
        "    original_forward = target_model.forward\n",
        "\n",
        "    @functools.wraps(original_forward)\n",
        "    def patched_forward(*args, **kwargs):\n",
        "        # Remove potentially problematic parameters\n",
        "        problematic_params = ['num_items_in_batch', 'num_logits_to_keep']\n",
        "        for param in problematic_params:\n",
        "            kwargs.pop(param, None)\n",
        "        return original_forward(*args, **kwargs)\n",
        "\n",
        "    # Apply patch\n",
        "    target_model.forward = patched_forward\n",
        "    return model\n",
        "\n",
        "# Apply patch\n",
        "model = patch_model_forward(model)\n",
        "print(\"Patched model forward method\")\n",
        "\n",
        "# Create Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    data_collator=collate_fn,\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Starting training\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "try:\n",
        "    trainer.train()\n",
        "\n",
        "    print(\"\\nTraining complete!\")\n",
        "\n",
        "    # Save model\n",
        "    print(\"\\nSaving model...\")\n",
        "    trainer.save_model(OUT_DIR)\n",
        "    tokenizer.save_pretrained(OUT_DIR)\n",
        "    print(f\"LoRA adapter saved to: {OUT_DIR}\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nTraining interrupted\")\n",
        "    interrupt_dir = f\"{OUT_DIR}/interrupted\"\n",
        "    trainer.save_model(interrupt_dir)\n",
        "    print(f\"Checkpoint saved to: {interrupt_dir}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nTraining failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise\n",
        "\n",
        "# Step 11: Merge LoRA weights\n",
        "print(\"\\nMerging LoRA weights...\")\n",
        "MERGE_DIR = f\"{PROJECT}/outputs/sft_merged\"\n",
        "os.makedirs(MERGE_DIR, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    merged = model.merge_and_unload()\n",
        "    merged.save_pretrained(MERGE_DIR, safe_serialization=True)\n",
        "    tokenizer.save_pretrained(MERGE_DIR)\n",
        "    print(f\"Merged full weights saved to: {MERGE_DIR}\")\n",
        "\n",
        "except AttributeError:\n",
        "    print(\"Current PEFT version does not support merge_and_unload()\")\n",
        "    print(\"You can upgrade PEFT or directly use the LoRA adapter\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Merging failed: {e}\")\n",
        "    print(\"This does not affect the training result; you can still use the LoRA adapter\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"All done!\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nOutput files:\")\n",
        "print(f\"LoRA adapter: {OUT_DIR}\")\n",
        "print(f\"Merged model: {MERGE_DIR}\")"
      ],
      "metadata": {
        "id": "34ETYTrqQZJW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1ea517b-9e99-4ad0-bb2b-162860162423"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuring environment...\n",
            "bitsandbytes has been disabled\n",
            "\n",
            "Verifying files...\n",
            "Training data: /content/drive/MyDrive/FastVLM_RLHF/sft_data/train.json\n",
            "Validation data: /content/drive/MyDrive/FastVLM_RLHF/sft_data/val.json\n",
            "Output directory: /content/drive/MyDrive/FastVLM_RLHF/outputs/sft_lora\n",
            "\n",
            "Checking dependencies...\n",
            "PEFT version: 0.17.1\n",
            "Transformers version: 4.57.1\n",
            "Using new API version\n",
            "\n",
            "Verifying model...\n",
            "Using device: cuda:0\n",
            "Model dtype: torch.float16\n",
            "\n",
            "Configuring image preprocessor...\n",
            "Using torchvision transforms (size=336)\n",
            "\n",
            "Building dataset...\n",
            "Training set: 19 samples\n",
            "Validation set: 1 samples\n",
            "\n",
            "Configuring LoRA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 9,232,384 || all params: 1,685,101,152 || trainable%: 0.5479\n",
            "\n",
            "Configuring training parameters...\n",
            "  - Batch size: 2\n",
            "  - Gradient accumulation: 4\n",
            "  - Effective batch size: 8\n",
            "  - Epochs: 3\n",
            "  - Learning rate: 0.0002\n",
            "\n",
            "Patching model compatibility...\n",
            "Patched model forward method\n",
            "\n",
            "============================================================\n",
            "Starting training\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:27, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training complete!\n",
            "\n",
            "Saving model...\n",
            "LoRA adapter saved to: /content/drive/MyDrive/FastVLM_RLHF/outputs/sft_lora\n",
            "\n",
            "Merging LoRA weights...\n",
            "Merged full weights saved to: /content/drive/MyDrive/FastVLM_RLHF/outputs/sft_merged\n",
            "\n",
            "============================================================\n",
            "All done!\n",
            "============================================================\n",
            "\n",
            "Output files:\n",
            "LoRA adapter: /content/drive/MyDrive/FastVLM_RLHF/outputs/sft_lora\n",
            "Merged model: /content/drive/MyDrive/FastVLM_RLHF/outputs/sft_merged\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DPO Preference Generation"
      ],
      "metadata": {
        "id": "1sGf8DJ9H_wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pixel_values_from_image(img: Image.Image):\n",
        "    # Try using the real image_processor\n",
        "    if 'image_processor' in globals() and callable(getattr(image_processor, \"__call__\", None)):\n",
        "        px = image_processor(images=img, return_tensors=\"pt\")\n",
        "        pv = px.get(\"pixel_values\") or px.get(\"images\") or px[\"pixel_values\"]\n",
        "        return pv.to(model.device, dtype=getattr(model, \"dtype\", torch.float16))\n",
        "\n",
        "    # Build pixel_values (B, C, H, W) with torchvision\n",
        "    # Get image_size from the model; if unavailable use 336.\n",
        "    # If image_processor was overridden as an int, use it directly.\n",
        "    size = 336\n",
        "    if isinstance(globals().get(\"image_processor\", None), int):\n",
        "        size = int(image_processor)\n",
        "    else:\n",
        "        vision_cfg = getattr(getattr(model, \"config\", None), \"vision_config\", None)\n",
        "        size = int(getattr(vision_cfg, \"image_size\", size)) if vision_cfg else size\n",
        "\n",
        "    preprocess = T.Compose([\n",
        "        T.Resize(size, interpolation=T.InterpolationMode.BICUBIC),\n",
        "        T.CenterCrop(size),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.48145466, 0.4578275, 0.40821073],\n",
        "                    [0.26862954, 0.26130258, 0.27577711]),\n",
        "    ])\n",
        "    pv = preprocess(img).unsqueeze(0)  # (1,3,H,W)\n",
        "    return pv.to(model.device, dtype=getattr(model, \"dtype\", torch.float16))\n",
        "\n",
        "PROJECT  = \"/content/drive/MyDrive/FastVLM_RLHF\"\n",
        "GT_DIR   = f\"{PROJECT}/gt_json\"\n",
        "PRED_DIR = f\"{PROJECT}/preds_1.5b\"\n",
        "OUT_DIR  = f\"{PROJECT}/pref_data\"\n",
        "OUT_PATH = f\"{OUT_DIR}/dpo_pairs.jsonl\"\n",
        "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "KEYS = [\"2P\",\"1P\",\"NO STOPPING\",\"NO PARKING\",\"TICKET\",\"PERMIT\",\n",
        "        \"→\",\"←\",\"↔\",\"AM\",\"PM\",\"MON\",\"TUE\",\"WED\",\"THU\",\"FRI\",\"SAT\",\"SUN\"]\n",
        "\n",
        "def auto_score(pred_text, gt_text):\n",
        "    t, g = pred_text.upper(), gt_text.upper()\n",
        "    return sum(1 for k in KEYS if (k in t) and (k in g))\n",
        "\n",
        "pairs = 0\n",
        "skips = 0\n",
        "missing = []\n",
        "\n",
        "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as fout:\n",
        "    for gt_file in sorted(os.listdir(GT_DIR)):\n",
        "        if not gt_file.lower().endswith(\".json\"):\n",
        "            continue\n",
        "        base = os.path.splitext(gt_file)[0]\n",
        "        gt_path = os.path.join(GT_DIR, gt_file)\n",
        "\n",
        "        # Support different naming: IMG_6484.json/IMG_6484.JPG.json/IMG_6484.jpg.json\n",
        "        cand_names = [f\"{base}.json\", f\"{base}.JPG.json\", f\"{base}.jpg.json\"]\n",
        "        pred_path = next((os.path.join(PRED_DIR, n) for n in cand_names\n",
        "                          if os.path.exists(os.path.join(PRED_DIR, n))), None)\n",
        "\n",
        "        if pred_path is None:\n",
        "            skips += 1\n",
        "            missing.append(base)\n",
        "            continue\n",
        "\n",
        "        gt   = json.load(open(gt_path))\n",
        "        pred = json.load(open(pred_path))\n",
        "\n",
        "        gt_text   = json.dumps(gt, ensure_ascii=False)\n",
        "        pred_text = json.dumps(pred, ensure_ascii=False)\n",
        "\n",
        "        # Two candidates\n",
        "        pred_a = pred_text\n",
        "        pred_b = pred_text[::-1]  # Construct a simple contrast sample\n",
        "\n",
        "        sa, sb = auto_score(pred_a, gt_text), auto_score(pred_b, gt_text)\n",
        "        if sa == sb:\n",
        "            chosen, rejected = (pred_a, pred_b) if random.random() < 0.5 else (pred_b, pred_a)\n",
        "        else:\n",
        "            chosen, rejected = (pred_a, pred_b) if sa > sb else (pred_b, pred_a)\n",
        "\n",
        "        fout.write(json.dumps({\n",
        "            \"image\": base,\n",
        "            \"prompt\": \"Extract parking info\",\n",
        "            \"chosen\": chosen,\n",
        "            \"rejected\": rejected\n",
        "        }, ensure_ascii=False) + \"\\n\")\n",
        "        pairs += 1\n",
        "\n",
        "print(f\"DPO preference pairs generated: {OUT_PATH} (total {pairs} pairs, skipped {skips})\")\n",
        "if missing:\n",
        "    print(\"The following basenames had no corresponding .json in preds_1.5b:\")\n",
        "    print(\", \".join(missing[:20]) + (\" ...\" if len(missing) > 20 else \"\"))"
      ],
      "metadata": {
        "id": "2_CRlfUL3Tu1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b16e2d5-f78d-42e2-c0e3-f433f0d39099"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DPO preference pairs generated: /content/drive/MyDrive/FastVLM_RLHF/pref_data/dpo_pairs.jsonl (total 20 pairs, skipped 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate predictions using the loaded SFT model"
      ],
      "metadata": {
        "id": "lB5B5JCk1IWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT = \"/content/drive/MyDrive/FastVLM_RLHF\"\n",
        "IMG_DIR = f\"{PROJECT}/images\"\n",
        "PRED_DIR = f\"{PROJECT}/preds_1.5b\"\n",
        "\n",
        "os.makedirs(PRED_DIR, exist_ok=True)\n",
        "\n",
        "# Supported image formats\n",
        "IMG_EXTS = [\".jpg\", \".jpeg\", \".png\", \".webp\", \".bmp\", \".JPG\", \".JPEG\", \".PNG\"]\n",
        "\n",
        "# Check whether the model is already loaded\n",
        "if 'model' not in globals() or 'tokenizer' not in globals() or 'image_processor' not in globals():\n",
        "    print(\"\\nModel not loaded!\")\n",
        "    print(\"Please run the model loading script first.\")\n",
        "    raise RuntimeError(\"Load the model before proceeding.\")\n",
        "\n",
        "print(f\"\\nUsing the loaded model\")\n",
        "print(f\"Model device: {model.device}\")\n",
        "print(f\"Model type: {type(model).__name__}\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Prediction function\n",
        "def generate_prediction(image_path, prompt=\"Describe all parking rules and info in this image.\"):\n",
        "    # Generate a prediction for a single image\n",
        "    try:\n",
        "        # Load image\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        # Prepare inputs\n",
        "        full_prompt = f\"<image>\\n{prompt}\"\n",
        "        inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "        # Process image\n",
        "        pixel_values = image_processor(image, return_tensors=\"pt\")[\"pixel_values\"]\n",
        "        pixel_values = pixel_values.to(model.device, dtype=model.dtype)\n",
        "\n",
        "        # Generate\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                images=pixel_values,\n",
        "                max_new_tokens=256,\n",
        "                do_sample=False,\n",
        "                temperature=0.0,\n",
        "            )\n",
        "\n",
        "        # Decode\n",
        "        full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Extract the answer\n",
        "        if prompt in full_text:\n",
        "            answer = full_text.split(prompt)[-1].strip()\n",
        "        else:\n",
        "            answer = full_text.strip()\n",
        "\n",
        "        return answer\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Batch prediction\n",
        "print(\"\\nStarting prediction...\\n\")\n",
        "\n",
        "# Collect all images\n",
        "image_files = []\n",
        "for ext in IMG_EXTS:\n",
        "    image_files.extend(glob.glob(os.path.join(IMG_DIR, f\"*{ext}\")))\n",
        "\n",
        "image_files = sorted(image_files)\n",
        "print(f\"Found {len(image_files)} images\")\n",
        "\n",
        "# Generate predictions\n",
        "success_count = 0\n",
        "failed_count = 0\n",
        "\n",
        "for img_path in tqdm(image_files, desc=\"Generating predictions\"):\n",
        "    base_name = Path(img_path).stem\n",
        "    pred_path = os.path.join(PRED_DIR, f\"{base_name}.json\")\n",
        "\n",
        "    # Skip if prediction already exists\n",
        "    if os.path.exists(pred_path):\n",
        "        success_count += 1\n",
        "        continue\n",
        "\n",
        "    # Generate prediction\n",
        "    prediction = generate_prediction(img_path)\n",
        "\n",
        "    if prediction:\n",
        "        # Try to parse as structured data\n",
        "        try:\n",
        "            pred_data = json.loads(prediction)\n",
        "        except json.JSONDecodeError:\n",
        "            # If it's not JSON, store as plain text\n",
        "            pred_data = {\"text\": prediction}\n",
        "\n",
        "        # Save prediction\n",
        "        with open(pred_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(pred_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        success_count += 1\n",
        "    else:\n",
        "        failed_count += 1\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\\nGeneration summary\")\n",
        "print(f\"Total images: {len(image_files)}\")\n",
        "print(f\"Succeeded: {success_count}\")\n",
        "print(f\"Failed: {failed_count}\")\n",
        "print(f\"Output directory: {PRED_DIR}\")\n",
        "\n",
        "# Show an example\n",
        "pred_files = glob.glob(os.path.join(PRED_DIR, \"*.json\"))\n",
        "if pred_files:\n",
        "    print(\"\\nPrediction example:\")\n",
        "    with open(pred_files[0], 'r', encoding='utf-8') as f:\n",
        "        example = json.load(f)\n",
        "    print(json.dumps(example, ensure_ascii=False, indent=2)[:300])"
      ],
      "metadata": {
        "id": "XNBGcNMyS4bY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3bdd812-12f3-42d0-eda3-83480b1d0cd4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using the loaded model\n",
            "Model device: cuda:0\n",
            "Model type: PeftModelForCausalLM\n",
            "\n",
            "Starting prediction...\n",
            "\n",
            "Found 20 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating predictions: 100%|██████████| 20/20 [00:00<00:00, 1898.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Generation summary\n",
            "Total images: 20\n",
            "Succeeded: 20\n",
            "Failed: 0\n",
            "Output directory: /content/drive/MyDrive/FastVLM_RLHF/preds_1.5b\n",
            "\n",
            "Prediction example:\n",
            "{\n",
            "  \"parking_sign\": \"parking\",\n",
            "  \"parking_time\": \"8AM-10PM\",\n",
            "  \"parking_day\": \"MON-FRI\",\n",
            "  \"parking_duration\": \"2P\",\n",
            "  \"parking_arrow\": \"left\",\n",
            "  \"vehicle_type\": \"bus\",\n",
            "  \"permit_zone\": \"AREA 36\",\n",
            "  \"area_type\": \"DISABLE PEOPLE ONLY\",\n",
            "  \"Addition_info\": \"TICKET\"\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SFT Prediction vs GT Automatic Evaluation (Keyword F1 + Error Examples)"
      ],
      "metadata": {
        "id": "bRUwHsmk2HSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT  = \"/content/drive/MyDrive/FastVLM_RLHF\"\n",
        "GT_DIR   = f\"{PROJECT}/gt_json\"\n",
        "PRED_DIR = f\"{PROJECT}/preds_1.5b\"\n",
        "OUT_DIR  = f\"{PROJECT}/outputs\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Keyword set\n",
        "KEYS = [\n",
        "    \"NO STOPPING\",\"NO PARKING\",\"DISABLE\",\"DISABLED\",\"DISABLE PEOPLE ONLY\",\n",
        "    \"1P\",\"2P\",\"3P\",\"TICKET\",\"PERMIT\",\"BUS\",\"PARALLEL\",\"ANGLED\",\n",
        "    \"AM\",\"PM\",\"MON\",\"TUE\",\"WED\",\"THU\",\"FRI\",\"SAT\",\"SUN\",\n",
        "    \"LEFT\",\"RIGHT\",\"BOTH\",\"↔\",\"→\",\"←\",\"AREA\",\"ZONE\"\n",
        "]\n",
        "\n",
        "# Normalization utility\n",
        "def norm_text(s: str) -> str:\n",
        "    s = unicodedata.normalize(\"NFKC\", s)\n",
        "    s = re.sub(r\"[\\s,;:|/]+\", \" \", s)\n",
        "    s = s.upper()\n",
        "    # Merge synonyms\n",
        "    s = s.replace(\"DISABLED\", \"DISABLE\")\n",
        "    s = s.replace(\"PEOPLE ONLY\", \"PEOPLE ONLY\")  # placeholder example\n",
        "    s = s.replace(\"↔\", \"BOTH\").replace(\"→\",\"RIGHT\").replace(\"←\",\"LEFT\")\n",
        "    s = s.replace(\"  \", \" \").strip()\n",
        "    return s\n",
        "\n",
        "def load_json_any(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        try:\n",
        "            return json.load(f)\n",
        "        except json.JSONDecodeError:\n",
        "            return None\n",
        "\n",
        "def flatten_gt(path):\n",
        "    # Flatten GT (list of dict with 'k=v', etc.) into text for maximum compatibility\n",
        "    obj = load_json_any(path)\n",
        "    if obj is None:\n",
        "        return \"\"\n",
        "    pieces = []\n",
        "    if isinstance(obj, list):\n",
        "        for item in obj:\n",
        "            if isinstance(item, dict):\n",
        "                for k, v in item.items():\n",
        "                    if isinstance(v, str) and \"=\" in v:\n",
        "                        kk, vv = v.split(\"=\", 1)\n",
        "                        pieces += [kk, vv]\n",
        "                    else:\n",
        "                        pieces += [str(k), str(v)]\n",
        "            else:\n",
        "                pieces.append(str(item))\n",
        "    elif isinstance(obj, dict):\n",
        "        for k, v in obj.items():\n",
        "            pieces += [str(k), str(v)]\n",
        "    else:\n",
        "        pieces.append(str(obj))\n",
        "    return norm_text(\" \".join(pieces))\n",
        "\n",
        "def flatten_pred(path):\n",
        "    # Be flexible: pred.json may be JSON, {\"text\": ...}, or raw text\n",
        "    obj = load_json_any(path)\n",
        "    if obj is None:\n",
        "        # Fallback: file isn't JSON; read as plain text\n",
        "        try:\n",
        "            txt = open(path, \"r\", encoding=\"utf-8\").read()\n",
        "            return norm_text(txt)\n",
        "        except:\n",
        "            return \"\"\n",
        "    if isinstance(obj, dict) and \"text\" in obj and isinstance(obj[\"text\"], str):\n",
        "        return norm_text(obj[\"text\"])\n",
        "    # dict/list -> text\n",
        "    return norm_text(json.dumps(obj, ensure_ascii=False))\n",
        "\n",
        "def extract_keys(norm_str: str):\n",
        "    found = set()\n",
        "    for k in KEYS:\n",
        "        if k in norm_str:\n",
        "            found.add(k)\n",
        "    # Simple arrow inference\n",
        "    if \"ARROW LEFT\" in norm_str and \"LEFT\" not in found: found.add(\"LEFT\")\n",
        "    if \"ARROW RIGHT\" in norm_str and \"RIGHT\" not in found: found.add(\"RIGHT\")\n",
        "    if \"ARROWS BOTH\" in norm_str and \"BOTH\" not in found: found.add(\"BOTH\")\n",
        "    return found\n",
        "\n",
        "# Main evaluation loop\n",
        "rows = []\n",
        "per_key_tp = Counter(); per_key_fp = Counter(); per_key_fn = Counter()\n",
        "sample_errors = []\n",
        "\n",
        "gt_files = sorted([p for p in glob.glob(f\"{GT_DIR}/*.json\")])\n",
        "for gt_path in gt_files:\n",
        "    base = Path(gt_path).stem\n",
        "    # Find the corresponding prediction\n",
        "    pred_path = None\n",
        "    for cand in [f\"{base}.json\", f\"{base}.JPG.json\", f\"{base}.jpg.json\"]:\n",
        "        p = os.path.join(PRED_DIR, cand)\n",
        "        if os.path.exists(p):\n",
        "            pred_path = p; break\n",
        "    if pred_path is None:\n",
        "        continue\n",
        "\n",
        "    gtxt = flatten_gt(gt_path)\n",
        "    ptxt = flatten_pred(pred_path)\n",
        "    gset = extract_keys(gtxt)\n",
        "    pset = extract_keys(ptxt)\n",
        "\n",
        "    tp = len(gset & pset)\n",
        "    fp = len(pset - gset)\n",
        "    fn = len(gset - pset)\n",
        "\n",
        "    prec = tp / (tp + fp) if (tp+fp) else 0.0\n",
        "    rec  = tp / (tp + fn) if (tp+fn) else 0.0\n",
        "    f1   = 2*prec*rec/(prec+rec) if (prec+rec) else 0.0\n",
        "\n",
        "    rows.append([base, tp, fp, fn, round(prec,4), round(rec,4), round(f1,4),\n",
        "                 \";\".join(sorted(gset)), \";\".join(sorted(pset))])\n",
        "\n",
        "    # Per-key tallies\n",
        "    for k in (gset & pset): per_key_tp[k]+=1\n",
        "    for k in (pset - gset): per_key_fp[k]+=1\n",
        "    for k in (gset - pset): per_key_fn[k]+=1\n",
        "\n",
        "    # Collect error samples\n",
        "    if f1 < 1.0:\n",
        "        sample_errors.append({\n",
        "            \"id\": base,\n",
        "            \"gt_keys\": sorted(gset),\n",
        "            \"pred_keys\": sorted(pset),\n",
        "            \"gt_text\": gtxt[:200],\n",
        "            \"pred_text\": ptxt[:200]\n",
        "        })\n",
        "\n",
        "# Aggregates\n",
        "micro_tp = sum(r[1] for r in rows)\n",
        "micro_fp = sum(r[2] for r in rows)\n",
        "micro_fn = sum(r[3] for r in rows)\n",
        "micro_prec = micro_tp/(micro_tp+micro_fp) if (micro_tp+micro_fp) else 0.0\n",
        "micro_rec  = micro_tp/(micro_tp+micro_fn) if (micro_tp+micro_fn) else 0.0\n",
        "micro_f1   = 2*micro_prec*micro_rec/(micro_prec+micro_rec) if (micro_prec+micro_rec) else 0.0\n",
        "\n",
        "print(\"Number of samples:\", len(rows))\n",
        "print(f\"Micro P/R/F1: {micro_prec:.3f} / {micro_rec:.3f} / {micro_f1:.3f}\")\n",
        "\n",
        "# Per-key\n",
        "print(\"\\nPer-key statistics (sorted by occurrences)\")\n",
        "key_stats = []\n",
        "for k in sorted(set(list(per_key_tp)+list(per_key_fp)+list(per_key_fn))):\n",
        "    tp, fp, fn = per_key_tp[k], per_key_fp[k], per_key_fn[k]\n",
        "    p = tp/(tp+fp) if (tp+fp) else 0.0\n",
        "    r = tp/(tp+fn) if (tp+fn) else 0.0\n",
        "    f1= 2*p*r/(p+r) if (p+r) else 0.0\n",
        "    key_stats.append([k, tp, fp, fn, round(p,3), round(r,3), round(f1,3)])\n",
        "\n",
        "for line in sorted(key_stats, key=lambda x: x[1]+x[2]+x[3], reverse=True):\n",
        "    print(f\"{line[0]:>12s} | TP:{line[1]:2d} FP:{line[2]:2d} FN:{line[3]:2d} | P/R/F1={line[4]:.3f}/{line[5]:.3f}/{line[6]:.3f}\")\n",
        "\n",
        "# Export CSVs\n",
        "csv_main = os.path.join(OUT_DIR, \"eval_sft_by_image.csv\")\n",
        "with open(csv_main, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    w = csv.writer(f)\n",
        "    w.writerow([\"id\",\"TP\",\"FP\",\"FN\",\"precision\",\"recall\",\"f1\",\"gt_keys\",\"pred_keys\"])\n",
        "    w.writerows(rows)\n",
        "print(\"\\nDetails exported to:\", csv_main)\n",
        "\n",
        "csv_key = os.path.join(OUT_DIR, \"eval_sft_by_key.csv\")\n",
        "with open(csv_key, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    w = csv.writer(f); w.writerow([\"key\",\"TP\",\"FP\",\"FN\",\"precision\",\"recall\",\"f1\"])\n",
        "    w.writerows(key_stats)\n",
        "print(\"Per-key stats exported to:\", csv_key)\n",
        "\n",
        "# Save a subset of error samples\n",
        "err_path = os.path.join(OUT_DIR, \"eval_sft_errors.jsonl\")\n",
        "with open(err_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for e in sample_errors[:50]:\n",
        "        f.write(json.dumps(e, ensure_ascii=False)+\"\\n\")\n",
        "print(\"Error samples (first 50) exported to:\", err_path)"
      ],
      "metadata": {
        "id": "VOO5pZeO2WUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec9eecc1-14a2-4286-e2d9-d64825bb370d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 20\n",
            "Micro P/R/F1: 0.305 / 0.736 / 0.431\n",
            "\n",
            "Per-key statistics (sorted by occurrences)\n",
            "          2P | TP:10 FP:10 FN: 0 | P/R/F1=0.500/1.000/0.667\n",
            "          AM | TP:11 FP: 9 FN: 0 | P/R/F1=0.550/1.000/0.710\n",
            "        AREA | TP: 0 FP:20 FN: 0 | P/R/F1=0.000/0.000/0.000\n",
            "         BUS | TP: 0 FP:20 FN: 0 | P/R/F1=0.000/0.000/0.000\n",
            "     DISABLE | TP: 4 FP:16 FN: 0 | P/R/F1=0.200/1.000/0.333\n",
            "DISABLE PEOPLE ONLY | TP: 4 FP:16 FN: 0 | P/R/F1=0.200/1.000/0.333\n",
            "        LEFT | TP:13 FP: 6 FN: 1 | P/R/F1=0.684/0.929/0.788\n",
            "         MON | TP: 5 FP:15 FN: 0 | P/R/F1=0.250/1.000/0.400\n",
            "      PERMIT | TP: 2 FP:18 FN: 0 | P/R/F1=0.100/1.000/0.182\n",
            "          PM | TP:11 FP: 9 FN: 0 | P/R/F1=0.550/1.000/0.710\n",
            "      TICKET | TP: 9 FP:11 FN: 0 | P/R/F1=0.450/1.000/0.621\n",
            "        ZONE | TP: 1 FP:19 FN: 0 | P/R/F1=0.050/1.000/0.095\n",
            "         FRI | TP: 5 FP:13 FN: 0 | P/R/F1=0.278/1.000/0.435\n",
            "       RIGHT | TP: 0 FP: 1 FN:10 | P/R/F1=0.000/0.000/0.000\n",
            " NO STOPPING | TP: 3 FP: 0 FN: 3 | P/R/F1=1.000/0.500/0.667\n",
            "         SAT | TP: 0 FP: 2 FN: 4 | P/R/F1=0.000/0.000/0.000\n",
            "  NO PARKING | TP: 3 FP: 0 FN: 2 | P/R/F1=1.000/0.600/0.750\n",
            "         SUN | TP: 0 FP: 0 FN: 4 | P/R/F1=0.000/0.000/0.000\n",
            "          3P | TP: 0 FP: 0 FN: 3 | P/R/F1=0.000/0.000/0.000\n",
            "    PARALLEL | TP: 0 FP: 0 FN: 2 | P/R/F1=0.000/0.000/0.000\n",
            "\n",
            "Details exported to: /content/drive/MyDrive/FastVLM_RLHF/outputs/eval_sft_by_image.csv\n",
            "Per-key stats exported to: /content/drive/MyDrive/FastVLM_RLHF/outputs/eval_sft_by_key.csv\n",
            "Error samples (first 50) exported to: /content/drive/MyDrive/FastVLM_RLHF/outputs/eval_sft_errors.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FastVLM DPO Training"
      ],
      "metadata": {
        "id": "HSOFZRGK3Ewo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT = \"/content/drive/MyDrive/FastVLM_RLHF\"\n",
        "DPO_PAIRS = f\"{PROJECT}/pref_data/dpo_pairs_v2.jsonl\"\n",
        "OUT_DIR = f\"{PROJECT}/outputs/dpo_lora\"\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Step 1: Verify the model is loaded\n",
        "if 'model' not in globals() or 'tokenizer' not in globals():\n",
        "    raise RuntimeError(\"Please load the SFT-trained model first.\")\n",
        "\n",
        "print(f\"\\nUsing the loaded model\")\n",
        "print(f\"Model device: {model.device}\")\n",
        "print(f\"Model type: {type(model).__name__}\")\n",
        "\n",
        "# Switch to training mode\n",
        "model.train()\n",
        "\n",
        "# Step 2: Image preprocessor\n",
        "def get_image_processor_fn():\n",
        "    # Get an image preprocessor consistent with training\n",
        "    vision_config = getattr(model.config, \"vision_config\", {})\n",
        "    img_size = getattr(vision_config, \"image_size\", 336) or 336\n",
        "\n",
        "    # Prefer image_processor\n",
        "    if 'image_processor' in globals() and callable(getattr(image_processor, \"__call__\", None)):\n",
        "        def proc(pil_img):\n",
        "            px = image_processor(pil_img, return_tensors=\"pt\")[\"pixel_values\"]\n",
        "            return px[0]  # return (C, H, W)\n",
        "        print(f\"Using image_processor (size={img_size})\")\n",
        "        return proc\n",
        "\n",
        "    # Fallback to torchvision transforms\n",
        "    preprocess = T.Compose([\n",
        "        T.Resize(img_size, interpolation=T.InterpolationMode.BICUBIC),\n",
        "        T.CenterCrop(img_size),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(\n",
        "            [0.48145466, 0.4578275, 0.40821073],\n",
        "            [0.26862954, 0.26130258, 0.27577711]\n",
        "        ),\n",
        "    ])\n",
        "\n",
        "    def proc(pil_img):\n",
        "        return preprocess(pil_img)  # (C, H, W)\n",
        "\n",
        "    print(f\"Using torchvision transforms (size={img_size})\")\n",
        "    return proc\n",
        "\n",
        "img_proc = get_image_processor_fn()\n",
        "\n",
        "# Step 3: Build the DPO dataset\n",
        "class DPOVisionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    DPO dataset with multimodal inputs.\n",
        "    Each sample contains: image + prompt + chosen + rejected\n",
        "    \"\"\"\n",
        "    def __init__(self, jsonl_path, tokenizer, img_processor):\n",
        "        self.samples = []\n",
        "        with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                self.samples.append(json.loads(line))\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.img_processor = img_processor\n",
        "        print(f\"Loaded {len(self.samples)} preference pairs\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ex = self.samples[idx]\n",
        "\n",
        "        # Load image\n",
        "        img = Image.open(ex[\"image\"]).convert(\"RGB\")\n",
        "        pixel_values = self.img_processor(img)\n",
        "\n",
        "        # Build full prompt\n",
        "        full_prompt = f\"<image>\\n{ex['prompt']}\"\n",
        "\n",
        "        # Tokenize prompt\n",
        "        prompt_tokens = self.tokenizer(\n",
        "            full_prompt,\n",
        "            add_special_tokens=False,\n",
        "            return_tensors=None\n",
        "        )\n",
        "\n",
        "        # Tokenize chosen\n",
        "        chosen_tokens = self.tokenizer(\n",
        "            ex[\"chosen\"],\n",
        "            add_special_tokens=False,\n",
        "            return_tensors=None\n",
        "        )\n",
        "\n",
        "        # Tokenize rejected\n",
        "        rejected_tokens = self.tokenizer(\n",
        "            ex[\"rejected\"],\n",
        "            add_special_tokens=False,\n",
        "            return_tensors=None\n",
        "        )\n",
        "\n",
        "        # Build the full chosen sequence\n",
        "        chosen_input_ids = prompt_tokens[\"input_ids\"] + chosen_tokens[\"input_ids\"]\n",
        "        chosen_attention_mask = [1] * len(chosen_input_ids)\n",
        "        chosen_labels = [-100] * len(prompt_tokens[\"input_ids\"]) + chosen_tokens[\"input_ids\"]\n",
        "\n",
        "        # Build the full rejected sequence\n",
        "        rejected_input_ids = prompt_tokens[\"input_ids\"] + rejected_tokens[\"input_ids\"]\n",
        "        rejected_attention_mask = [1] * len(rejected_input_ids)\n",
        "        rejected_labels = [-100] * len(prompt_tokens[\"input_ids\"]) + rejected_tokens[\"input_ids\"]\n",
        "\n",
        "        return {\n",
        "            \"pixel_values\": pixel_values,\n",
        "            \"chosen_input_ids\": torch.tensor(chosen_input_ids, dtype=torch.long),\n",
        "            \"chosen_attention_mask\": torch.tensor(chosen_attention_mask, dtype=torch.long),\n",
        "            \"chosen_labels\": torch.tensor(chosen_labels, dtype=torch.long),\n",
        "            \"rejected_input_ids\": torch.tensor(rejected_input_ids, dtype=torch.long),\n",
        "            \"rejected_attention_mask\": torch.tensor(rejected_attention_mask, dtype=torch.long),\n",
        "            \"rejected_labels\": torch.tensor(rejected_labels, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Create dataset\n",
        "dpo_dataset = DPOVisionDataset(DPO_PAIRS, tokenizer, img_proc)\n",
        "\n",
        "# Step 4: Collator\n",
        "def dpo_collate_fn(batch):\n",
        "    # Gather all fields\n",
        "    pixel_values = torch.stack([b[\"pixel_values\"] for b in batch])\n",
        "\n",
        "    # Pad chosen sequences\n",
        "    chosen_input_ids = [b[\"chosen_input_ids\"] for b in batch]\n",
        "    chosen_attention_mask = [b[\"chosen_attention_mask\"] for b in batch]\n",
        "    chosen_labels = [b[\"chosen_labels\"] for b in batch]\n",
        "\n",
        "    max_chosen_len = max(x.size(0) for x in chosen_input_ids)\n",
        "\n",
        "    def pad_sequence(seqs, pad_val):\n",
        "        out = torch.full((len(seqs), max_chosen_len), pad_val, dtype=seqs[0].dtype)\n",
        "        for i, seq in enumerate(seqs):\n",
        "            out[i, :seq.size(0)] = seq\n",
        "        return out\n",
        "\n",
        "    pad_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else 0\n",
        "    chosen_input_ids = pad_sequence(chosen_input_ids, pad_id)\n",
        "    chosen_attention_mask = pad_sequence(chosen_attention_mask, 0)\n",
        "    chosen_labels = pad_sequence(chosen_labels, -100)\n",
        "\n",
        "    # Pad rejected sequences\n",
        "    rejected_input_ids = [b[\"rejected_input_ids\"] for b in batch]\n",
        "    rejected_attention_mask = [b[\"rejected_attention_mask\"] for b in batch]\n",
        "    rejected_labels = [b[\"rejected_labels\"] for b in batch]\n",
        "\n",
        "    max_rejected_len = max(x.size(0) for x in rejected_input_ids)\n",
        "\n",
        "    def pad_sequence_rejected(seqs, pad_val):\n",
        "        out = torch.full((len(seqs), max_rejected_len), pad_val, dtype=seqs[0].dtype)\n",
        "        for i, seq in enumerate(seqs):\n",
        "            out[i, :seq.size(0)] = seq\n",
        "        return out\n",
        "\n",
        "    rejected_input_ids = pad_sequence_rejected(rejected_input_ids, pad_id)\n",
        "    rejected_attention_mask = pad_sequence_rejected(rejected_attention_mask, 0)\n",
        "    rejected_labels = pad_sequence_rejected(rejected_labels, -100)\n",
        "\n",
        "    # Cast pixel_values to the correct dtype\n",
        "    model_dtype = getattr(model, \"dtype\", torch.float16)\n",
        "    pixel_values = pixel_values.to(dtype=model_dtype)\n",
        "\n",
        "    return {\n",
        "        \"pixel_values\": pixel_values,\n",
        "        \"chosen_input_ids\": chosen_input_ids,\n",
        "        \"chosen_attention_mask\": chosen_attention_mask,\n",
        "        \"chosen_labels\": chosen_labels,\n",
        "        \"rejected_input_ids\": rejected_input_ids,\n",
        "        \"rejected_attention_mask\": rejected_attention_mask,\n",
        "        \"rejected_labels\": rejected_labels,\n",
        "    }\n",
        "\n",
        "# Step 5: Custom DPO Trainer\n",
        "class DPOVisionTrainer(Trainer):\n",
        "    # Custom DPO Trainer with multimodal input support\n",
        "    def __init__(self, *args, beta=0.1, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.beta = beta\n",
        "        self.ref_model = None  # implicit reference model\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        # Compute DPO loss; add **kwargs to accept extra args from Transformers\n",
        "        pixel_values = inputs[\"pixel_values\"]\n",
        "\n",
        "        # Forward pass — chosen\n",
        "        chosen_outputs = model(\n",
        "            input_ids=inputs[\"chosen_input_ids\"],\n",
        "            attention_mask=inputs[\"chosen_attention_mask\"],\n",
        "            labels=inputs[\"chosen_labels\"],\n",
        "            images=pixel_values,\n",
        "        )\n",
        "        chosen_logps = -chosen_outputs.loss  # negative log-likelihood\n",
        "\n",
        "        # Forward pass — rejected\n",
        "        rejected_outputs = model(\n",
        "            input_ids=inputs[\"rejected_input_ids\"],\n",
        "            attention_mask=inputs[\"rejected_attention_mask\"],\n",
        "            labels=inputs[\"rejected_labels\"],\n",
        "            images=pixel_values,\n",
        "        )\n",
        "        rejected_logps = -rejected_outputs.loss\n",
        "\n",
        "        # DPO logits = β * (chosen_logps - rejected_logps)\n",
        "        logits = self.beta * (chosen_logps - rejected_logps)\n",
        "\n",
        "        # DPO loss: -log(sigmoid(logits))\n",
        "        loss = -torch.nn.functional.logsigmoid(logits).mean()\n",
        "\n",
        "        if return_outputs:\n",
        "            return loss, {\"chosen_logps\": chosen_logps, \"rejected_logps\": rejected_logps}\n",
        "        return loss\n",
        "\n",
        "# Step 6: Training setup\n",
        "BASE_DIR  = f\"{PROJECT}/ml-fastvlm/checkpoints/llava-fastvithd_1.5b_stage3\"\n",
        "SFT_ADAPT = f\"{PROJECT}/outputs/sft_lora\"\n",
        "\n",
        "# Correct unpacking: tokenizer, model, image_processor, context_len\n",
        "tokenizer, base_model, image_processor, _ = load_pretrained_model(\n",
        "    model_path=BASE_DIR,\n",
        "    model_base=None,\n",
        "    model_name=\"FastVLM-1.5B\",\n",
        "    device_map=\"auto\",\n",
        "    dtype=torch.float16\n",
        ")\n",
        "\n",
        "# Self-check: avoid passing the wrong object type\n",
        "assert hasattr(base_model, \"named_modules\") and hasattr(base_model, \"forward\"), \\\n",
        "    f\"Unexpected base_model type: {type(base_model)}\"\n",
        "\n",
        "# Attach SFT LoRA\n",
        "model = PeftModel.from_pretrained(base_model, SFT_ADAPT, is_trainable=True)\n",
        "\n",
        "# Explicitly activate/enable adapters (compatibility across PEFT versions)\n",
        "if hasattr(model, \"set_adapter\"):\n",
        "    model.set_adapter(\"default\")\n",
        "if hasattr(model, \"enable_adapter_layers\"):\n",
        "    model.enable_adapter_layers()\n",
        "\n",
        "# Freeze base, train only LoRA; ensure lora_* weights are trainable\n",
        "for n, p in model.named_parameters():\n",
        "    p.requires_grad = (\"lora_\" in n)\n",
        "\n",
        "model.train()\n",
        "\n",
        "# Sanity check: must have trainable params\n",
        "try:\n",
        "    model.print_trainable_parameters()\n",
        "except Exception:\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total     = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"trainable params: {trainable:,} / {total:,}\")\n",
        "\n",
        "assert any(p.requires_grad for p in model.parameters()), \\\n",
        "    \"No trainable parameters detected: ensure BASE_DIR is not a merged checkpoint and SFT_ADAPT points to a LoRA directory.\"\n",
        "\n",
        "# Step 7: Training arguments\n",
        "print(\"\\nConfiguring training arguments...\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUT_DIR,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=1,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False,\n",
        "    dataloader_num_workers=2,\n",
        "    dataloader_pin_memory=True,\n",
        ")\n",
        "\n",
        "print(f\"  - Batch size: 1\")\n",
        "print(f\"  - Gradient accumulation: 4\")\n",
        "print(f\"  - Effective batch size: 4\")\n",
        "print(f\"  - Epochs: 3\")\n",
        "print(f\"  - Learning rate: 5e-5\")\n",
        "print(f\"  - Beta (DPO temperature): 0.1\")\n",
        "\n",
        "# Step 8: Create the Trainer\n",
        "print(\"any trainable? ->\", any(p.requires_grad for p in model.parameters()))\n",
        "probe = model(input_ids=torch.ones(1,1,dtype=torch.long,device=model.device),\n",
        "              labels=torch.ones(1,1,dtype=torch.long,device=model.device)).loss\n",
        "print(\"loss requires_grad? ->\", probe.requires_grad)\n",
        "\n",
        "trainer = DPOVisionTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dpo_dataset,\n",
        "    data_collator=dpo_collate_fn,\n",
        "    beta=0.1,\n",
        ")\n",
        "\n",
        "print(\"Starting DPO training\")\n",
        "\n",
        "# Step 9: Start training\n",
        "try:\n",
        "    trainer.train()\n",
        "\n",
        "    print(\"\\nDPO training complete!\")\n",
        "\n",
        "    # Save model\n",
        "    print(\"\\nSaving model...\")\n",
        "    trainer.save_model(OUT_DIR)\n",
        "    tokenizer.save_pretrained(OUT_DIR)\n",
        "    print(f\"DPO LoRA adapter saved to: {OUT_DIR}\")\n",
        "\n",
        "    # Merge weights\n",
        "    print(\"\\nMerging LoRA weights...\")\n",
        "    MERGE_DIR = f\"{PROJECT}/outputs/dpo_merged\"\n",
        "    os.makedirs(MERGE_DIR, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        merged = model.merge_and_unload()\n",
        "        merged.save_pretrained(MERGE_DIR, safe_serialization=True)\n",
        "        tokenizer.save_pretrained(MERGE_DIR)\n",
        "        print(f\"Merged full weights saved to: {MERGE_DIR}\")\n",
        "    except AttributeError:\n",
        "        print(\"Current PEFT version does not support merge_and_unload()\")\n",
        "    except Exception as e:\n",
        "        print(f\"Merge failed: {e}\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nTraining interrupted\")\n",
        "    interrupt_dir = f\"{OUT_DIR}/interrupted\"\n",
        "    trainer.save_model(interrupt_dir)\n",
        "    print(f\"Checkpoint saved to: {interrupt_dir}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nTraining failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise\n",
        "\n",
        "print(\"All done!\")\n",
        "print(f\"\\nOutputs:\")\n",
        "print(f\"  - DPO LoRA adapter: {OUT_DIR}\")\n",
        "if os.path.exists(f\"{PROJECT}/outputs/dpo_merged\"):\n",
        "    print(f\"  - Merged model: {PROJECT}/outputs/dpo_merged\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MSjlRgQ15bFR",
        "outputId": "974386f5-96e4-47c4-c809-9fc0400f0c8a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using the loaded model\n",
            "Model device: cuda:0\n",
            "Model type: PeftModelForCausalLM\n",
            "Using torchvision transforms (size=336)\n",
            "Loaded 20 preference pairs\n",
            "trainable params: 9,232,384 || all params: 1,685,101,152 || trainable%: 0.5479\n",
            "\n",
            "Configuring training arguments...\n",
            "  - Batch size: 1\n",
            "  - Gradient accumulation: 4\n",
            "  - Effective batch size: 4\n",
            "  - Epochs: 3\n",
            "  - Learning rate: 5e-5\n",
            "  - Beta (DPO temperature): 0.1\n",
            "any trainable? -> True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss requires_grad? -> True\n",
            "Starting DPO training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:55, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.751700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.703800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.716300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.766600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.706800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.708700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.703300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.705900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.728800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.698500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.693300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.705300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.707100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.676000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.696300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DPO training complete!\n",
            "\n",
            "Saving model...\n",
            "DPO LoRA adapter saved to: /content/drive/MyDrive/FastVLM_RLHF/outputs/dpo_lora\n",
            "\n",
            "Merging LoRA weights...\n",
            "Merged full weights saved to: /content/drive/MyDrive/FastVLM_RLHF/outputs/dpo_merged\n",
            "All done!\n",
            "\n",
            "Outputs:\n",
            "  - DPO LoRA adapter: /content/drive/MyDrive/FastVLM_RLHF/outputs/dpo_lora\n",
            "  - Merged model: /content/drive/MyDrive/FastVLM_RLHF/outputs/dpo_merged\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DPO Training Loss Visualisation"
      ],
      "metadata": {
        "id": "ZsPo3Tmf5W6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loss data\n",
        "steps = list(range(1, 16))\n",
        "losses = [\n",
        "    0.7517, 0.7037, 0.7175, 0.7702, 0.7095,\n",
        "    0.7123, 0.7062, 0.7095, 0.7349, 0.7031,\n",
        "    0.6963, 0.7098, 0.7155, 0.6790, 0.7030\n",
        "]\n",
        "\n",
        "# Create the chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot the loss curve\n",
        "plt.plot(steps, losses, marker='o', linewidth=2, markersize=8, label='Training Loss')\n",
        "\n",
        "# Add a trendline (moving average)\n",
        "import numpy as np\n",
        "window = 3\n",
        "moving_avg = np.convolve(losses, np.ones(window)/window, mode='valid')\n",
        "plt.plot(range(window, len(losses)+1), moving_avg,\n",
        "         linestyle='--', linewidth=2, color='red', label=f'{window}-Step Moving Average')\n",
        "\n",
        "# Mark the minimum point\n",
        "min_idx = losses.index(min(losses))\n",
        "plt.scatter([min_idx + 1], [losses[min_idx]],\n",
        "            color='green', s=200, zorder=5, label=f'Best Loss ({losses[min_idx]:.4f})')\n",
        "\n",
        "# Beautify the chart\n",
        "plt.xlabel('Training Step', fontsize=12)\n",
        "plt.ylabel('DPO Loss', fontsize=12)\n",
        "plt.title('DPO Training Loss Curve', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend(fontsize=10)\n",
        "\n",
        "# Add annotations\n",
        "plt.axhline(y=losses[0], color='gray', linestyle=':', alpha=0.5, label='Initial Loss')\n",
        "plt.axhline(y=losses[-1], color='blue', linestyle=':', alpha=0.5, label='Final Loss')\n",
        "\n",
        "# Annotate improvement percentage on the plot\n",
        "improvement = (losses[0] - losses[-1]) / losses[0] * 100\n",
        "plt.text(8, 0.76, f'Improvement: {improvement:.1f}%',\n",
        "         fontsize=12, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print statistics\n",
        "print(\"DPO Training Loss Statistics\")\n",
        "print(f\"Initial loss: {losses[0]:.4f}\")\n",
        "print(f\"Final loss: {losses[-1]:.4f}\")\n",
        "print(f\"Lowest loss: {min(losses):.4f} (Step {min_idx + 1})\")\n",
        "print(f\"Highest loss: {max(losses):.4f} (Step {losses.index(max(losses)) + 1})\")\n",
        "print(f\"Average loss: {np.mean(losses):.4f}\")\n",
        "print(f\"Loss standard deviation: {np.std(losses):.4f}\")\n",
        "print(f\"Overall improvement: {improvement:.2f}%\")"
      ],
      "metadata": {
        "id": "aZbn4L-U9eku",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "62a51b4f-2cbb-4174-df81-d19f3a588b3b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKYAAAJOCAYAAACN2Q8zAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Xd4FFXbBvB7S3rvPSQhCST0klADQuhFqhTpKFhAUYqIDRCx4IcNX8GCIChFVBABqVJCD70kJEAakE56T3bn+2PJJEt63ZT7d13RndkzM8/sDpPss+c8RyIIggAiIiIiIiIiIqJ6JtV0AERERERERERE1DwxMUVERERERERERBrBxBQREREREREREWkEE1NERERERERERKQRTEwREREREREREZFGMDFFREREREREREQawcQUERERERERERFpBBNTRERERERERESkEUxMERERERERERGRRjAxRURERPTEM888A4lEAolEgpkzZ9Z4fydOnBD3J5FIEBERUeN9EhERETUlTEwRERE1Ik8nOiQSCbS1tWFiYgI3NzcMGDAAK1euxIMHD0rdPiIiosT2hT/6+vpwd3fH7Nmzcf369TJjiI2NxYoVK9CzZ09YWlpCW1sb5ubm6NKlC5YsWYKwsLAanU9FPy4uLlV92agCxV/f2kjINVRhYWF4++230b17d1hZWUFLSwvGxsbo2LEj5s+fj9OnT2s6RCIiomZHIgiCoOkgiIiIqHJOnDiBfv36VdhOJpPh/fffx/vvvw+ptOh7qIiICLi6ula4vVwux8aNGzF9+nS19b/88gteeeUVZGdnl7vt6tWr8dZbb1V4nMqeT3EtWrSos55HO3fuFJN6bdu2xZAhQ2q0vwcPHmDnzp3i8ty5c2FsbFyjfdYFiUQiPp4xYwY2b96suWDqgFKpxMqVK7F69WooFIpy2/JPYyIiovol13QAREREVH0TJ05E165dkZqaiitXruDQoUNQKBRQKBRYsWIFYmNjsX79+jK3HzhwIAYNGgSFQoHr169j586dUCqVKCgowMsvv4yBAwfCzs4OALBjxw613jR6enqYNGkS3N3d8fDhQ2zfvh0pKSkoKCjA0qVLIZVKsXjx4nLjb9myJT7//HO1dYcPH8aRI0fE5XfeeQdmZmbisomJSbn7TE9Ph5GRUbltyjJx4sRqbVcWJyenCl8Dqnvz589X+3egq6uLMWPGwNvbGwUFBbhz5w4OHjyI1NTUOo8lLS2tQSYniYiINEYgIiKiRuP48eMCAPFn06ZNas8HBQUJrq6uam3+/fdf8fnw8HC155YvX662/bvvvqv2/MaNGwVBEIS0tDTBwsJCXG9iYiLcunVLbdsHDx4Ijo6OYhsdHR0hKiqqyue4fPlytRjCw8PLfL5FixZCYmKi8OqrrwoODg6CVCoVvvzyS0EQBOGvv/4Spk6dKrRr106wtrYWtLS0BAMDA8HLy0uYN29eif0KgiD07dtX3PeMGTPKfN2OHz8ubN++XfD19RX09PQEU1NTYfz48SXO9+n3q/gxZ8yYIa7v27evEB0dLcyZM0ewtbUVtLW1hdatWws//PBDqa/RjRs3hBEjRghGRkaCkZGRMGTIEOHq1aslXpvKKh5j8fMuT1ZWlvDFF18IPXv2FExNTQUtLS3B2tpaGDp0qLBz585St/n777+FwYMHC9bW1oJcLheMjIwENzc3YdSoUcLHH38sKBQKsW1CQoKwaNEiwdvbW9DX1xe0tLQEGxsbwcfHR5g3b55w7ty5SsV58OBBtfPz9PQUwsLCSrTLzMwUPv30U3G5vPdOEAShRYsWpf47enq7u3fvCp9//rnQunVrQVtbWxg1apTQu3fvcl/v7777Tnze2NhYyMrKEp9LTU0VPv74Y8HX11cwNjYWtLS0BCcnJ2HGjBkl/k0SERE1BkxMERERNSIVJaYEQRAuXryo1mbQoEHicxUlpvbt26f2/OrVqwVBEIRNmzaprX/vvfdKje/7779Xa7dixYoqn2NVElOWlpZC69at1doXJqbGjRuntv7pH2NjY+HGjRtq+65sYqp4YqH4j4eHh5CdnS1uV9nElJubm2BnZ1fqPguTg4UCAwMFQ0PDEu10dXWFgQMH1ktiKiYmRmjTpk25r++4ceOE/Px8cZunr6HSfgpfu+zsbKFVq1bltl26dGmlzm3IkCFq2126dKlS29VWYsrPz09tedSoUcLGjRvVrsPi14wgCGrbzJ07V1wfGhoquLi4lPma6OjoCL///nulzo+IiKih4FA+IiKiJsbHxwcdOnQQC5ifOnUKCoUCMpmswm3PnTuntmxrawsACAgIUFv/3HPPlbr9xIkT8dJLL4nLT29X2xITE5GYmIgBAwagV69eSEhIgI2NDQDA1NQUgwYNgpeXF8zMzKCtrY24uDjs3r0bUVFRSEtLw9KlS3HgwIEqH/f06dPw8fHB4MGDcfz4cZw5cwYAcPfuXezZsweTJk2q0v7CwsKgq6uLV155BXp6eli/fr1Yx2vNmjWYPXs2AEAQBMyePRsZGRnitpMnT4abmxt+//13tSGQdWnKlCm4ffu2uDx+/Hh4e3vjyJEj4jX0559/4uOPP8YHH3wAAGpD6Xx8fDBixAgUFBTgwYMHuHDhAoKDg8Xnjx8/jpCQEACqYXcvvPACHBwcEBsbi3v37uHkyZOVilOpVOLEiRPicocOHdClS5dqn3d1BAQEoE2bNhg5ciQEQYBMJsOECRPw+uuvIzMzE2lpadi/fz/GjRsHQFWXrHgR9lmzZgEAFAoFxowZI9ZXs7KywvPPPw9zc3McOnQIZ8+eRW5uLqZPn44uXbrAzc2tXs+TiIioupiYIiIiaoJatWolJqZycnKQlJQEKyurEu3Onj2L//u//4NCocCNGzewY8cO8Tk9PT0MHToUABATE6O2XYsWLUo9romJCUxMTMRaPU9vVxfeeOMNfPnllyXW//TTT8jPz8f58+dx9+5dpKWlwdHREf7+/ti0aRMA4L///kN+fj60tLSqdExfX1+cPn0aWlpayM/Ph6OjI+Lj4wEAgYGBVU5MAaoaXqNGjQIAODs744033gAAhISEiHWzLly4gJs3b4rbLF26FJ9++ikAYNGiRWjZsiWSk5OrfOyquHbtGv777z9x+a233sJnn30GAPjggw/g5+cnJqe+/vprvPfee5BKpcjJyRG3+eabb9C9e3e1/UZEREBbWxsA1Nr27dsX3377rVrb3NxcJCYmVhjr48eP1fbVunXryp5mrenevTuOHz8OXV1dtfXPPfecWGR++/btYmJqx44dYgF2Ly8v8XXav3+/mAyUyWQ4c+YMPDw8AADvvvsuOnXqhJs3byInJwfffvstvvjii/o4PSIiohpjYoqIiKgJEio5s9iRI0dK7WUjk8nwv//9Tyx83pC99957pa7/7bff8MYbb5SbwChMcFT1PF988UUxmaWlpQVXV1cxMVWdxJC9vb2YlAJUicXikpOTYWRkhEuXLqmtLz5ropmZGUaNGlXnM+o93atuxowZ4mOZTIapU6eKbZKSkhASEgIvLy/4+fnhxo0bAFRF93v06AEPDw94e3ujT58+aNeunbgfHx8f6OjoIDc3F4cOHUKbNm3Qvn17eHp6olOnTvD394eDg0OdnmdtWbx4cYmkFKDqCVX4Xu3fv19MPm7fvl2tTaHCXnmAqveUp6dnmcc8e/ZsLURORERUP5iYIiIiaoJCQ0PFx7q6urCwsKhwGx0dHTg4OMDPzw8LFixAp06dxOeeTtxERkaiffv2JfaRmpqqNrNZXSe2LC0tSz23K1euYPr06VAqlRXuIzc3t8rHdXFxUVvW0dERH1fmmFXZX/F9pqSkqK0vHGpZ1nJdSEpKUlsuHDpZ1nJhou7jjz9GWFgY/v33X2RkZJRIivbt2xf79++HgYEBHB0dsXnzZrz22mtITExEUFAQgoKCxLaGhob48ccfK+yZZmFhAV1dXbHX1J07d6p+wk88neyt7HVTVi+tPn36wN3dHffu3UNOTg7++usvdOvWDVevXgUAyOVytcTj0697eRISEirdloiISNOYmCIiImpiLl26JA7jA1Qf+KVSaaltly9fjhUrVlS4Tz8/P/z888/i8h9//FFqYur3338vsV1dMjAwKHX9rl27xGSORCLBtm3bMHLkSBgYGODAgQMYPnx4jY779NA/iURSL/szNTVVW46Pj4e5ubm4HBsbW6M4KqP48QAgLi5OLTkYFxen9ryZmRkAwNjYGAcOHMDDhw9x/vx5hIaGIigoCLt370ZWVhZOnjyJNWvWYOXKlQCASZMmYdy4cbh48SJu3ryJu3fv4vjx47h69SoyMjLwwgsvYMSIETA0NCwzVqlUimeeeQYHDx4EAFy/fh1Xr15VS7qWt21xhTW/ACAtLa3EeZalrGsUAGbOnCn2+Nu+fTvCwsLE54YOHaqW5Cv+uuvq6mLVqlVl7tfExKRSsRERETUEpf+VSkRERI1SSEhIiV4kCxcurPF+x40bp/bBeN26dWrFqgEgOjpa7cOytra22lCk+vT48WPxsYmJCSZMmCAmCJ5OnjUmXbt2VVsuPuwrOTkZf//9d53H0LNnT7XlX375RXysUCjw66+/isvm5ubisMRbt26J9bjGjx+Pd955B7/++itefPFFsf2VK1cAqHoHRUZGQktLC7169cLLL7+MtWvX4tixY2LbrKwssUB6eRYsWKC2/PzzzyMyMrJEu6ysLLFWFlAyCXj+/Hnx8SeffFLp4bLlmTFjhpgAO3bsmFj7DIBY8L5Q8dc9JycHbdq0weLFi0v8+Pn5wcfHp8axERER1Rf2mCIiImrEDh48iMTERKSlpeHq1as4ePAgCgoKxOfnzZuHQYMG1fg4RkZG+Pbbb/H8888DUA0p69q1KyZNmgR3d3c8fPgQ27dvV6uvtHr1ajg7O9f42NVRvEZTSkoKhg8fjp49e+L06dM4fPiwRmKqDd27d0e7du3EAuirVq1CeHg4nJ2d8fvvv9dK4fN9+/aVSIAV+ueff9ChQwf4+/uLSaI1a9YgLCwMbdq0weHDh9VqUC1YsEBMvCxevBgXL16Ev78/nJycYGVlhejoaLVkTGEyKDQ0FD169BBnmLS3t4dcLhd7Pj3dvjxDhgzB3Llz8cMPPwBQDefz8vLCmDFj4O3tjYKCAgQHB+PgwYNITU3F0qVLAaiG4BkZGSE9PR0A8Oqrr2Lfvn2IjY0tUWeruhwdHTFw4EAcOnRInKEQAKytrUv06hs+fDi8vLzEhPDo0aMxduxYeHt7Q6lU4v79+zh16hQiIyOxadMmdOzYsVZiJCIiqmtMTBERETViO3fuxM6dO0usl8vlWL58Od55551aO9bkyZORm5uLV199FdnZ2cjKylIb3ldIJpPh448/xuLFi2vt2FU1a9YsfPHFF4iOjgagSuAVJjVmzJih1sunsfn555/Rr18/ZGRkQBAEbN26FYCqLlX//v3FGfPKGr5ZkcePH6v1OCuusK7Sr7/+Cn9/f7Hu0x9//IE//vhDre24ceNKXH/Jyckl2hXS1dXF66+/rrYuMDAQgYGBpbYfO3YsWrZsWfEJAfjuu+9gYWGBzz77DEqlEtnZ2di2bVu522hra2PBggX46KOPAKjOfffu3QBUPdeioqLEgvc1MXv2bBw6dEht3dSpU0sM75TL5dizZw8GDx6MiIgI5OXlqc2iSURE1FhxKB8REVEjJ5PJYGRkBFdXV/j7+2PlypWIiIjAe++9V+3kRFlmzpyJ+/fv44MPPkD37t1hbm4OuVwOExMTdOrUCYsWLUJISAjeeuutWj1uVZmbm+P06dMYO3YsjI2NoaenBx8fH/z111+YOXOmRmOrqa5du+Ls2bMYPnw4DA0NYWhoCH9/f5w6dQoeHh5iu8r0JqouW1tbBAYGYu3atejRowdMTEwgl8thZWWFIUOGYMeOHfjjjz8glxd9B7pkyRIsWLAA3bt3h4ODA7S1taGjowM3NzfMmDEDFy9eFIegtWrVCmvXrsXYsWPh6ekJExMTyGQymJmZoVevXvj666+rlJQpTJYWXpu+vr4wNzeHTCaDoaEhOnTogMWLF5dIgn344Yf4+OOP4erqCi0tLbRo0QLLli3DyZMnoaenVyuv5ahRo0rU7SprCKynpydu3LiBNWvWoGfPnjAzMxP//bdv3x4vvvgidu/eLfZsJCIiagwkQm0MkCciIiKiepGXlwe5XF4i6ZiRkYG2bduK9ZPmzJkjDl8jIiIiaqg4lI+IiIioEQkKCsKzzz6LKVOmwNvbG2ZmZoiIiMCGDRvEpJRUKsW8efM0HCkRERFRxZiYIiIiImpkHjx4gE8//bTU57S1tbF+/Xp06NChnqMiIiIiqjompoiIiIgaEScnJ7z55ps4ceIEoqKikJqaCl1dXbi6uuKZZ57Bq6++itatW2s6TCIiIqJKYY0pIiIiIiIiIiLSCM7KR0REREREREREGsHEFBERERERERERaQRrTFWCUqlEdHQ0jIyMIJFINB0OEREREREREVGDJQgC0tPTYW9vD6m0/D5RTExVQnR0NJycnDQdBhERERERERFRo/HgwQM4OjqW24aJqUowMjICoHpBjY2NNRwN1RWlUomEhARYWVlVmNElehqvH6ouXjtUE7x+qCZ4/VB18dqhmuD10zykpaXByclJzKeUh4mpSigcvmdsbMzEVBOmVCqRk5MDY2Nj3iCpynj9UHXx2qGa4PVDNcHrh6qL1w7VBK+f5qUy5ZB4FRARERERERERkUYwMUVERERERERERBrBxBQREREREREREWkEa0wRERERERFRs6NUKpGXl6fpMJodpVKJ/Px85OTksMZUI6alpQWZTFYr+2JiioiIiIiIiJqVvLw8hIeHQ6lUajqUZkcQBCiVSqSnp1eqMDY1XKamprC1ta3x+8jEFBERERERETUbgiAgJiYGMpkMTk5O7LVTzwRBQEFBAeRyORNTjZQgCMjKykJ8fDwAwM7Orkb7Y2KKiIiIiIiImo2CggJkZWXB3t4e+vr6mg6n2WFiqmnQ09MDAMTHx8Pa2rpGw/qYGiYiIiIiIqJmQ6FQAAC0tbU1HAlR41aY2M3Pz6/RfpiYIiIiIiIiomaHvXWIaqa2/g0xMUVERERERERERBrBxBQRERERERFRFeTkK/DXlYd4eetlTPr+HF7eehl/XXmInHyFpkOrEhcXF3z11VeVbn/ixAlIJBKkpKTUWUzU/LD4OREREREREVElHQmKw6Jd15CWXQCpBFAKgFQCHLwdixX/3MYXz3XEAG+bWj1mRUOmli9fjhUrVlR5v4GBgTAwMKh0+549eyImJgYmJiZVPlZVnDhxAv369UNycjJMTU3r9FikeUxMEREREREREVXCkaA4zN16CRBUy8qn/p+eXYA5Wy/hh2ldMbAWk1MxMTHi4507d+KDDz5ASEiIuM7Q0FB8LAgCFAoF5PKKP+5bWVlVKQ5tbW3Y2tpWaRuiinAoHxEREREREVEFcvIVWLTrGiCIeakShCf/WbzrWq0O67O1tRV/TExMIJFIxOU7d+7AyMgI//77L7p06QIdHR2cPn0a9+/fx6hRo2BjYwNDQ0P4+Pjg6NGjavt9eiifRCLBTz/9hDFjxkBfXx8eHh7Yu3ev+PzTQ/k2b94MU1NTHDp0CF5eXjA0NMSQIUPUEmkFBQV4/fXXYWpqCgsLCyxduhSzZ8/GmDFjqv16JCcnY/r06TAzM4O+vj6GDh2Ku3fvis9HRkZi5MiRMDMzg4GBAdq0aYMDBw6I206ZMgVWVlbQ09ODh4cHNm3aVO1YqOaYmCIiqoHC+gKv/HYFr+4KwSu/XWmU9QWIiIiIqHwHbsYgLbugzKRUIQFAanYB/r0VU0HL2vX222/j008/RXBwMNq3b4+MjAwMGzYMx44dw9WrVzFkyBCMHDkSUVFR5e5n5cqVmDBhAm7cuIFhw4ZhypQpSEpKKrN9VlYW/u///g9bt27FqVOnEBUVhcWLF4vPf/bZZ/jtt9+wadMmnDlzBmlpaWrJruqYOXMmLl26hL179+LcuXMQBAHDhg1Dfn4+AGDevHnIzc3FqVOncPPmTXz22Wdir7L3338fQUFB+PfffxEcHIz169fD0tKyRvFQzXAoHxFRNZVaXyA6A4dux9VZfQEiIiIiqn0j151GQnpuuW2Ss/KqtM+3/7yJz/4NKbeNlZEO/nmtd5X2W5YPP/wQAwcOFJfNzc3RoUMHcXnVqlXYvXs39u7di/nz55e5n5kzZ2Ly5MkAgI8//hjffPMNLl68iCFDhpTaPj8/Hxs2bEDLli0BAPPnz8eHH34oPr9u3TosW7ZM7CH17bff4t9//632ed69exd79+7FmTNn0LNnTwDAb7/9BicnJ+zZswfPPfccoqKiMG7cOLRr1w4A4ObmJm4fFRWFTp06oWvXrgBUvcZIs5iYIiKqBk3VFyAiIiKi2peQnovYtJxa3WdugbLW91mewkRLoYyMDKxYsQL79+9HTEwMCgoKkJ2dXWGPqfbt24uPDQwMYGxsjPj4+DLb6+vri0kpALCzsxPbp6amIi4uDr6+vuLzMpkMnTp1qtK5FRccHAy5XI5u3bqJ6ywsLNCqVSsEBwcDAF5//XW88sorOHz4MAYMGIBx48aJ5/XKK69g3LhxuHLlCgYNGoTRo0eLCS7SDA7lIyKqIk3WFyAiIiKi2mdlpANbY91yf3TkVfv4rCOXVrhPKyOdWjuHp2fXW7x4MXbv3o2PP/4YAQEBuHbtGtq1a4e8vPJ7fmlpaaktSyQSKJXKKrUXhIoGPNatF198EWFhYZg2bRpu3ryJrl27Yt26dQCAoUOHIjIyEm+++Saio6Ph7++vNvSQ6h97TBERVVFhfYGKFK8vMKaTY90HRkRERETVUpnhdH9deYiFv1+v9D4/HddOo38DnjlzBjNnzhSH0GVkZCAiIqJeYzAxMYGNjQ0CAwPRp08fAIBCocC1a9fQsWPHau3Ty8sLBQUFuHDhgtjT6fHjxwgJCYG3t7fYzsnJCS+//DJefvllLFu2DD/++CNee+01AKrZCGfMmIEZM2bAz88PS5Yswf/93//V7GSp2piYIiKqosO348SaUhWRSoBDt+KYmCIiIiJq5Ia1s8OKf24jvYIC6BIAxnpyDG1rV1+hlcrDwwN//fUXRo4cCYlEgvfff7/cnk915bXXXsMnn3wCd3d3tG7dGt988w2Sk5MhkUgq3PbmzZswMjISlyUSCTp06IBRo0Zhzpw5+P7772FkZIS3334bDg4OGDVqFADgjTfewNChQ+Hp6Ynk5GQcP34cXl5eAIAPPvgAXbp0QZs2bZCbm4t9+/aJz5FmMDFFRFRFKVl5lUpKAarkVUp21QplEhEREVHDo6slwxfPdcScrZcgKaOkg+TJf9Y+1xG6WrJ6jlDdF198gdmzZ6Nnz56wtLTE0qVLkZaWVu9xLF26FLGxsZg+fTpkMhnmzJmDgQMHlhgCWJrCXlaFZDIZCgoKsGnTJixYsAAjRoxAXl4e+vTpgwMHDoj7VCgUmDdvHh4+fAhjY2MMGTIEX375JQBAW1sby5YtQ0REBPT09ODn54cdO3bU/olTpUkETQ/+bATS0tJgYmKC1NRUGBsbazocqiNKpRLx8fGwtraGVMrya1S2l7dexuGg2Er3mBrkbYsN07rUfWDUKPHeQzXB64dqgtcPVVdjv3ZycnIQHh4OV1dX6OrqVnn7I0FxWLzrGlKLz8z85P8menKs5czM5VIoFPDy8sKECRPw0UcfaTocqoHy/i1VJY/CHlNERFU0qI0NDt6OrVRbpQAMbss/TIiIiIiaioHeNrjwzgD8eysGh27FISU7D6Z62hjc1gZD29ppvKdUQxMZGYnDhw+jb9++yM3Nxbp16xAREYHnn39e06FRA8HEFBFRFTW2+gJEREREVLt0tWQY08mRdUQrQSqVYvPmzVi8eDEEQUDbtm1x8OBB1nUiERNTRERVVLy+QFmZqYZUX4CIiIiISFOcnJxw5swZcVkQBBQUVDzDNTUfjW9AMBFRAzDA2wafj2tf5vPGenL8OK0r6wsQERERERGVgz2miIiqqfgUt87m+ohKygIA2Jvo4r/Fz7CnFBERERERUQXYY4qIqJoC7iaIj9eMawcPSz0AQExaDvIUSk2FRURERERE1GgwMUVEVA1KpYDT9xIBAAbaMnRyNkUHB0MAgCAAlyOTNRkeERERERFRo8DEFBFRNQTFpCExIw8A0KOlJbRkUnR8kpgCgEsRSZoKjYiIiIiIqNFgYoqIqBoC7iaKj/t4WgIAOjoYiesCw9ljioiIiIiIqCJMTBERVUPx+lJ+HlYAAEsDLbQw1wcAXHuYgtwChUZiIyIiIiIilc2bN8PU1FTTYVA5mJgiIqqirLwCXIpQ9YhyNNODi4W++FxXFzMAQF6BEjcepmokPiIiIiJqetavX4/27dvD2NgYxsbG6NGjB/79998Ktzt58iT69+8Pc3Nz6Ovrw8PDAzNmzEBenqosRX0nbqRSKbS1tXH+/Hm19bm5ubCwsIBEIsGJEydq7XgTJ05EaGhore2vItnZ2TA3N4elpSVyc3Pr7biNGRNTRERVdCE8SZx1z8/DChKJRHyuMDEFABfDWWeKiIiIiGqHo6MjPv30U1y+fBmXLl1C//79MWrUKNy+fbvMbYKCgjBkyBB07doVp06dws2bN7Fu3Tpoa2tDodBc734nJyds2rRJbd3u3bthaGhYxhbVp6enB2tr61rfb1n+/PNPtGnTBq1bt8aePXvq/Hj5+fl1foy6xsQUEVEVBYQWqy/lYan2nI+Lufg4kAXQiYiIiKiWjBw5EsOGDYOHhwc8PT2xevVqGBoaluh5VNzhw4dha2uLNWvWoG3btmjZsiWGDBmCH3/8EXp6ejhx4gRmzZqF1NRUSCQSSCQSrFixAoCqB9PixYvh4OAAAwMDdOvWTa0nU2FPqz179sDDwwO6uroYPHgwHjx4UOG5TJ06FTt37kR2dra47ueff8aMGTNKtL158yb69+8PPT09WFhYYO7cucjIyBDPT1dXFykpKWrbLFiwAP3791eLs9CKFSvQsWNHbN26FS4uLjAxMcGkSZOQnp4utklPT8eUKVNgYGAAOzs7fPnll3jmmWfwxhtvVHhuGzduxNSpUzF16lRs3LhRXP/DDz/A3t4eSqVSrf2oUaMwe/Zscfnvv/9G586doaurCzc3N6xcuRIFBQXi8xKJBOvXr8ezzz4LAwMDrF69GgqFAi+88AJcXV2hp6eHVq1a4euvv1Y7TkFBAV5//XWYmprCwsICS5cuxYwZMzB69GixjVKpxCeffCLup0OHDvjjjz8qPOeaYmKKiKiKCutLSSVAz5bqiSlXC31YGmoDAC5HJkOhFOo9PiIiIiJq2hQKBXbs2IHMzEz06NGjzHa2traIiYnBqVOnSn2+Z8+e+Oqrr2BsbIyYmBjExMRg8eLFAID58+fj3Llz2LFjB27cuIHnnnsOQ4YMwd27d8Xts7KysHr1amzZsgVnzpxBSkoKJk2aVGH8nTt3houLC/78808AQFRUFE6dOoVp06aptcvMzMTgwYNhZmaGwMBA7Nq1C0ePHsX8+fMBAP7+/jA1NRX3U/ja7Ny5E1OmTCnz+Pfv38eePXuwb98+7Nu3DydPnsSnn34qPr9w4UKcOXMGe/fuxZEjRxAQEIArV65UeF7379/HuXPnMGHCBEyYMAEBAQGIjIwEADz33HN4/Pgxjh8/LrZPSkrCwYMHxVgDAgIwffp0LFiwAEFBQfj++++xefNmrF69Wu04K1aswJgxY3Dz5k3Mnj0bSqUSjo6O2LVrF4KCgvDBBx/gnXfewe+//y5u89lnn+G3337Dpk2bcObMGaSlpZXo0fXJJ59gy5Yt2LBhA27fvo0333wTU6dOxcmTJys89xoRqEKpqakCACE1NVXToVAdUigUQkxMjKBQKDQdCjVg0SlZQoul+4QWS/cJo/93Wlxf/Pp5eeslsc3tR7xvUPl476Ga4PVDNcHrh6qrsV872dnZQlBQkJCdna3+xNq1guDgUPHPyJEldzpyZOW2Xbu2RrHfuHFDMDAwEGQymWBiYiLs37+/3PYFBQXCzJkzBQCCra2tMHr0aGHdunVqn203bdokmJiYqG0XGRkpyGQy4dGjR2rr/f39hWXLlonbARDOnz8vPh8cHCwAEC5cuFBmTACEXbt2CV9++aXQr18/QRAEYeXKlcKYMWOE5ORkAYBw/PhxQRAE4YcffhDMzMyEjIwMcfv9+/cLUqlUiI2NFQRBEBYsWCD0799ffP7QoUOCjo6OkJycXOr5LV++XNDX1xfS0tLEdUuWLBG6desmCIIgpKWlCVpaWsKuXbvE51NSUgR9fX1hwYIFZZ6XIAjCO++8I4wePVpcHjVqlLB8+XK15dmzZ4vL33//vWBvby/+W/L39xc+/vhjtX1u3bpVsLOzU3v93njjjXLjEARBmDdvnjBu3Dhx2cbGRvj888/F5YKCAsHZ2VkYNWqUIAiCkJOTI+jr6wtnz55V288LL7wgTJ48udRjlPlvSahaHoU9poiIqiDgbvFhfFaltuFwPiIiIqJGKC0NePSo4p+EhJLbJiRUbtu0tBqF2KpVK1y7dg0XLlzAK6+8ghkzZiAoKAgA8PLLL8PQ0FD8AQCZTIZNmzbh4cOHWLNmDRwcHPDxxx+jTZs2iImJKfM4N2/ehEKhgKenp9o+T548ifv374vt5HI5fHx8xOXWrVvD1NQUwcHBFZ7L1KlTce7cOYSFhWHz5s1qw9kKBQcHo0OHDjAwMBDX9erVC0qlEiEhIQCAKVOm4MSJE4iOjgYA/Pbbbxg+fHi5Bd1dXFxgZGQkLtvZ2SE+Ph4AEBYWhvz8fPj6+orPm5iYoFWrVuWej0KhwC+//IKpU6eqnePmzZvF4XtTpkzBn3/+KRZF/+233zBp0iRIparUzPXr1/Hhhx+qveZz5sxBTEwMsrKyxP127dq1xPH/97//oUuXLrCysoKhoSF++OEHREVFAQBSU1MRFxendk4ymQxdunQRl+/du4esrCwMHDhQ7fhbtmxRe8/rgrxO905E1MSoJaY8LUttUzwxdTEiCTN6utR1WERERERUU8bGgINDxe2sSvly0sqqctsaG1c9rmK0tbXh7u4OAOjSpQsCAwPx9ddf4/vvv8eHH34oDsN7moODA6ZNm4Zp06Zh1apV8PT0xIYNG7By5cpS22dkZEAmk+Hy5cuQyWRqz9VWgXILCwuMGDECL7zwAnJycjB06FC1Ok+V5ePjg5YtW2LHjh145ZVXsHv3bmzevLncbbS0tNSWJRJJidpPVXXo0CE8evQIEydOVFuvUChw7NgxDBw4ECNHjoQgCNi/fz98fHwQEBCAL7/8UmybkZGBlStXYuzYsSX2r6urKz4unqgDgB07dmDx4sVYu3YtevToASMjI3z++ee4cOFCpeMvrNu1f/9+ODx1Levo6FR6P9XBxBQRUSUplQJOP6kvZaQjRwdH01LbedkZwUBbhsw8BQLDkyAIgtrMfURERETUAC1cqPqpjr17azeWSlIqlWLvG2tr60rNPmdmZgY7OztkZmYCQKkz9HXq1AkKhQLx8fHw8/Mrc18FBQW4dOmS2BMnJCQEKSkp8PLyqlT8s2fPxrBhw7B06dISCTAA8PLywubNm5GZmSkmY86cOQOpVKrWg2nKlCn47bff4OjoCKlUiuHDh1fq+KVxc3ODlpYWAgMD4ezsDEDV4yg0NBR9+vQpc7uNGzdi0qRJePfdd9XWr169Ghs3bsTAgQOhq6uLsWPH4rfffsO9e/fQqlUrdO7cWWzbuXNnhISEiMnHyjpz5gx69uyJV199VVxXvJeTiYkJbGxsEBgYKJ6DQqHAlStX0LFjRwCAt7c3dHR0EBUVhb59+1bp+DXFxBQRUSXdjk5DcpZqOtae7haQy0ofDS2XSdG5hRkC7iYiPj0XUUlZaGFhUGpbIiIiIqLKWLZsGYYOHQpnZ2ekp6dj27ZtOHHiBA4dOlTmNt9//z2uXbuGMWPGoGXLlsjJycGWLVtw+/ZtrFu3DoBqWFtGRgaOHTuGDh06QF9fH56enpgyZQqmT5+OtWvXolOnTkhISMCxY8fQvn17MfGjpaWF1157Dd988w3kcjnmz5+P7t27qw0ZK8+QIUOQkJAA4zJ6kk2ZMgXLly/HjBkzsGLFCiQkJOC1117DtGnTYGNjo9ZuxYoVWL16NcaPH1+jHj5GRkaYMWMGlixZAnNzc1hbW2P58uWQSqVlftmckJCAf/75B3v37kXbtm3Vnps+fTrGjBmDpKQkmJubY8qUKRgxYgRu376tNuwPAD744AOMGDECzs7OGD9+PKRSKa5fv45bt27ho48+KjNmDw8PbNmyBYcOHYKrqyu2bt2KwMBAuLq6im1ee+01fPLJJ3B3d0fr1q2xbt06JCcni+dkZGSExYsX480334RSqUTv3r2RmpqKM2fOwNjYuNQZE2sLa0wREVXSqbtF9QT8yqgvVci3+HC+cNaZIiIiIqKaiY+Px/Tp09GqVSv4+/sjMDAQhw4dwsCBA8vcxtfXFxkZGXj55ZfRpk0b9O3bF+fPn8eePXvEXjE9e/bEyy+/jIkTJ8LKygpr1qwBAGzatAnTp0/HokWL0KpVK4wePVqtFxEA6OvrY+nSpXj++efRq1cvGBoaYufOnZU+J4lEAktLS2hra5f6vL6+Pg4dOoSkpCT4+Phg/Pjx8Pf3x7fffqvWzt3dHb6+vrhx40a5s/FV1hdffIEePXpgxIgRGDBgAHr16gUvLy+14XTFbdmyBQYGBvD39y/xnL+/P/T09PDrr78CAPr37w9zc3OEhITg+eefV2s7ePBg7Nu3D4cPH4aPjw+6d++OL7/8Ei1atCg33pdeegljx47FxIkT0a1bNzx+/Fit9xQALF26FJMnT8b06dPRo0cPGBoaYvDgwWrntGrVKrz//vv45JNP4OXlhSFDhmD//v1qCa66IBEEgXOZVyAtLQ0mJiZITU0tM5NLjZ9SqUR8fDysra3F4nNExU364RzOh6mSTKeW9IOzhb743NPXz/mwx5j0w3kAwMSuTvhsfHuNxEwNH+89VBO8fqgmeP1QdTX2aycnJwfh4eFwdXUtM9FAFdu8eTPeeOMNpKSkVGk7QRBQUFAAuVzeaMpdZGZmwsHBAWvXrsULL7yg6XBqhVKphJeXFyZMmIBVq1ZVax/l/VuqSh6FQ/mIiCohM7cAlyOTAQAtLPTVklKl6ehkCi2ZBPkKgTPzERERERE1IlevXsWdO3fg6+uL1NRUfPjhhwCAUaNGaTiy6ouMjMThw4fRt29f5Obm4ttvv0V4eHiJXlua0PjS20REGnA+7DHyFaoOpn4epc/GV5yulgztHEwAAGGJmUhIz63T+IiIiIiIqPb83//9Hzp06IABAwYgMzMTAQEBsLSs+HNAQyWVSrF582b4+PigV69euHnzJo4ePVrpQvV1iT2miIgqIeBuovi4ovpShXxczXElKgUAcCkiCUPb2dVFaERERERE9W7mzJmYOXOmpsOoE506dcLly5c1HUatcnJywpkzZzQdRqnYY4qIqBIKC5/LpBL0aGlRqW3UCqBzOB8REREREVEJTEwREVXgYXIWwhIyAQCdnExhrKtVqe26tjBHYT1H1pkiIiIiIiIqiYkpIqIKnK7GMD4AMNHXQisbIwBAUHQaMnILaj02IiIiItIspaDUdAhEjRprTBERVUCtvpRn1Qoe+riY405sOpQCcCUyGX08K5/YIiIiIqKG50rMFWy6ugkBUQEISghCvjIfWlIteFt5w8/ZD7M6zUJnu86aDpOo0WCPKSKiciiUAk7fUyWmjHXlaP9kpr3K6upiJj7mcD4iIiKixute0j303dQXXX7ogg2XN+B63HXkK/MBAPnKfFyPu44Nlzegyw9d0HdTX9xLuqfhiIkaB/aYIiIqx81HqUjNVv3B0dvDEnJZ1fL5vq7FCqCHMzFFRDWXk5OD4OBg3L59C48TE5CSkgIDfX1ICovaEVWSIAjIzMqEgb5BrV4/WtrasLaxQ5s2bdCqVStoa2vX2r6JNGXbzW2Y/fdsKAQFAKBAWXqJhsL1Zx+eRdvv2mLTqE2Y3G5yvcVJ1BgxMUVEVI6A0ATxcVXqSxWyM9GDo5keHiZn49qDFOQWKKAjl9VmiETUjKSnp2PTpo14HPcQTvaWaOlkBaWdAXR0dcG8FFWVIAC5OTm1fv3k5eXj4aP72HXjEhxbeGD6jBnQ1dWtvQMQ1bNtN7dh6l9TIUCo9DYFygIUoABT/poCAQKeb/d8HUZIx44dw/z583Hr1i3IZI3/b+3ExER4e3vjypUrcHR01HQ4dY6JKSKichSvL9XbvWr1pQr5upjjYfIj5BYocetRKrq0MK94IyKipwiCgK1bfkFuegJemjUelhZmEAQBWZmZ0Deo3R4v1DzU9fXzKDoOO/44gF27fse0adNrff9E9eHu47uY/ffsKiWlihMgYPbfs+Hr4At3c/caxTJz5kz88ssv4rK5uTl8fHywZs0atG/fvkb7LrRixQrs2bMH165dq5V29eWtt97Ce++9p5aUOnHiBBYuXIjbt2/DyckJ7733HmbOnFnufgRBwNq1a/HDDz8gMjISlpaWePXVV/Huu+8CKPkeFPL29sbt27cBqL5Eev/997F7927Ex8ejU6dO+Prrr+Hj46N2nOXLl+PHH39ESkoKevXqhfXr18PDwwMAYGlpienTp2P58uXYuHFjTV+eBo81poiIypCek48rUckAADdLAziZ61drPz7FhvMFRiTXSmxE1PzExMQgNuYBRgx9BpYWZhVvQKRhDvY2GNCvO+6FBCMtLU3T4RBVy4t7XxSH71WXQlDghb9fqJV4hgwZgpiYGMTExODYsWOQy+UYMWJErey7sTp9+jTu37+PcePGievCw8MxfPhw9OvXD9euXcMbb7yBF198EYcOHSp3XwsWLMBPP/2E//u//8OdO3ewd+9e+Pr6is9//fXX4usfExODBw8ewNzcHM8995zY5sUXX8SRI0ewdetW3Lx5E4MGDcKAAQPw6NEjsc2aNWvwzTffYMOGDbhw4QIMDAwwePBg5OTkiG1mzZqF3377DUlJTb8cCBNTRERlOB+WhAKl6tsxP4/q9ZYCVDPzFQpknSkiqqbQ0FDoaUvh2qLpd+mnpqOVhxskyEdoaKimQyGqssvRl3Eq6lSZ9aQqq0BZgFNRp3Al5kqNY9LR0YGtrS1sbW3RsWNHvP3223jw4AESEorKTzx48AATJkyAqakpzM3NMWrUKERERIjPnzhxAr6+vjAwMICpqSl69eqFyMhIbN68GStXrsT169chkUggkUiwefPmasV58+ZN9O/fH3p6erCwsMDcuXORkZEhPn/y5El069atRAwAcP36dfTr1w9GRkYwNjZGly5dcOnSpTKPtWPHDgwcOFBtyPCGDRvg6uqKtWvXwsvLC/Pnz8f48ePx5Zdflrmf4OBgrF+/Hn///TeeffZZuLq6okuXLhg4cKDYxsTERHz9bW1tcenSJSQnJ2PWrFkAgOzsbPz5559Ys2YN+vTpA3d3d6xYsQLu7u5Yv349AFVvqa+++grvvfceRo0ahfbt22PLli2Ijo7Gnj17xGO1adMG9vb22L17d9Ve/EaIiSkiojKcqmF9qUItrQxgbqAq/HopMhlKZfW6ghNR85aeng5TE0NIpfzzjRoPXV0d6Ovpqn0gJWosNl/bDLm0dqrfyKVybLq6qVb2VSgjIwO//vor3N3dYWFhAQDIz8/H4MGDYWRkhICAAJw5cwaGhoYYMmQI8vLyUFBQgNGjR6Nv3764ceMGzp07h7lz50IikWDixIlYtGgR2rRpI/YImjhxYpXjyszMxODBg2FmZobAwEDs2rULR48exfz58wEABQUFGD9+PPr06VMiBgCYMmUKHB0dERgYiMuXL+Ptt9+GlpZWmccLCAhA165d1dadO3cOAwYMUFs3ePBgnDt3rsz9/PPPP3Bzc8O+ffvg6uoKFxcXvPjii+X2WNq4cSMGDBiAFi1aiOemUChK1NXT09PD6dOnAah6c8XGxqrFZ2Jigm7dupWIz9fXFwEBAWUev6lgjSkiojIE3FUlpuRSCbq3tKj2fiQSCbq2MMPhoDikZucjND4drW2NaytMImomlEolZExKUSMkl8ugUNRsKBSRJgREBdS4t1ShAmUBTj84XeP97Nu3D4aGhgBUCSA7Ozvs27dP/NJi586dUCqV+Omnn8REz6ZNm2BqaooTJ06ga9euSE1NxYgRI9CyZUsAgJeXl7h/Q0NDyOVy2NraVjvGbdu2IScnB1u2bIGBgQEA4Ntvv8XIkSPx2WefQS6XlxtDVFQUlixZgtatWwOAWHepLJGRkbC3t1dbFxsbCxsbG7V1NjY2SEtLQ3Z2NvT09ErsJywsDJGRkdi1axe2bNkChUKBN998E+PHj8d///1Xon10dDT+/fdfbNu2TVxnZGSEHj16YNWqVfDy8oKNjQ22b9+Oc+fOwd3dXYytMJ6n4yt8rpC9vT2uXr1a7vk3BfzrhoioFFGPsxDxOAsA0LmFGQx1apbH93XlcD4iqjtbtu2GjnlrXL56U9OhUBmysrKx6tN1OHn6Qq3s79iJsxg8agasWnSFhXNndO83Frv+OlDhdi/Oexs65q2hY94auhZeMHfuCl0LL7TrNlStXUpqGmbMXQwbV1+06jQAm7b+UWJfl6/ehKlDR4RHPqyVcyJqaIISgmp1f7fjb9d4H4U1k65du4aLFy9i8ODBGDp0qNowuHv37sHIyAiGhoYwNDSEubk5cnJycP/+fZibm2PmzJkYPHgwRo4cKdZMqk3BwcHo0KGDmJQCgF69ekGpVCIkJATm5uaYPn06hgwZUmoMCxcuxIsvvogBAwbg008/xf3798s9XnZ2dq3M/KlUKpGbm4stW7bAz88PzzzzDDZu3Ijjx48jJCSkRPtffvkFpqamGD16tNr6rVu3QhAEODg4QEdHB9988w0mT55crR7Penp6yMrKqu4pNRpMTBERlSLgXtEwvj41qC9VqHidqYssgE5E1OxkZefgozX/w6nTF2u8r19++xPDx70AuVyOD99/E5+sfAu9e/jgwaPKfbjU0dHGpg1r8PP6z7Dhqw/x8/rP8MnKJWpt3n5/DU6duYj3356PYYOfwStvvI9zF4rq4wiCgIVvr8ZrL09n3TNqkpSCEvnK/FrdZ74yH0pBWaN9GBgYwN3dHe7u7vDx8cFPP/2EzMxM/PjjjwBUw/u6dOkiJq8Kf0JDQ/H8888DUPWgOnfuHHr27ImdO3fC09MT58+fr/H5VcVPP/2Es2fPlhrDihUrcPv2bQwfPhz//fcfvL29y62zZGlpieRk9b+vbW1tERcXp7YuLi4OxsbGpfaWAgA7OzvI5XJ4enqK6wp7ckVFRam1FQQBP//8M6ZNmwZtbW2151q2bImTJ08iIyMDDx48wMWLF5Gfnw83NzcxtsJ4no7v6Z5qSUlJsLKqfkmRxoJD+YiIShEQmig+rkl9qUJt7I2hry1DVp4CgeFJEASBU7sTUZMlCAJycnKhp1fzb7BJXUTUQyx4axVenTMVX3z6brX2IZfL8fyEZyEIArIyM6FvYFDid9KBwyfw8YrFmDppNADg1u0Q7D90HD26dQYAbN/1D6IeRmPpmy/V6HyIGiqpRAotqVatJqe0pFqQSmq3b4hEIoFUKkV2djYAoHPnzti5cyesra1hbFx26YhOnTqhU6dOWLZsGXr06IFt27ahe/fu0NbWrvHQWy8vL2zevBmZmZlir6kzZ85AKpWiVatWajF07ty5RAwA4OnpCU9PT7z55puYPHkyNm3ahDFjxpR5LkFB6r3bevTogQMH1HuRHjlyBD169Cgz7l69eqGgoAD3798XhxgWTtxQWEOq0MmTJ3Hv3j288ELZsy0aGBjAwMAAycnJOHToENasWQMAcHV1ha2tLY4dO4aOHTsCANLS0nDhwgW88soravu4desWnnnmmTKP0VSwxxQR0VMKFEqcua9KTJnqa6Gtg0mN9ymXSdHZWTW9e2xaDh4mZ9d4n0RE5Xlx3tswd+qMqIfRGD3pJZg7dYZrmz5Y/9NvAIBbQSEYPGoGzBw7waN9f+z44x+17bds+ws65q0RcDYQr775AexadoOlcxfMfmUpklNS1dp6duiP0ZNewuFjAejRfxxM7Dvgx807AQBhEQ8weeYC2Lp1g6lDR/gNnIgDh0+I28bFJ0Lfqg0++uzbEucQcjcMOuat8d2Pv4rrUlLTsGjZx2jZ9hkY2baDV5dB+L+vf4RSWdQLISLqIXTMW+OLdRux/qff0KrTAJg6dMSwsbPx4GEMBEHAx59/B7c2fWFi3wHjpryKpOSUEsc/eOQU+g+bAjPHTrBw7oxRE19CUPDdUl/nR9FxGD91HsydOsPBoweWvv+Z+OEuIuohHDxUH4Y+WvM/cSjdqk/XAVAVK74TGoaY2Phy31MA+HHTTigUCix/53UAQEZGJgSh6pNqKBQKpKWVXZA8OzsHpqZFH2rNzEyRlaWaxjwzMwvvrVyLVe8vhKGhQVm7IGr0vK28a3V/bazb1Hgfubm5iI2NRWxsLIKDg/Haa68hIyMDI0eOBKAqHG5paYlRo0YhICAA4eHhOHHiBF5//XU8fPgQ4eHhWLZsGc6dO4fIyEgcPnwYd+/eFXsGubi4IDw8HNeuXUNiYiJyc3PLjCU7O7tEz6z79+9jypQp0NXVxYwZM3Dr1i0cP34cr732GqZNmwYbGxuEh4fj3XffLTWG7OxszJ8/HydOnEBkZCTOnDmDwMBAtRpUTxs8eLBYWLzQyy+/jLCwMLz11lu4c+cOvvvuO/z+++948803xTbffvst/P39xeUBAwagc+fOmD17Nq5evYrLly/jpZdewsCBA9V6UQGqoufdunVD27ZtS8Rz6NAhHDx4EOHh4Thy5Aj69euH1q1bizP3SSQSvPHGG/joo4+wd+9e3Lx5E9OnT4e9vb3asMCsrCxcvnwZgwYNKvPcmwompoiInnL9YSrSc1SFLnu5W0ImrZ2eTV1dzMTHgRGsM0VEdU+hUODZ5+bC0cEOH69YjBZODnjjrVXYsu0vjHxuDjp3bIvVyxfB0NAAs195u9RaQW+8tQohoWF4b+l8TJk0Ctt3/YPnps4rkQwJvReB6XMWw/+Znlj7yTvo0K414uIT8cyQyTjy32m89MJkrHz3DeTk5mLc86/i731HAAA21pbw6+WDP/YcLHHsP3b/C5lMhnGjhgBQ1WkaMGIatu/aiymTRuGLT99Fz26d8N6HX2DJu5+W2H7HH/vw/cbteHXOVLzx6iwEnA3ElNlvYPnqr3D4WAAWLXgRL0yfgP0Hj+Pt99eobfvbzr8xetJLMDDQx+rli7Bs8asIDrmHfsOmICJK/XVSKBQYMf5FWJiZ4tMP34JfTx989b9N+OmX3wEAVhbmWLd2BQBg1IiB2LRhDTZtWIPRI1UfNh7FxKFD92F4f9UXFb6n/508i1Yebjh45CTc2vSFhXMX2LXsjhWrv1ZLzpUnKysbli26wtrVB27t+mPBkg+RkZGp1qZL53b45rvNuHs/AoePBeDwsQD4dGkPAPjsy+9hb2eDKRNHVep4RI2Vn7Nfrc7K19upd433c/DgQdjZ2cHOzg7dunUTZ70r7FWjr6+PU6dOwdnZGWPHjoWXlxdeeOEF5OTkwNjYGPr6+rhz5w7GjRsHT09PzJ07F/PmzcNLL6l6P44bNw5DhgxBv379YGVlhe3bt5cZS2hoqNjzqvDnpZdegr6+Pg4dOoSkpCT4+Phg/Pjx8Pf3x7fffivGGBISgvHjx5eIQSaT4fHjx5g+fTo8PT0xYcIEDB06FCtXriwzjilTpuD27dtqdaBcXV2xf/9+HDlyBB06dMDatWvx008/YfDgwWKbxMREtfpVUqkU//zzDywtLdGnTx8MHz4cXl5e2LFjh9rxUlNT8eeff5bZWyo1NRXz5s1D69atMX36dPTu3RuHDh1Sm1nwrbfewmuvvYa5c+fCx8cHGRkZOHjwoFqtrL///hvOzs7w8/Mr89ybColQna9Ympm0tDSYmJggNTW13O6Q1LgplUrEx8fD2tqaU3E3c18dDcVXR1XfiH82rh0m+jhXuE1lrp+z9xLx/E+qoreTfZ3wydj2tRc0NVq891Bl/f3334iLCsLMqWPFdYVDsf74+zDmvvYOzh7bhS6d2gFQ9eTZun0PVr3/Jt56MtwqJTUNLt59kJOTi60/rsVzY4cBUPVMat9tGN57ax7ef/s1AKoeU3Pmv4POHdvg1KEd4h/Ua7/ZiHdWfI4/fvsOI4f2B6DqMRX5IBr/7PoRg/yL/oBe/M4nWLfhF/x34Df06t4FgKqHTxe/URAEAXeuHIFUKsVPm3di3sLluHJ6L9p4F30r3bHHCNjYWOLQns0AgE/+bz0+//pHXDjxFzxauojt3vtwLb5Y9zNCrh6Fk6MdIqIeolXHAbCyNMftS4dgYmwEAHh/1RdY8+UPaN+2Nc799wfkctUHzulzFmH3P4eRGHkZOjrayMjIRMt2/TB21GCs/2qVeJy4+ES08x2KcaOHiOsLX+fly17HO0teFdt2e2YspFIJzv33JwAg8XEyHDx6qL3GhQrjnTZ5NH76X8kEW3FWLbpCJpMhKzsbi157Ee3btsKefUew4499WPLGHHz0waJyt3/vw7UQBKBTe28olAr8e+gEtv+xDz27dcaRf7aIr8mtoBCMmvASHkarZogaM3IQtm36CpEPotGp5wgc2rMZ3Xw6lnusQt/+sA0duvZR65lAjVtj/92Vk5OD8PBwuLq6lls0+0rMFXT5oUutHffy3MvobNe51vbXWAmCgIKCAsjl8lorbbFkyRKkpaXh+++/r5X9NQTdu3fH66+/LtYGa4jK+7dUlTxK47uLEBHVsYC7tVtfqlAnZzPIn/S+usiZ+Yionsya9pz42NTEGJ7urjAw0MP4MUWzsLXycIOpiXGpPaZemD5B7Vvel2ZPglwux8EjJ9XaubRwVEtKAcDBoyfh07m9mJQCAENDA7w4YwIiox4h+M49AMDokYMgl8uxa/e/YrvbQaEIDrmH50YXxfnn3wfRq3sXmJmaIPFxsvjTv29PKBQKnD53Se34Y0cNEZNSAODTpQMAYPJzI8UETOH6vLx8PIpRFaI9duIsUlLTMHHccLXjyGQy+HRpj5OlFDCfM2uS2nKv7l0QHlG52epcnB2Rm3SnwqQUAGRkZiE5JRUfvP0alr/zOsY8Oxi//PB/GOTvh2+/34r09LKH5wHARx8swurlizB+zFBMGDsc//tiBVa++wbOXriCv/4+JLZr690Kty8dwtlju3D70iHs+OUbSKVSLH3/M4wZOQjdfDpizz+H0dVvFDw7+mP1mv9Va0ghUUPW2a4z+jj3qXGvKblUjj7OfZiUqkPvvvsuWrRoUemeow1dYmIixo4di8mTJ2s6lHrBxBQRUTGp2fm49iAFAOBubQh709Jn7agOPW2ZWK/qfkImHmeUPWafiKg26OrqwMrSXG2dibEhHOxsS3xLbWJsWKJ2FAC4t1Qv+GpoaAA7GytERj1SW+9SysxsUQ+i4enhWmJ9K09VUdnIh9EAAEsLM/Tr0x1//F2UmNq1+1/I5XJxuBsA3AuLxOFjAXDw6KH2M3SMqm5HfMJjteM4O9qVOEcAcHIofX3Kk/O/G6aadn3wqJkljnX0+BkkPHWc0l5nM1PjUl/PmiosKD9h3HC19RPHDUd2dg6u3Qyu8j5ff2UGpFIp/jt5Tm29rq4OunRqB3c31TVw/NR5HD1+Bh99sAghd8Mw9cVFeO3l6fhh3Wp8//N2bNn2VzXPiqjh2jhqI2QSWY32IZPIsHHUxlqKiEpjamqKd955p1H24CuNpaUl3nrrrWYzWVKDnJXvf//7Hz7//HPExsaiQ4cOWLduHXx9fUtt+8wzz+DkyZMl1g8bNgz79+8Xl4ODg7F06VKcPHkSBQUF8Pb2xp9//gln54qH6BBR83Hu/mMolKpvfP08LGt9/76u5mLi61JkMga3sS1/AyKiGpDJSv8wVdb6mvR40dPVqfa2ADBh7DDMmf8Ort8MRod2Xvjj73/Rr093WFoU1edTKpXwf6YnFr3+Yqn78HB3UVsu6wOKTFb6+sLzF558475pwxrYWJf8XSCXq79+Zb2edcHO1gr37kfCxko9LitLCwBAckpalfepp6cLC3NTJJWTSFMoFFi0bDWWLJgDB3sbfPz5d+jh2xEzpowDALw4YwK2/7FPXCZqKtzN3bFp1CZM+WsKBFT9HimBBJtGbYK7uXsdREfUNDS4xNTOnTuxcOFCbNiwAd26dcNXX32FwYMHIyQkBNbW1iXa//XXX8jLyxOXHz9+jA4dOuC554q6rd+/fx+9e/fGCy+8gJUrV8LY2Bi3b98udzwxETVPAXcTxMd9anEYXyEfF3P8cCoMABAYnsTEFBE1ePfuR+IZv+7ickZGJmLiEjB4YJ8Kt3V2skfo3fAS60Pvqu6DLRztxXXPDh+AeQuXY9du1fTed+9F4K035qpt5+bijMzMLPg/07Na51JZbi6qLy6tLM1r7Vi19aV35w5tcO9+JB7FxMHNxUlcXzijn1WxRF5lpadnIvFxsloS8Gnf/7wdGRmZeHP+bABAdGw87GyL/ja3s7NGdHRclY9N1BhMbjcZAgTM/ns2FIICBcqCCreRS+WQSWTYNGoTJrdrHsOxiKqrwfVz++KLLzBnzhzMmjUL3t7e2LBhA/T19fHzzz+X2t7c3By2trbiz5EjR6Cvr6+WmHr33XcxbNgwrFmzBp06dULLli3x7LPPlproIqLmrbC+lJZMgm5u5hW0rrquLTgzHxE1Lhu3/I78/Hxx+fufd6CgoACDB1ScmBoyoC8Cr9zA+YtXxXWZmVn46Zff0cLZAV6ti3oQmJoYY2D/3vhjz0H8/tcBaGtr4dnhA9T2N370EJwPvIbDxwJKHCslNQ0FBRV/WKyMgf17w9jIEGu+/F7t3AslJFb9/q2vpxoanpKaXuK5/Px83AkNE5NL5Rk/RlWwfvOvf4jrlEoltmz7C+ZmJujcsWjq8vvhUbgfHiUu5+TkllqD6pO130EQBAz2L33mp6TkFKz6dB0+WfkWdJ/0jLOxskBIsaTjnZAw2NrUfk9joobi+XbP49art9DTUZWsLqvuVOH6Xk69cOvVW0xKEVVCg+oxlZeXh8uXL2PZsmXiOqlUigEDBuDcuXPlbFlk48aNmDRpEgwMDACoflHv378fb731FgYPHoyrV6/C1dUVy5Ytw+jRo+viNIiokYp8nImopCwAQNcW5tDXrv1bpJmBNjysDXE3PgO3otOQmVsAA50GdSsmIlKTl5ePIaNnYdzoIQi9F47vN25Hr+5dxBn5yrPkjTn4/a/9eHbCXMybOw1mZib4dcceREQ+xM4nxbSLe27MMMx8aQm+37gNA/v3hqmJ+iw+C197AfsO/ocxk1/B9Mlj0KljG2RmZuF2cCj+2nsYodeOldvrp7KMjQ2xbu1yzHp5Kbo9MxYTxg6HpYUZHjyKwb+HT6JHt074es0HVdqnnp4uvFq54489/8LD3QXmpiZo4+WBNt6eeBQThw7dh1VqVr5nh/mjX98eWPPlD0h8nIz2bVtj7/6jOHP+Mv73xUro6GiLbYeOngkACL3+HwAgNj4B3fqOxYRxw9HKwxUQVAXqj/x3BoP8/TByWOmz5q34+Bu09fbEuNFDxHVjnh2E1Z9/h/mLVqCFkz1++mUn1nz0dpVeEyJNq+rwZXdzd5ycdRJXYq5g09VNOB11GrcTbiNfmQ8tqRbaWLdBb6femNVpFgudU7NQW8XmG9SnocTERCgUCtjY2Kitt7GxwZ07dyrc/uLFi7h16xY2biwqLBcfH4+MjAx8+umn+Oijj/DZZ5/h4MGDGDt2LI4fP46+ffuW2E9ubi5yc4uKEqelqcbqK5XKJlPln0pSKpUQBIHvcTN2IqTom+reHhZVuhaqcv10dTHD3fgMKJQCLkcmobc7v2FuznjvocoqvFaKf5BSLQN4UvdEEIrVSRKK2hT35Nky1pfc/svP3sOOP/bhw0/WIT8/HxPGDscXn76j3vapbQtZW1ng+L/b8N7Ktfjux1+Rk5uLdt6t8Ne27zB00DMl2g8f3A96erpIz8jE+NFDSzyvp6eLI3u34LMvf8Bfew/i1517YGxkCPeWLnh/6XwYGxkUe01KxiS+JmWtL/b6TRw3ArY21vi/r3/EF+s2IjcvD/Z2NujVvQumTx5byddZff36rz/EwqWrseTdT5CXl49335oHby+PUo9fnl1b1mHFx1/jjz3/Yuv23fB0d8WmDWsw+bmR6uf1VAwmxkYYOqgvjp04g1937IFCoYBrC0d8+N4beHP+bEgkkhLHvxUUik1bdyHg8E6159p4eeKHdR/jozXfIiMjEy/NnowXpj9XavyF9zje55qOxv67SyaTQSKRICEhAZaWllUuMO1l6oU1/daIy0pBCalEPdGenZ1dK7E2Vfn5+WozvlLjIggC8vPzER8fD4lEArlcXuJ+UJX7g0RoQPO6RkdHw8HBAWfPnkWPHj3E9W+99RZOnjyJCxculLv9Sy+9hHPnzuHGjRsl9jl58mRs27ZNXP/ss8/CwMAA27dvL7GfFStWYOXKlSXWh4aGwsjIqMR6ahqUSiVSU1NhYmLSZGZzoKp5a+89nApTFX7d/LwXWlvrV3rbqlw/B+88xoqDEQCAF7rZYU4P+3LbU9PGew9V1sGDB5GWEI5pk54V1wmCgJzcXOjq6NT6zD3bdv2D+YtW4tg/W9Cpg3et7psahrq8fopb//Pv8PDuCj+/0ocKUuPTFH535eXliR0QqP4plcpGe+2QiiAIkMvlMDY2LnUSkPT0dHh6eiI1NRXGxsal7KFIg+oxZWlpCZlMhrg49cKJcXFxsLUtv0BwZmYmduzYgQ8//LDEPuVyOby91f+g8vLywunTp0vd17Jly7Bw4UJxOS0tDU5OTrCysqrwBaXGS6lUQiKRwMrKijfJZihfocSVR9cAAOb6Wujt3QJSaeX/SK/K9eOvbSQmpoIS8ljvrpnjvYcqy8TEBLlpOtB/Uq4AKOwJI4G+gX6tJxa0tVW1hHT19NSOSU1HXV4/xeno6MDU1JS/75qQpvK7S6FQlFpHjuqWUqlEUlISzM3NG/X109zJZDLI5fIyf39UZbK5BpWY0tbWRpcuXXDs2DGx/pNSqcSxY8cwf/78crfdtWsXcnNzMXXq1BL79PHxQUhIiNr60NBQtGjRotR96ejoQEen5JTHUqmU/3CaOIlEwve5mboRlYKMXAUAoLeHVYmpwCujstePk7kBHEz18CglG9cepEAhAFplTF1OzQPvPVQZUqkUEomkxB+AEglKXV9Thbsr3D81TXV1/agfg/e4pqgpvK9SqZTDyTRAqVQiIyMD+vr6jfr6ofJV5b1tUIkpAFi4cCFmzJiBrl27wtfXF1999RUyMzMxa9YsAMD06dPh4OCATz75RG27jRs3YvTo0bCwsCixzyVLlmDixIno06cP+vXrh4MHD+Kff/7BiRMn6uOUiKgRCAhNEB/7edR9zScfFzM8upaN7HwFbj1KRSfnmhfrJSIiaogaUOUQIiJqgBpcYmrixIlISEjABx98gNjYWHTs2BEHDx4UC6JHRUWVyLyFhITg9OnTOHz4cKn7HDNmDDZs2IBPPvkEr7/+Olq1aoU///wTvXv3rvPzIaLG4dTdRPGxn4dVnR+vq4s59lyLBgAERiQxMUVEFdLS0kJefkG9HW/682Mx/fmx9XY8arry8wugra1dcUMiImqWGlxiCgDmz59f5tC90no5tWrVqsJvYmbPno3Zs2fXRnhE1MSkZOXhxsMUAICnjSFsTSo/Hrq6fF3NxccXw5Mxt0+dH5KIGjlra2tcPJuGrKxs6OvraTocokpJSExCVg7rKRIRUdk4oJOImr2z9x9D+SS3XR+9pQDA3coQpvqqmgaXIpOgVHKYAxGVz8vLC5Bq4fK1W5oOhahSBEFA4JUb0NU3RsuWLTUdDhERNVBMTBFRsxdwt6i+VB/P+klMSaUSdG2h6jWVkpWP+wkZ9XJcImq8DAwM0LP3Mzh59jqOnTiLpOQUTYdEVCpBEBCf8BgHDp/AlRv30a//QMjlDXKgBhERNQD8DUFEzZogCDgVqqovpS2XwtfFvIItao+vqxmOBscBAC5GJMHDxqjejk1EjdPAgaoP+GdPn8K5S7ehqy2HQqGAjo42JBJ+30hVIwhK5ObmQkdHp1avn/z8fOTkKaBnYIyhI8agR48etbZvIiJqepiYIqJmLTwxE49SsgEAvi7m0NOW1duxfYolwQLDkzClW4t6OzYRNU4SiQT9+/eHn58f7t27h4SEBCQkJMDU1JRTblOVKZVKpKSk1Pr1o62tDSsrK7i5ubGnFBERVYi/KYioWQtQm43Psl6P3cbeBLpaUuTkKxEYkVyvxyaixk1LSwteXl5o1aoV4uPjYW1tzcQUVZlSqeT1Q0REGsffQETUrBWvL1Vfhc8Lacul6ORkBgB4lJIt9twiIiIiIiJqLpiYIqJmK69AiXP3HwMALA110Nq2/ms8+biqD+cjIiIiIiJqTpiYIqJm60pUMjLzFABUw/ikUkm9x1C82PrFCCamiIiIiIioeWFiioiaLfVhfPVbX6pQJ2dTyJ4kxC4xMUVERERERM0ME1NE1GwVL3ze210ziSkDHTna2hsDAELjMpCcmaeROIiIiIiIiDSBiSkiapaSMvNw81EqAKC1rRGsjXU1FkvXYsP5LkVydj4iIiIiImo+mJgiombpzL1ECILqcR/P+p2N72k+xRJTgRzOR0REREREzQgTU0TULDWE+lKFfFzMxMcXOTMfERERERE1I0xMEVGzIwiCWF9KRy5V67GkCRaGOmhpZQAAuPUoFVl5BRqNh4iIiIiIqL4wMUVEzc79hAzEpOYAALq5WUBXS6bhiABfV1VyrEAp4NqDFM0GQ0REREREVE+YmCKiZudUaNFsfH00PIyvkFqdqXAWQCciIiIiouaBiSkianbU60tptvB5IRZAJyIiIiKi5oiJKSJqVnILFDgfpkr8WBvpwNPGUMMRqTia6cHWWBcAcCUqGQUKpYYjIiIiIiIiqntMTBFRs3I5MhnZ+QoAqt5SEolEwxGpSCQS+DypM5WVp8Dt6DQNR0RERERERFT3mJgiomalcDY+AOjj2TDqSxXydTETH3M4HxERERERNQdMTBFRs3IqtKi+VC/3hpWYKuwxBTAxRUREREREzQMTU0TUbCRm5IpD5NrYG8PSUEfDEanztDaCsa4cAHApIhmCIGg4IiIiIiIiorrFxBQRNRtn7hUN42sos/EVJ5VK0PXJ7HyPM/NwPyFTwxERERERERHVLSamiKjZOBVarL6UR8MaxlfIx4XD+YiIiIiIqPlgYoqImgVBEBBwV1VfSldLii7FCo03JL6uxQqghzMxRURERERETRsTU0TULITGZSA+PRcA0N3NAjpymYYjKl07B1PoyFW35ovsMUVERERERE0cE1NE1CwU9pYCGmZ9qULacik6OpkCAB4mZyMmNVuzAREREREREdUhJqaIqFk4dbfh15cq5OtavM5UsgYjISIiIiIiqltMTBFRk5eTr8CFsMcAADsTXbhbG2o4ovJ1LV4AnXWmiIiIiIioCZNrOgCqezn5Chy4GYPDt+OQkpUHU31tDGpjg2Ht7KCr1TDr7BDVpksRycgtUAIA/DwsIZFINBxR+To7m0IqAZQCZ+YjIiIiIqKmjYmpJu5IUBwW7bqGtOwC8YOuVAIcvB2LFf/cxhfPdcQAbxtNh0lUpxpLfalCRrpa8LY3xq1HaQiJS0dqVj5M9LU0HRYREREREVGt41C+JuxIUBzmbr2E9OwCAKqkVPH/p2cXYM7WSzgSFKehCInqR2F9KYkE6OXesOtLFfJ5MpxPEIBLkew1RURERERETRMTU01UTr4Ci3ZdAwRAKKON8OQ/i3ddQ06+ov6CI6pH8ek5CI5JAwC0czCBuYG2hiOqHF8XFkAnIiIiIqKmj0P5qkChUEAQBLE+jVKpFJelUqlaOwCQSqV13lYQBCiVqto5MllRvaj91x8hIzsPAiQACuvpCJBCgPDkkWoNkJadh/03HmJsZ+cK91uVGEo7j4bW9unXXaFQQKlUVqqtpt/72rhOGkLbun7vA0LjxXW93S3E2GpynZT1uhfeI8rbb1mvz9NtCwugS6HEpfDEat97mvN7Xxf3iNq4Tkpr+/S9p7y2vEc0vLaavufX5N7D975x3CPqqm3hvae4hvDeN7frpKxzbghty3uPnr738L1veveIuvpdUnj9FMfrpOG8n7V5j6gsJqaq4OzZsxg4cCC0tVU9Lh48eIDw8HDY2dmhVatWYrszZ85AqVSie/fu0NXVBQBER0fj3r17sLa2hre3t9j2/PnzyM/Ph4+PDwwMDAAAsbGxCA0NhaWlJdq2bSu2DQwMRE5ODjp37gxjY2MAQHx8PIKDg2FmZoYOHToUxXA+EB20HuNugSUyBB0AgIkkB66yJGQK2rirKKqz4yl/jHOnz+AZF0NYWFgAAJKTk3Hjxg0YGhqia9euYtubN28iJSUF3t7esLa2BgCkpaXh6tWr0NPTQ7du3cS2t27dQlJSElq3bg1bW1sAQGZmJi5dugRtbW307NlTbBscHIyEhAR4eHjAwcEBAJCdnY2LFy9CLpejd+/eYtvQ0FDExsbCzc0Nzs7OAIC8vDycO3cOEokEffv2Fdveu3cP0dHRcHFxgYuLCwDVP5LTp08DAPr06SP+owoPD0dISAhatWoFDw8PAKp/aAEBAQCA3r17Qy5X/ZOJiopCREQE7O3t4enpKR7v9OnTEAQBPXr0gI6O6nV/+PAhwsLCYGtri9atW4ttz507h4KCAvj6+kJfXx8AEBMTg7t378LKygpt2rQR2164cAF5eXno2rUrDA0Nxff+zp07MDc3R/v27cW2ly5dQnZ2Njp16gQTExMAQEJCAoKCgmBqaoqOHTuKba9evYqMjAy0b98e5uaqREhSUhJu3rwJIyMjdOnSRWx7/fp1pKWloW3btrC0VA2HS01NxbVr16Cvrw9fX1+19z45ORleXl6wsVHVMEtPT8eVK1egq6uL7t27i22DgoKQmJgIT09P2NvbAwCysrIQGBgILS0t9OrVS2x7584dxMfHw93dHY6OjgCA3NxcnD9/HlKpFH369BHb3r17FzExMTgXXiCu6+lqJr6fzzzzjLg+LCwMDx8+hLOzM9zc3ACobsiFbf38/MQbbUREBKKiouDo6Ah3d3e19z4zMxMDBgwQ29bkHmFlpAM3SwPop9yDEBuLpNT2sDBV/buvjXvE5cuXkZWVhY4dO8LU1BQA8PjxY9y6dQvGxsbo3Lmz2PbatWtIT09Hu3btmv094sGDB3ByckLLli0B1M494tGjR7h58ybc3NzUfj/wHqFS1/cIV1dXtGjRAgCQn5+Ps2fPAqj9e0Rh2549e9bq3xEXLlxASkoK+vbtCyMjIwC8RzS1e0Rd/h0RHBwMuVwuvr4A7xGFmso9oq4+a1y5cgUJCQno2bOn+N7zHuECoGndI+rq74gbN25AEATY2dmJbXmPaFr3iMuXLyMhoajOb0U4lK+Jys4rgFDWGL6nCAKQU8ChfNT0CIKAGw9TAQD62jJ0dDLVbEBV1NXFDACgUAq49ShVw9EQERERERHVPokgVDZ90XylpaXBxMQESUlJMDU1bRRd517eEoijwbEoEMofygcAMokSA71ssX5a12bdbbKgoABxcXGwsbERv61oDl0sNd22Lt/7oEepGPm/MxAggX9ra/w0o2udda/Nz89HfHw8bG1txX3X9P3cdekBlv5xDQDwxoBWeH2AZ5X321zf+8bUBb+0e09ZbXmPaJzXSVnnXBtta3rv4Xvf8O8RddlWoVAgISEBtra2YvuG8N43t+ukvPdI023LOufS7j1875vePaKufpcUFBQgPj4ednZ2dX7vaQrXSW28R5p479PS0mBubo7U1FSxh1VZOJSvCmQymfgGAFB7k55u97S6aiuRSEpdP6itHQ4GxT/dGkpISrRVCFIMbmendm5l7bcqMZR2Hg29rUwmU9umKvsF6ve9r43rpCG0rcv380xY0pM6a4Cfh2WdxQCozrm27xG+ruZQPkkiB0Yml9u2rP021/e+IbYFyn7vn773lNe2KvutbFteJ3XbFqjb97Mm9x6+9w2nLaCZvyMqc+/hdVK3bYHG+Tfk0/cevvd12xZonNdJWW2ffo7XSdltgcb53pe2viylH5EavWHt7GCsJy8lDaVOAsBET46hbe0qaEnU+ATcTRQf+3laldOyYXI214e1kap+wJXIZBQolBVsQURERERE1LgwMdVE6WrJ8MVzHQEJykxOSZ78Z+1zHaGrVflsJlFjkJ2nwMWIJACAg6ke3CwNNBxR1UkkEvi4mgMAMvMUuBObruGIiIiIiIiIahcTU03YAG8b/DCtK4z1VCM2pU9lqLTlUvw4rSsGeNtoIDqiunUxIgl5BaoeRoXD+BojXxdz8fHF8CQNRkJERERERFT7mJhq4gZ62+DCOwPw5cQOGORti07FZiXztDViUoqarIDQoulJ+zTCYXyFCmfmA4DACCamiIiIiIioaWHx82ZAV0uGMZ0cMaaTIwBgyFencCc2HTcfpiI+PQfWRroajpCo9hXWl5JKgJ4tLTQcTfW1tjWGkY4c6bkFCIxIEmfIICIiIiIiagrYY6oZ8veyFh+fuJNQTkuixikuLQchcap6TO0dTWGqr63hiKpPJpWgy5NeU4kZeQhPzNRwRERERERERLWHialmyN+raPje0eA4DUZCVDeKz8bXx8NSg5HUDp9idaY4nI+IiIiIiJoSJqaaoY6OprA0VPUgCbibiJx8hYYjIqpdAXeLegL6NeL6UoV8XYsnppI1GAkREREREVHtYmKqGZJKJejXSjWcLztfgXNhjzUcEVHtUSoFnH7SY8pQR46OxQr+N1btHU2gLVfdrtljioiIiIiImhImppqp4sP5jnE4HzUhQTFpeJyZBwDo0dICWrLGf5vTkcvQwdEEABD5OAvxaTkajoiIiIiIiKh2NP5PbFQtfh6W0H7ygf2/4HgIgqDhiIhqx6liw/iaQn2pQsXrTF1krykiIiIiImoimJhqpgx05OjR0gIAEJ2ag6CYNA1HRFQ7AkKLCp/7eTT++lKFfIrXmQpnYoqIiIiIiJoGJqaaMX8va/HxseB4DUZCVDuy8gpwKVKVtHEy10MLC30NR1R7urQwg0SienyRBdCJiIiIiKiJYGKqGevfunhiinWmqPG7EJaEfIVqWKqfhxUkhZmcJsBYVwtetsYAgDuxaUjLyddwRERERERERDXHxFQz5mimj9a2RgCA6w9TWVCZGr2mWl+qkO+T4XyCAFyOZK8pIiIiIiJq/JiYauYGFJud7787HM5HjVvAXVV9KZlUgh4tm15iqquLmfiYdaaIiIiIiKgpYGKqmSteZ+oo60xRIxadko178RkAgI5OpjDR09JwRLXPt9jMfIGcmY+IiIiIiJoAJqaauQ6OprA01AEAnL6XgJx8hYYjIqqe03eLz8bX9HpLAYC1sa5Y0P36g1T+eyUiIiIiokaPialmTiqVoH9rKwBATr4SZ+8nVrAFUcNUvL6Un4eVBiOpWz5Pek3lKZS48TBVw9EQERERERHVDBNTBP9idaY4nI8aI4VSwOl7qqSqka4cHRxNNBxR3eFwPiIiIiIiakqYmCL4eVhCW666FP4LjocgCBqOiKhqbkenIiUrHwDQq6Ul5LKme2vzcWViioiIiIiImo6m++mNKk1fW46eLS0AALFpObgdnabhiIiqJqB4fSnPpllfqpCLhT4sDbUBAJcjkqFQMpFMRERERESNFxNTBEB9ON8xDuejRuZkaFF9qT5NuL4UAEgkErHOVHpuAe7EMpFMRERERESNFxNTBADwb20tPj52J06DkRBVTUZuAa5EJgNQ9SZyMtfXcER1z6d4nalwDucjIiIiIqLGi4kpAgDYm+rB284YAHDjYSri0nI0HBFR5Zy//xgFT4azNeXZ+IrzVaszlazBSIiIiIiIiGqGiSkSDfAq6jX13x0O56PGIeBu0TA+P4+mXV+qkJedMQx15ABUBdA5YQERERERETVWTEyRSL3OFIfzUeNQWPhcJpWgx5Mi/k2dTCpB5xZmAID49FxEJWVpOCIiIiIiIqLqYWKKRO0cTGBlpAMAOH0vETn5Cg1HRFS+B0lZCEvMBAB0djaFka6WhiOqPz5PElMAcJF1poiIiIiIqJFiYopEUqkE/VuphvPl5Ctx5l6ihiMiKt/pYtdoc6kvVchHrc4UE1NERERERNQ4MTFFavyL1Zk6Gsw6U9SwNcf6UoU6OplCSyYBwALoRERERETUeDExRWp6e1hCW666LP67E8eiytRgKZQCTj+pL2Wip4X2jqaaDaie6WrJxHMOT8xEfDpn0iQiIiIiosaHiSlSo68tR68nBaTj0nJx61GahiMiKt2NhylIyykAAPR2t4RMKtFwRPXPx6VoON9l9poiIiIiIqJGiIkpKqH47HxHOTsfNVCFs/EBzW8YXyFf12IF0FlnioiIiIiIGiEmpqiE4nWmjt1hYooapuL1pXo308RUF2dzSJ50FGMBdCIiIiIiaoyYmKIS7Ez00MbeGABw61EaYlNZu4YalvScfFyJSgEAuFkZwNFMX7MBaYiJvhZa2RgBAIKi05Cek6/hiIiIiIiIiKqGiSkqVfHhfOw1RQ3NufuPoVCqCvP38bDScDSaVVhnSilATNYRERERERE1FkxMUakGFB/OFxyvwUiISjpVbBhfc60vVcjHtagAemA4h/MREREREVHjwsQUlaqtvQmsjXQAAGfuJSI7T6HhiIiKFBY+15JJ0N3NQsPRaJZvsZn5WGeKiIiIiIgaGyamqFRSqUQsgp5boMSZe4kVbEFUPyIfZyLycRYAoLOzGQx05BqOSLNsTXThZK4HALj2IAW5BUwiExERERFR48HEFJXJvzXrTFHDU9hbCgD6eDbv+lKFCutM5RYocetRqoajISIiIiIiqjwmpqhMvdwtoSNXXSLHguOhfFJsmkiTAlhfqgSfYsP5LoYnazASIiIiIiKiqmFiisqkpy1Db3fVB//49FzcimZPDNKsAoUSZ+89BgCY6Wuhjb2JhiNqGHxYZ4qIiIiIiBopJqaoXP5eRcP5jnJ2PtKw6w9TkJ5bAEDVo08mlWg4ooahpZUBLAy0AQCXIpLYu5GIiIiIiBoNJqaoXP1bW4uPjwWzzhRp1qlQ1pcqjUQiQVcXMwBAWk4BQuPTNRwRERERERFR5TAxReWyNdFFWwdjAMDt6DTEpGZrOCJqzlhfqmxqw/nCOZyPiIiIiIgaByamqEJqs/NxOB9pSGp2Pq49SAEAeFgbws5ET7MBNTC+rsUKoEewADoRERERETUOTExRhQZ4FU9McTgfaca5+4koLJ3k58FhfE/ztjOGvrYMgKrHlCCwzhQRERERETV8TExRhdo6GMPGWAcAcOb+Y2TlFWg4ImqOTt0tqi/l58lhfE+Ty6To7KyqMxWbloOHyRx2S0REREREDR8TU1QhiUSC/k+G8+UVKHG6WIKAqD4IgoBToar6UtoyKboVG7ZGRYrXmbrIOlNERERERNQIMDFFlTLAq/jsfKwzRfUr4nGW2AOoq4sZ9LXlGo6oYfJxNRMfB0YwMUVERERERA0fE1NUKb3cLaGrpbpcjt2Jh1LJ+jVUf9Rn42N9qbJ0cjKDlkwCgIkpIiIiIiJqHBpkYup///sfXFxcoKuri27duuHixYtltn3mmWcgkUhK/AwfPrzU9i+//DIkEgm++uqrOoq+adLVkqG3u6quT2JGLm48StVwRNScnAotVl/Kg/WlyqKnLUNbBxMAwP2ETDzOyNVwREREREREROVrcImpnTt3YuHChVi+fDmuXLmCDh06YPDgwYiPL3342F9//YWYmBjx59atW5DJZHjuuedKtN29ezfOnz8Pe3v7uj6NJsmfs/ORBuQrlDh3X5WYsjDQhredsYYjatiK15kKjEjWYCREREREREQVa3CJqS+++AJz5szBrFmz4O3tjQ0bNkBfXx8///xzqe3Nzc1ha2sr/hw5cgT6+volElOPHj3Ca6+9ht9++w1aWlr1cSpNjn9r1pmi+nc1KgWZeQoAQG8PS0ilEg1H1LCpJ6Y4nI+IiIiIiBq2BlVBOC8vD5cvX8ayZcvEdVKpFAMGDMC5c+cqtY+NGzdi0qRJMDAwENcplUpMmzYNS5YsQZs2bSrcR25uLnJzi4bApKWliftRKpWVPZ0mx9JQG+0cTHDzUSqCYtLwMCkT9qZ6mg6r1iiVSgiC0Kzf44boVGhRErS3u0WDfX8ayvXT2dlEfHwxPEnj8VDFGsq1Q40Trx+qCV4/VF28dqgmeP00D1V5fxtUYioxMREKhQI2NjZq621sbHDnzp0Kt7948SJu3bqFjRs3qq3/7LPPIJfL8frrr1cqjk8++QQrV64ssT4hIQE5OTmV2kdT1d1JHzef1Jf6OzAM4zo0nULUSqUSqampEAQBUmmD60zYbP0XFCM+bm2KMof1alpDun7cLHQR9jgHQdGpiHgYA31tmUbjofI1pGuHGh9eP1QTvH6ounjtUE3w+mke0tPTK922QSWmamrjxo1o164dfH19xXWXL1/G119/jStXrkAiqdwQoGXLlmHhwoXiclpaGpycnGBlZQVj4+Zd3+bZrjr48bwqUXDxUTZeGWhdwRaNh1KphEQigZWVFW+QDURKVh6C47MAAJ42hmjj5qjhiMrWkK6f7i3jEfb4ARQC8DBHC70dWTC+IWtI1w41Prx+qCZ4/VB18dqhmuD10zzo6upWum2DSkxZWlpCJpMhLk69sHZcXBxsbW3L3TYzMxM7duzAhx9+qLY+ICAA8fHxcHZ2FtcpFAosWrQIX331FSIiIkrsS0dHBzo6OiXWS6XSZv8Pp62DKexMdBGTmoNzYY+RU6CEvnaDuoxqRCKR8H1uQM6FJUMQVI/7ejb8X1wN5frp5maBbRcfAAAuRaagj2fTSSA3VQ3l2qHGidcP1QSvH6ouXjtUE7x+mr6qvLcN6irQ1tZGly5dcOzYMXGdUqnEsWPH0KNHj3K33bVrF3JzczF16lS19dOmTcONGzdw7do18cfe3h5LlizBoUOH6uQ8mjKJRIL+T4qg5xUoEXA3UcMRUVMWcDdBfOzn0XSGjda1rsULoIezADoRERERETVcDa6ry8KFCzFjxgx07doVvr6++Oqrr5CZmYlZs2YBAKZPnw4HBwd88sknattt3LgRo0ePhoWFhdp6CwuLEuu0tLRga2uLVq1a1e3JNFEDvGzw24UoAMCx4DgMblN+bzai6hAEQUx8asul8HU1r2ALKuRgqgcHUz08SsnG1QfJyCtQQlveoL6HICIiIiIiAtAAE1MTJ05EQkICPvjgA8TGxqJjx444ePCgWBA9KiqqRJewkJAQnD59GocPH9ZEyM1Oj5YW0NWSIidfif/uJECpFCCVVq5+F1FlhSVm4lFKNgCgm6s5dLVYwLsqfFzM8OhaNnLylbgVnYrOzmaaDomIiIiIiKiEBpeYAoD58+dj/vz5pT534sSJEutatWoFobAQTSWUVleKKk9XS4be7lY4GhyHxIxcXH+Ygk780Eu1LCC0+DA+Fu+uKh9Xc+y5Fg1ANZyPiSkiIiIiImqIOLaDqmWAV1Ex5WPB8RqMhJqqU8Xql7G+VNX5Fq8zFZGswUiIiIiIiIjKxsQUVUthAXQAOBocV05LoqrLLVDg3P3HAABLQx20tjXScESNj7u1Icz0tQAAlyKToFRWvlcpERERERFRfWFiiqrF2lgXHRxNAAB3YtPxMDlLwxFRU3IlMgXZ+QoAQB8PS0gkrGFWVRKJBF1aqHpNpWTl415ChoYjIiIiIiIiKomJKao2fy8b8fF/dzicj2pPwN1i9aU8WV+qunxdi+pKXQxP0mAkREREREREpWNiiqrN36v4cD4mpqj2BBSrL9XLnYmp6vJRqzPFxBQRERERETU8TExRtXnbGcPeRBcAcP7+Y2TkFmg4ImoKHmfk4lZ0KgDAy84Y1ka6Go6o8WrrYAI9LRkA1cx8REREREREDQ0TU1RtEokE/Z/0mspTKHG62PArouo6c/8xhCd1uvt4sLdUTWjJpOjkbAoAiE7NwaOUbM0GRERERERE9BQmpqhGiteZOsbhfFQLAkKL1ZfysNJgJE2D2nA+9poiIiIiIqIGhokpqpEebhbQ11YNFToeEs8p6alGBEEQ60vpaknR1cWsgi2oIsUTUxdZZ4qIiIiIiBoYJqaoRnS1ZOj9pDh1YkYerj1M0WxA1Kjdi89AbFoOAKCbqwV0n9RHourr5GwKmVQCgD2miIiIiIio4WFiimpsgNpwvjgNRkKN3alis/H5sb5UrTDQkaOtvTEA4G58BpIz8zQcERERERERUREmpqjG+rW2hkTVIYN1pqhGAooV0O/jyfpStUWtzhSH8xERERERUQPCxBTVmJWRDjo4mgIA7sSm42FylmYDokYpt0CB82GPAQA2xjrwsDbUcERNh49rUWLqUmSyBiMhIiIiIiJSJ9d0ANQ0DPCyxrUHKQBUvaZm9HTRaDzU+FyOSEZOvhKAajY+SWE3PKqxri2KishfZJ0pImoGcvIVOHAzBodvxyElKw+m+toY1MYGw9rZsX4hERFRA8MeU1Qr+rcuqjN1lHWmqBpOFhvGx/pStcvCUActrQwAALcepSIrr0DDERER1Z0jQXHw/fgoFv5+HYeDYnE+PAmHg2Kx8Pfr8P34KI4G8e8UIiKihoSJKaoVXnZGsDfRBQBcCEtCRi4/+FLVBIQWFT4vnOmRao/vk+F8BUoB16JSNBsMEVEdORIUh7lbLyE9W/V3iFKA2v/TswswZ+slHGFyioiIqMFgYopqhUQigf+T2fnyFEoEhCZUsAVRkYT0XATFpAEA2joYw8JQR8MRNT3FC6BfZAF0ImqCcvIVWLTrGiAAQhlthCf/WbzrGnLyFfUXHBEREZWJiSmqNf5e1uLjo5ydj6rgzL2i3lJ+HpyNry5wZj4iauoO3IxBWnZBmUmpQgKA1OwC/Hsrpj7CIiIiogowMUW1prubBfS1VQVFj4fEQ6Gs6E9DIpVTrC9V5xzN9GD3ZLjt1agU5CuUGo6IiKh2Hb4dB2kl582QSoBDtzicj4iIqCFgYopqja6WTEwqJGXm4doDTktPFRMEAQF3VT2m9LRk6FJsBjmqPRKJROw1lZWnQFB0moYjIiKqXSlZeajsd2JKAUjJzqvbgIiIiKhSmJiiWlVYZwrgcD6qnJC4dCSk5wIAuruZQ0fOabzrio9LUdKPw/mIqKkx1deuUo8pUz3tug2IiIiIKoWJKapV/VtbQ/Lkj8JjwewiTxUrPhtfH0/Wl6pLPq7FCqCHMzFFRE3LoDY2VeoxNbitTcUNiYiIqM4xMUW1ytJQBx2dTAEAoXEZeJCUpdmAqMFTry/FxFRd8rQ2gomeFgDgUmQyBIF14Iio6RjWzg7GuvIK20kAmOjJMbStXd0HRURERBViYopq3YBiw/nYa4rKk5OvEHvu2JvooqWVgYYjatqkUgm6PqnhlZSZh/sJGRqOiIio9uhqyTCyg33FDSXA2uc6QleLQ8eJiIgaAiamqNb5e1mLj4/dYZ0pKltgRBJyC1Szw/l5WEEiqWRxEKo29eF8nKCAiJqO1Ox8HLgZo7autJpTX03oiAHeHMZHRETUUDAxRbWulY0RHEz1AADnwx4jPSdfwxFRQ1U4Gx8A+HlaajCS5qNwZj4AuMQC6ETUhHz7310kZ6n+5hjWzg5fTuyAQd626O5mDmdzfbHdo9RsTYVIREREpWBiimqdRCLBgCe9pvIVglrygai4U6Gq+lISCdCrJRNT9aGdgwl05Kpb/0UmpoioiYhIzMTmsxEAAB25FO8Ma40xnRyxYVoX7JjbA1tm+4qTs2w+E4HcAoXmgiUiIiI1TExRnfAvVmfqKOtMUSni03JwJzYdANDewQRmBpy2uz5oy6XiBAUPk7MRw54DRNQEfHwgGPkK1YQOc/zc4Gimr/a8i6UBBnvbAgDi03Ox91p0vcdIREREpWNiiupENzdzGGirioqeCEmAorLzN1OzoTaMj7Px1StftTpT7DVFRI3b2fuJOByk+hLMykgHrzzTstR2c/q4iY9/DAjjzKREREQNBBNTVCd05DL08VQlG5Iy83A1ikWWSV3A3QTxsZ8Hh/HVp+J1pgLrYzhfejoQFARERwNKZd0fj4iaDYVSwKp9weLyksGtYKAjL7VtlxZm6PJkZtLQuAycDE0otR0RERHVLyamqM70b100O9/RYM7OR0WUSgGn76l6TBloy9DJ2UzDETUvnVuYiTNVBdbGzHxKJfD4ccn1s2cD1taAsTHQpg3g4ADo6QHu7oC/v+r5FSuAQ4dqHgMRNUt/XH6A4Jg0AEAbe2OM7+xYbvs5fuq9poiIiEjzSv9KiagW9GttDYkEEATgWHAc3h7aWtMhUQMRHJuGxIw8AECPlhbQljNHXp8MdeRoY2+Cm49SERKXjtSsfJjoa5W/UWYmEBam/nP/vur/4eGAszNw927JbRKe6pGQl6fa7v79onUzZwKDB6u3Gz4cMDQEWrRQ/Tg7Fz02Man2uRNR05GRW4DPD4WKy++P8Ia0MOtehoHeNnCx0EfE4yycufcYtx6loq0D7ylERESaxMQU1RlLQx10cjLFlagU3I3PQNTjLDhb6Fe8ITV5rC+leT4u5rj5KBUAcCkyCf6trIDYWMDMTNWrqdA//wBz5gBxFUxiEBEBKBSATFa0rmVLVS+pli1ViaXkZCAqCoiMBNLSitq1aKG+r5wc4MCBso9lYlKUrFq1CujYsei5ggJAKlX9EFGT9t3xe0jMyAUADGlji+5uFhVuI5NK8KKfG97bcwuAqtfU15M61WmcREREVL5q/eV+7NgxfP7552rrfv75Zzg7O8PGxgZvvvkmFApOw0ucnY9Kx/pSGpKdrar1tG8fxp/+E8uPfo+f/liJDoN7AgYGqiTS6dPq2xgZlZ+U0tNTDdMbNkxVS6q41auBhw+BkyeBrVuBffuAGzeA1FRVkuraNWDvXmDiRPXtHj0q/zxSU1X72bcPyM9Xf+6ff1QxeXgAAwaohguuXAls3gwcP67q4ZWXV/7+iajBe5CUhZ9OhwMAtGVSLBtW+V7Z4zo7wvzJTLD7bsTgUQpnJyUiItKkavWYWrFiBVoU+4b75s2beOmll9C+fXu4u7vjm2++ga2tLZYuXVprgVLjNMDLBp8fCgEAHLsTh9m9XTUcEWladp5CrGvkYKoHV0sDDUfUhAgCEB+v6nFUvBeSIKgSNcWGz3k/+Skh7KmaK25ugJ2dqteTm1vRT+GyjQ0gKWPoTFnrAcDUVPXToUPJ51q2VJ3Dgweq3lWRkUU9rQp/HjxQJaWe7m0VGalKPN27p/opK6527YDr19XX37ypeq5FC1VCjogarM8O3kFegWoyhVm9XNDCovK/S/S0ZZjWvQW+PnYXCqWATafD8d6IUu+IREREVA+qlZgKDg7GuHHjxOWtW7fC2NgYAQEB0NfXx8svv4wtW7YwMUXwtDGEo5keHiZn40JYEtJy8mGsW0EtG2rSLoQ/Rp5C9WGij6cVJOUlL6ik3FzVsLniNZ6KP87KAkaPBnbvLtpGIgF0dMrepUwLWh7ukLZ0A2xt1Z90dlbNplffdHRURdLd3Ut/XqlUDT20emooqIEB0LatKkH1dA+uQoIAaJVyH1q4EDh6VPXY1LT0+lbOzqokn7l5ye2JqF5cikjCvhsxAAALA23M61/GfaIc03q0wIaT95FboMT2i1F4zd8DJnr8+4SIiEgTqpWYyszMhLGxsbh88OBBDBkyBPr6qvpBPj4++PXXX2snQmrUJBIJBnjZYPPZCBQoBZwKTcCI9vaaDos0qHh9qT4cxleSIACJiaokk6+veq+jFSuADz9UtSnP072eAMDHR1WbqViPp/VRAjbHShBvaI5tc3uiR8uK67M0GFIpYF/KvWTOHNWPIAApKSV7WhX2vmrfvuS2kZFFj1NSVD9P96oCgA8+UA0PLJSbC3z2mXoSy9ER0Nau4UkS0dOUSgGr9gWJywsHeVbrCy9LQx2M6+KIbReikJmnwI6LUXipb8vaDJWIiIgqqVqJKScnJwQGBmL27Nm4d+8ebt26hUWLFonPJyUlQaecb+epefH3ssbmsxEAgGPB8UxMNXOF9aWkEqBny2aamMrLUyVBSpvhLiysqKdPdLRqGF0hS8uyk1La2oCLi2oYXNu2JZ/fvLnEKqvLDxG3S5V4uRSR1LgSUxWRSFSF3M3MSh8uWJoZM4DQ0KJk1oMHqmLqT3t6+OCDB8Dy5SWPb29fssfV889zVkGiGthz7RGuP1RN3NDKxggTuzpVe18v9HbF9otREARg05kIzOrlylliiYiINKBaiakpU6bgww8/xKNHj3D79m2YmZlh1KhR4vOXL1+Gp6dnrQVJjVs3VwsY6siRkVuA4yHxKFAoIZfxD7/mKDY1B6FxGQCADk6mMNFvosMmBEFV3Pv+fVUyybVYbbWICFXySKmseD9hYeqJqTZtVL2oSqv3ZG+vPiNeJfi6FA1HuxiRVKVtm6R331VfVihUwwWfrnPVubN6u+I9rQoJgqqI+6NHwNmzRevHjFFPTO3YAcn27TCytQUWLQL4u5OoTFl5BVhzMERcfm+EV43+nmhpZYgBXjY4EhSH2LQc7LsRjbGdHWsjVCIiIqqCaiWm3n33XeTl5eHAgQNwdnbG5s2bYWpqCkDVW+rEiRNYsGBBbcZJjZi2XIo+npY4cDMWKVn5uPogBT4urM/SHKnPxmdVTstGJjwc+OUXmF66BEl0tCqhlKr6Rh/vvQesWlXU1sGh7P3I5apeNYWJpyf3VVG/fsCFC7UWtpO5HqyNdBCfnosrkclMGj9NJlO9Xw4OQM+eZbfr0AHYs6f0Iu3x8UXtdHQAa2v1bS9ehGTvXhgAEI4cUc02aGhYF2dD1Oj9cCoMsWk5AAD/1ta18ntkbh83HAmKE/c/ppMDax8SERHVs2olpuRyOVavXo3Vq1eXeM7c3ByxsbE1DoyaFv/WNjhwU3VdHA2OY2KqmWpS9aUEAfjvP2DdOmDvXkgFAbqltXu63pOWFjB8OKCnV3KGO0dHVXKqnkgkEvi4mmP/jRhk5ikQHJOOdo4cZlZllpZAsV7DarKzi2YXTEpS1cYq7sED8aEkPBxYsgRYv74OgyVqnGJSs7HhpGpmUblUgneGe9XKfru2MEMnZ1NcjUrBndh0BNxNRB/PJvTFCRERUSNQq5+AwsLCkJubCy+v2vljgZqOfq2tIZUASkFVZ2rZUF4jzY1SKeD0PVViykhHjg5OppoNqKZefBH4+ecSqwWZDBJn56KEk59fyW337q2HACvH10WVmAJUw/mYmKplenqq4XllDdHbsQPKa9cAPz9Is7OBDRuAsWOBgQPrNUyihu7zgyHIyVcNgZ7WowVaWtVOz0KJRIK5fm545bcrAIAfA8KYmCIiIqpn1Rqz8c0332DSpElq62bNmgUPDw+0bdsWXbt2RXzx4QvU7JkbaKOzsxkA4F58BiIfZ2o4Iqpvt6PTkJSZBwDo0dICWo19yNjw4UWPHRygXLUKCWfOQMjMVPWSOnoU+P57YOpUzcVYCcV7LwaGs85UvZPJgE6dkP7BB0XrZs8uGgpKRLj2IAV/XX0EADDR08ICf49a3f+gNrZwNlfNLB1wNxFB0Wm1un8iIiIqX7U+Gf7000+wsbERlw8dOoRffvkFc+fOxbp16xAWFoaVxafSJgLg71V0zRwNZuKyuTlVvL5UY/k2WhCAI0eAZ58FDh1Sf+7ZZ4Hx44GdO1U1pt55Bwo3N9VQvUakla0RjHRVnWcvRSZBKGvWP6pT2dOnQ/D3Vy08fAi8+aZmAyJqIARBwEf7gsTlNwZ4wFRfu1aPIZNK8KJf0SQVPwWEldOaiIiIalu1ElORkZFqw/V+//13uLq6Yv369Xj11Vcxf/58HDhwoNaCpKZhgFdR0d9jwXEajIQ0oXjh8wZfXyojA/juO9UseIMGAf/8A3zzjXobuRzYtQuYMKHRJaOKk0kl6NpC1ZsxMSMP4YnszagRUimEn34CjIxUy5s2Afv2aTYmogZg/80YXIpMBgC4WRlgavcWdXKc8V0cYfpkpti916MRk5pdJ8chIiKikqqVmHr6G/XDhw9j6NCh4rKLiwsLoFMJ7taGYlf5i+FJSMvJ13BEVF8ycwtw+ckHC2dzfbSwMNBwRGW4d0/VU8XBAZg3DwgOLnru1i1VwqoJ6lp8OF8Eh/NpjLMz8OWXRctz5gBpHFJEzVdOvgKfHLgjLr833KvOhoHra8sx7UnSq0ApYPOZiDo5DhEREZVUrd/unp6e2L17NwDVML7o6Gi1xNTDhw9h+vQ059TsSSQS9G+t6jVVoBRwMiShgi2oqbgQ/hj5ClVC26+h9ZZSKoHDh4ERI1QFqr/6Sj0Z0KePqmfU/fuAYe0U221ofF2LElMXw5M1GAlh9mxg2DDAxAT49NOiHlREzdDG0+F4lKLqueTnYYl+rawr2KJmpvdwgbZc9afxtgtRSOcXaERERPWiWompxYsX48iRIzAzM8PIkSPh5eWFwYMHi8//999/6NixY23FSE3IgGJ1pjicr/k4FZooPvbzaGD1pW7dAgYPBvbvV9WUAgBdXeCFF4Br14CTJ1W1pOS1Oolpg9Le0UT8MMYeUxomkQA//aS6LmfMUC0TNUPx6Tn47vg9AIBUArw33BuSOv73YGWkg3GdHQAA6bkF2Bn4oE6PR0RERCrVSkxNmjQJhw4dwsyZM/Huu+/i+PHjkD/50JaUlARzc3PMnTu3VgOlpsHX1RxGOqpr5XhIAgoUSg1HRPWhsL6UTCpBT3cLzQaT/VTdkPbtgV69VI+dnVW9VB4+VCUHOnSo//g0QEcuQ0dHUwBAVFIW4tJyNBtQc2dnBzg6ajoKIo1aeygUmXkKAMBkX2e0sq2f3oMv9HYTH/98Ohz5/DuFiIiozlW7C8DAgQMxcODAEuvNzc3x119/1Sgoarq05VL08bTC/psxSM3Ox+XIZHRz03CigurUo5Rs3E9QFdTu5GQKY10NFApXKlWz6q1bBzx4ANy4od4TZdUqICUFGDmySfeMKo+PqxkuPuktFRiRhBHt7TUcEam5eBHw8WEPKmoWbken4vfLqt5KRjpyLBzoWW/Hdrc2xAAvaxwNjkd0ag7234jB6E4O9XZ8IiKi5qhGFSQzMzNx4MABrF+/HuvXr8eBAweQmckZnah8/sVn57sTr8FIqD6cLjYbX70P40tLU82m17q1qm7Pv/+qhkgdP67erl8/YMyYZpuUAgCf4gXQwzmcr8FISQFmzgS6dQO2b9d0NER1ThAErNoXJI6sfs3fHRaGOvUawxy/ol5TP5wKKzHpDxEREdWuaiem1q1bB3t7e4wcORLz5s3DvHnzMGLECNjb2+Pbb7+tzRipienXyhrSJ1/6H2WdqSbv1N1i9aU866nweUgI8Nprqtn1FiwA7t4teq5FC850VorOLczEzjgXI1gAvcE4cQL45RfV4/nzgehojYZDVNcOB8XhfJgqOd7CQh8zerrUewy+rubo4GgCAAiKScPZ+4/rPQYiIqLmpFqJqS1btmDBggVo27Yttm3bhmvXruHatWvYvn072rVrhwULFmDr1q21HSs1EWYG2ujSwgwAEJaQifBE9rJrqhRKAWfuqRJTxrpytHcwqdsDHjoEDBmi6iH17bdARkbRc/36Abt3q2bXGz26buNohIx1teBlawwAuBObhtRszkbVIIweDUyapHqcnAzMnVtUpJ+oicktUODjA8Hi8rKhXtCRy+o9DolEgjl91HtNERERUd2pVmLqiy++QJ8+fXDq1ClMnDgR7du3R/v27TFx4kScPHkSfn5+WLt2bW3HSk2IP2fnaxZuPUpFSpYqwdHL3RJyWY1GD1fs119VyalCenrASy8BN28C//2n+pAvq/8POY2Fr6tqOJ8gAFci2Wuqwfj2W8DWVvV4/35g82aNhkNUV7acjUTk4ywAQDdXcwxuY1PBFnVnSBtbOJrpAQBOhv4/e/cd19TdPXD8k7BBhmxFENyIe+C21llrtdPW1lprrd3rZ/t0Pt172d1aW7tsq9Y+Vq1774FbEcQBCIIMQYbMkOT3x4UATpBxM8779YomN/cmB7i5Sc493/PNJC4tX7VYhBBCCGt3Td8S4+LiGD9+PHaX+IJnZ2fH+PHjiYuLq3NwwnoNr9JnSobzWa/Nxxqwv1Rs7MUz7D35pPJ/aCh88gmkpMDMmdCpU/0+t5Wq2meqohG6MAM+PjBrVuXtZ55RmvgLYUWyzpfw5Xpl2LVGA6/e1BGNis3+7e20TB0YZrr9wxapmhJCCCEayjUlpjw9PUlMTLzs/YmJiXh4eFxrTMIGtPZrQksfVwB2J56TYUNWakvV/lJt66G/lF4PS5fCyJHQsSP8+Wf1+yMjYd06OHECnn0Wmjat+3PakN5hlb+vPZKYMi9jx8Lkycr1vDyYOlWG9Amr8tnaY+QXlwEwvmcLOjX00O8auLNXMJ4uykyyiw+kkJ5XrHJEQgghhHW6psTUmDFj+Oqrr5g3b95F982fP5+vv/6asWPH1jk4Yb00Gg3DOigl+nqDkU1VKmuEdcgv1rEvSRkOFubrRrC367U/WE4OzJgB7dopX9DXrFGWf/XVxV/Ohw6V4XrXyN/dmdDyhPHB5FyKdXqVIxLVfP650tAflNfA99+rGo4Q9eVYej5/7koCwNXRjudGtlc5IoWbkz339g0BQKc38vO2RHUDEkIIIazUNSWmPvjgA1q1asXEiRMJCgpiyJAhDBkyhKCgIO655x5atWrFBx98UN+xCitTdTif9JmyPjvjsykzKEmja66WiomBRx9Vvow/+yzEVxlK0aqVUkGil+RJfepVPpyvVG/g0OlclaMR1Xh5wU8/Vd5+7rnqrwkhLJDRaOTtpTGUv13w+PVt8PdwVjeoKib3C8WxvD/iH7tOcb6kTOWIhBBCCOtzTYkpPz8/9u3bx4wZM+jcuTPp6emkp6fTuXNnPvvsM/bu3YuvbyNNCy8sVu8wb9yd7QHYGJdJmd6gckSiPm05Xof+UjExMGIEREQoPaIKCyvvGzkS/v0Xjh2D//s/sLevp4gFQGSVPlO7ZTif+Rk5UmnoD9C/Pzg6qhuPEHW0MS7TNOw7yMulWl8nc+Dv4cwt3ZsDkF9cxvzd0t9NCCGEqG/XPEWWs7MzTz/9NCtXriQ2NpbY2FhWrlzJU089RXx8PH9e2PtFiAs42Gm5rp2SsMgt0rFHZgGzKhVfNOy1Gvq28r7K2hfw9ISNGytvu7nB448rDc9XrYKbbpLheg2kd1iVBugJkpgySx9/DD//rLwWWrRQOxohrplOb+CdZTGm2y+O7oCzg/kd2x8c1Mp0/aetCXIiTQghhKhnDTJ3+z///MOkSZMa4qGFlRkeXjkVtAznsx7J2YUknC0AoEdIU9ydHS6/cnS0UgFVVVAQ3H47tGmj9NVJSYGvv4YOHRouaAFAqI8rvk2cANh36hx6gzTYNjvu7nD//crUZUJYsD93JXEyU3mv6NmyKTd1aaZyRJfWLsCd69srJ9JScopYHp2mckRCCCGEdWmQxJQQNTWkvR/a8u9W62Iz1A1G1Jurzsan18OiRUqj8s6dlRnGSkqqrzNzJsTFwdNPKxVUolFoNBoiy2fnyy8p42hansoRiRrJy4My6X0jLEduoY7P1h4z3X71po5ozDjZOm1wZdXUrM0nMcqsmEIIIUS9kcSUUJWXqyO9WipDh+LPFhCfeV7liER9qNpfanC7Kv2lsrOVYUitW8Ott8KGDcryzEyYP7/6g3h5gVYOUWroXbXPlAznM39r10KnTvDJJ2pHIkSNfbHuODmFOgBu7R5Et2AvdQO6in6tfOgU5AFAdEoeO+Pl2CiEEELUF/nWJ1Q3rNrsfFI1ZenK9Aa2nVAqprxcHegU5AmHDsG0aUo/nOefh1OnKjdo2xa++AJuuUWdgMVFqiWmEqX3m1lLTIQbboDkZHj9dWVorBBm7mTmeX7bkQiAs4OW529or25ANaDRaHhocGvT7R+2yIyYQgghRH2RxJRQ3bAqfabWSp8pi3coJZe8YmVI0YA2vtjdOR66doUff4SiosoVR4+GFSvg6FF46inw8FApYnGh8GYeNHFSZjuMSsyWISvmLDQUpk9XrpeWwn33gU6nakhCXM37y2MpK+9f9/Dg1jTzdFE5opq5sVMgQV5KrOuPZnA8PV/liIQQQgjrUON51mfMmFHjB922bds1BSNsU2s/N0J9XEnMKmTPqXPkFurwdL1Cs2xh1rYcq+wvNbitr9LAvIK7O0yZosyw166dCtGJmrDTaujRsimbj2WSmV/CqaxCQn3d1A5LXM5bb8GyZRATA/v3w3vvKdVTQpihrcfPsra8OjrAw4mHr2t1lS3Mh72dlgcGhvH2UmUmwR+2xPPRHV1VjkoIIYSwfDVOTD333HO1emBzbmApzItGo2FYeACztyagNxjZeCyDm7sFqR2WqK0DB+CbbzjcehwVxZgD2/rBo48qs+499phSzeHurmqYomYiQ5XEFChVU5KYMmPOzvDrr9C3rzKxwDvvwNix0KOH2pEJUY3eYOSdZTGm28+P6oCrY40/ipqFu3oH8/naY+QXl7FofyrPjWyPv4ez2mEJIYQQFq3GnwYSEhIaMg5h44aF+zN7q7KPrY2VxJTFKCuDf/6Br76CLVsA6DSwiLUD7qa1n5sy5MGrpdL3RpLVFuXCBuh39gpWMRpxVb16wUsvKUmpsjKYPBn27AEnJ7UjE8Jk/u5kjqYpw9+6tPDk1u6W917fxMmeiX1aMnPTSUr1Bn7dkch/RnVQOywhhBDCotU4MdWyZcuGjEPYuN6h3rg725NfXMbGuAx0egMOdtICzWxlZsIPP8B338Hp09XuuilmE5/3n8CgtlVm45OklMXpGuyFo52WUr2BPaekAbpFePVVpTrx4EElGfzmm8qwPiHMQF6xjk9Xx5luv3pTR7Ray3xvuL9/KLO3xqPTG/l9ZxKPDWmDm5NlVX4JIYQQ5kS++Quz4GCnZUh7ZXa+/OIydifKNMxmad8+pUdUcDC88kr1pFR4OIsfeoVxkz8DjYbB7XzVi1PUmbODHV1aeAKQcLaAjPxilSMSV+XoqAzpcyjv0ffhh7Brl7oxCVHumw0nyCooBWBM52bVqjItTaCnM+O6KtVeuUU6FuxJVjkiIYQQwrJJYkqYjeHh/qbr68obowoz8r//Qc+e8MsvUFKiLNNolF42a9bAkSN82noYhY4uONhp6BPmo2q4ou56VfniuCdRqqYsQteulY3PnZ1BhuELM5CUVcjPWxMBcLTX8uJoyx/69tDgyqbts7clUKY3qBiNEEIIYdkkMSXMxpB2/tiVl/WvPyqJKbNzww3g5aVc9/SEZ5+FEydgyRIYPpxT2YUkZRcC0LNlUxnWYAUiw5qarkclSBWjxXjhBWWygYMHYcIEtaMRgvdXxFJanriZOjCMYG9XlSOqu/aB7lzXThmynpxdxKoj6SpHJIQQQlguSUwJs+Hp6kCvlsoX4YSzBZzMPK9yRKIaNzd44w2YORNSUuCTT6BV5RnjzcfPmq5X6y8lLFbPlt6m9mAyvNaC2NvDN99AmzZqRyIEu+KzWBGdBoBvEyceG9Ja5YjqT9WqqVmbT2I0GlWMRgghhLBckpgSZmV4eIDp+rpYOftodp5+Gh5+WElSXWDLsUzT9cGSmLIKni4OtA9wByD2TB75xTqVIxJ1Il+aRSMzGIy8vSzGdPu5ke1wd3ZQMaL61b+1Dx2beQBw8HSuVJYKIYQQ16hOiamCggLOnDnD+fNS2SLqx7AqfabWSp8pi6HTG9hxMgsAbzdHIpp7qByRqC+RYUqfKYMR9iXlqBuMuDYFBfDkk/DUU2pHImzM//adJjolD4DwZh6M7xWsckT1S6PRVKua+mFLvIrRCCGEEJar1ompxMREHnvsMVq2bImHhwctWrTA09OTkJAQHn/8cRKk0aqog1Z+TWjlq1Tj7D11jpzCUpUjEjVxMDmH/JIyAAa28bXYKcDFxarOnLVbqgEsj14PAwbA118rl3Xr1I5I2IiCkjI+XhVnuv3qTeGmPpLWZEyXZjTzdAaUE2onMuRkrRBCCFFbtUpMLV68mC5dujBz5kzs7OwYO3Ys99xzD2PHjsXe3p7vvvuOLl26sHjx4oaKV9iAiqopvcHIxrjMq6wtzEH1/lK+KkYi6lvVxFSU9JmyPHZ28OCDlbcfeADy8tSLR9iMmZtOkpGvzOA6omMA/Vtb53uDg52WBwaEmW7P3ipVU0IIIURt1TgxFRMTw1133UWLFi3YtGkT8fHxLFq0iDlz5rBo0SLi4+PZtGkTISEhTJgwgZiYmKs/qBCXMKxKn6m10mfKImw5XplAlMbn1iXQ05lgbxcADiTnUFKmVzkiUWuPPQbXX69cT0qC6dPVjUdYvZScImZtVhI0DnYaXr4xXOWIGtaEyGDcy2ei/d++FDLLE3JCCCGEqJkaJ6bee+89fH192bp1K4MGDbrkOoMGDWLLli34+Pjw/vvv11uQwrb0bNkUD2flA96mY5noyqeYFuYpt1DHweQcANoFNCGwfEiDsB4VVVOlZQYOn85VORpRa1ot/PQTNGmi3J49G5YvVzcmYdU+WnmUkjLlvXtyv1DCfC+eMMOauDs7cE+fEEA5Ts7ZkahuQEIIIYSFqXFiasOGDUydOhVvb+8rruft7c0DDzzA+vXr6xycsE0OdlqGtFeG8+UXl0lfGzO3/eRZDOWTfUm1lHWKlOF8li80FGbMqLw9bRqcO6daOMJ67Us6x+IDqQA0dXXgyWFtVY6ocdw/IBT78h5av+08RWFpmcoRCSGEEJajxomprKwsQkNDa7RuWFgYWVlZ1xqTEDI7nwWR/lLWr3dYZWJqT6IkMyzWgw/CDTco11NTZZY+Ue+MRiNv/VvZymH6iHZ4ujioGFHjaebpwriuzQHIKdTx997TKkckhBBCWI4aJ6Z8fX1rPONeQkICvr7yBVVcuyHt/E2z96w7mo7RaFQ5InEpRqORzceU/lKOdlr6hPmoHJFoCK183fBxcwRgT2I2BoO8Hi2SRgM//ACensrt33+HRYtUDUlYlyUHUzlQPrS7rX8T7o4MUTegRvbgoFam6z9uSUAvx0ohhBCiRmqcmBoyZAizZ88mO/vKwziys7OZPXs2Q4YMqWtswoZ5ujrQO7QpAKeyCjmZKdMvm6OEswWk5BQB0DusKS6OdipHJBqCRqOhV/nrMa+4jLj0fJUjEtesRQv48svK27/9pl4swqoUler5cMVR0+3/3tQRe7taTf5s8To29zBVDidlF7L6SJrKEQkhhBCWocafGF5++WWysrIYPHgw27dvv+Q627dv57rrriMrK4uXXnqp3oIUtml4tdn5ZDifOdpSbRif9JeyZr2r9JnaLX2mLNukSXDXXfDxx7BggdrRCCvx45Z4UnOLARjS3o/r2tnme8K0KlVT32+Ol4pvIYQQogZqnJjq2LEjf/75J4mJiQwaNIjWrVtz2223MXnyZG677TbatGnDoEGDiI+P5/fffyciIqIh4xY2YFiVxNS62HQVIxGXs+V4pum69JeybpFV+kxFyYQElk2jgblz4bnnwE6qHEXdpecV8+3GkwDYaTX8d0y4yhGpZ1BbXzoEugNwIDmHvaekL58QQghxNbWqsb7ttts4dOgQ06ZNo6SkhEWLFjFnzhwWLVpEUVERDz74IAcPHuSOO+5oqHiFDQnzdaOVnzLF9N5T5zhXUKpyRKKq0jIDO04qkxz4NnEkPNBD5YhEQ+rYzAO38qGauxOzpQrA0mk0akcgrMjHq+Io0ukBuLdPCG383VWOSD0ajaZa1dSszfEqRiOEEEJYhloP/m/VqhUzZ87k9OnT5OTkkJycTE5ODikpKXz//fe0adOmIeIUNqpiOJ/BCBviZDifOdmfdI6CUuWLyMA2vmi18kXXmtnbaenRUukzlZ5XwulzRSpHJOrVjh3w9NMgCUdRS4dP55pmoPNwtueZ4e1Ujkh9Y7s2J9DDGYA1senES59MIYQQ4opqnZjatWsX8+bNY+3atTg6OhIUFISHh1RKiIYxrIO/6fq6o5KYMifSX8r2VO0zJcP5rMiHH8LAgUpTdGmGLmrBaDTy9tIY0+2nhrWlafkMnrbM0V7LlAGhgJLr/XFrzWa1FkIIIWxVjRNT+fn5DBw4kP79+zNx4kRGjRpF69atOXDgQL0H9c033xAaGoqzszN9+vQhKirqsusOGTIEjUZz0WXMmDEA6HQ6XnjhBTp37oybmxvNmzfnvvvuIzU1td7jFvWvZ8umeLo4ALA5LpPSMoPKEYkK0l/K9lTMzAfSAN2qdOgAhvJj69NPw+nT6sYjLMbK6DSiyo8FYb5u3NcvVN2AzMjdfUJo4mQPwP/2nubs+RKVIxJCCCHMV40TUx999BHbt2/n1ltv5auvvuLpp58mOzubyZMn12tA8+fPZ/r06bz++uvs27ePrl27MmrUKDIyLl0ts3DhQs6cOWO6REdHY2dnx/jx4wEoLCxk3759vPrqq+zbt4+FCxcSFxfHuHHj6jVu0TDs7bRc316pxskvKZMvw2biXEEph1JyAegQ6I5/+ZAFYd26BzfFwU4Zshklr0XrcfPNykx9ALm5MHWqDOkTV1Ws0/PeiljT7ZdvDMfRvtaF+FbLw9mBCb2DASgpMzBnxymVIxJCCCHMV40/QSxcuJDbbruNv//+m8cee4wZM2bwxRdfEB0dTUJC/ZUoz5gxg2nTpjFlyhQ6duzIzJkzcXV15aeffrrk+t7e3gQGBpoua9aswdXV1ZSY8vT0ZM2aNdx55520b9+evn378vXXX7N3716SkpLqLW7RcKrOzrdWZuczC9tOnjV9bx1so1OC2yIXRzs6BXkCEJ9ZIBUA1uSLL6B5c+X66tXwww/qxiPM3i/bE0nOVnrNDWjjw/Bw/6tsYXumDAzDrrz/4pydpygq78sohBBCiOpqnJhKTExk5MiR1ZaNGjUKo9HI6Xoq+y8tLWXv3r0MHz68MkCtluHDh7Njx44aPcbs2bOZMGECbm5ul10nNzcXjUaDl5dXXUMWjeC69n7Yl3+wWxebIbOBmYEtx6r2l5JhfLYkskqfqT1SNWU9mjaF2bMrb0+fDvV40klYl8z8Er5efwIArQb+O6YjGpnp8SJBXi7c1KUZANkFpfxvnwyTFUIIIS7FvqYrFhUV0aRJk2rLKm7rdLp6Cebs2bPo9XoCAgKqLQ8ICODo0aNX3T4qKoro6GhmV/1wfYHi4mJeeOEF7r777ss2bS8pKaGkpLISIC8vDwCDwYDBID2OGlsTRzt6h3qzIz6LpOxCjqXl0Tag/qeiNhgMGI1G+RtfhdFoZHN5fykney09Q7zkd4bt7D+9Wnrxffn1qIRsRnYMuOL64urMZt8ZORLN1KloZs+GggKMU6ZgXLsWtDI8y5ypsf/MWB3H+ZIyAO7sFUz7gCbq779m6sGBoSw+oPQ1/XFLPHf1amGqojIHZnP8ERZH9h1RF7L/2Iba/H1rnJgCKCgoIDu78gx5xfX8/Pxqyyt4e3tftKwhzZ49m86dOxMZGXnJ+3U6HXfeeSdGo5Hvvvvuso/z/vvv8+abb160PDMzk+Li4nqLV9RcnxYu7IhXri/ek8B9vQPr/TkMBgO5ubkYjUa08kXsshKzizmTq7wOujVvQt65LPJUjskc2Mr+E+JWORRlx4kMMjJ8VIzGOpjTvqN54QV8V67ELiUFzaZN5H/wAYUPPqhqTOLKGnv/OZ5ZyPw9yQC4OmqZ1K3pZfuACvCzh17B7uxJzicxq5CFO49zXRsvtcMyMafjj7Assu+IupD9xzbk5+fXeN1aJaYeeeQRHnnkkYuW33bbbZdcX6+v3Vh6X19f7OzsSE+v3kcoPT2dwMArJyIKCgqYN28eb7311iXvr0hKnTp1ivXr11+2WgrgpZdeYvr06abbeXl5BAcH4+fnd8XtRMMZ19uNzzcrJfC7Thfy3Jj672VhMBjQaDT4+fnJAfIKlp9INF0fFtEcf3/pKwK2s//4A+38T3Is4zzHMotw8/TGzalWbyXiAma17/j7wy+/wIgRALh/+ilNnnwS3Ou/SlXUj8bcf4xGI9P/3Y2hfET9E9e3ITwsqEGf0xo8PkzDlF/2APDX4WzG92+nckSVzOr4IyyK7DuiLmT/sQ3OzjWfIKvG3yZef/31awqmNhwdHenZsyfr1q3jlltuAZSddt26dTzxxBNX3HbBggWUlJRw7733XnRfRVLq+PHjbNiwAR+fK5/hd3JywsnJ6aLlWq1WXjgqaeXnTms/N05mFrA/6Rw5RWV4uznW+/NoNBr5O1/FluOV/aUGt5c3k6psZf/pHebNsYzz6A1GDpzOZVBbaYBfV2a17wwfDo8/Djt2oPn1VzSenmpHJK6isfaftTHpbD+ZBUCwtwsPDGxlHvusmRvS3p/2Ae7Epeez99Q59ifn0rNlU7XDMjGr44+wKLLviLqQ/cf61eZva1aJKYDp06czefJkevXqRWRkJJ9//jkFBQVMmTIFgPvuu4+goCDef//9atvNnj2bW2655aKkk06n44477mDfvn0sXboUvV5PWloaoAw1dHSs/+SGaBjDwwM4mRmPwQgbjmZwe88Waodkc0rK9OyMV4bt+rk70b4Ben0J8xcZ5s0fu5RZTXcnZEtiyhp9/DHY24ODg9qRCDNRWmbgveWxptsvjQ7H2cFOxYgsh0aj4cFBYfzn70MA/LA5np6TeqoclRBCCGE+zC49edddd/HJJ5/w2muv0a1bNw4cOMDKlStNDdGTkpI4c+ZMtW3i4uLYunUrU6dOvejxUlJSWLJkCadPn6Zbt240a9bMdNm+fXuj/EyifgwLr2yyvO5o+hXWFA1l76lzFOmUIbqD2vrKLEw2qneVmfmiZGY+6+TiIkkpUc2cnaeIP1sAKLNzju5U/70erdm4bs3xd1eq8VfFpJFY/rsUQgghRC17TIEyY93vv//O6tWrOXnyJPn5+bi7u9OmTRtuuOEG7rnnnjpXIT3xxBOXHbq3cePGi5a1b98eo9F4yfVDQ0Mve5+wLD1CvPBydSCnUMfmY2cpLTPgaG92uVWrVm0Yn1TJ2KzmXi4EebmQklPEgeQceS3agpISmDULHnlEElY26FxBKV+sPQaARgOv3tRRTkzUkpO9HfcPCOWjlXEYjTB7awJv39JJ7bCEEEIIs1CrbxKHDx8mPDychx56iAULFnDy5EkKCws5efIkf/31F1OnTiUiIoLY2NirP5gQtWRvp+X69kqj7fMlZexKyFI5IttQrNOzcN9pHpmzl1+3J5qW9wo1n/4YovFFhilVU8U6A9GpuSpHIxrUoUPQuzc89RR8+KHa0QgVfL72GHnFZQDc1r0FnVtI37FrMTGyJa6OyvDHBXuTyS4oVTkiIYQQwjzUODF1/vx5xo0bR3p6Ou+++y7JycmcO3eu2v/vvPMOqampjB07loICKVEW9W9YeOUMcOtiZXrqhrYmJp3I99Yy/a+DrI5Jo7C0cqbNG7/cwtoYGVJpq6omJncnyHA+q1ZcDEeOKNffegsOHlQ3HtGoTmTk83t5TzkXBzuev6G9yhFZLk9XB+7qHQwoSf3fd55SOSIhhBDCPNQ4MfXzzz+TlJTEsmXLePHFFwkKqj49cFBQEC+99BL//vsvCQkJ/PLLL/UdqxAMbueHvVYZPrA2Nl2GaTagNTHpPDRnD/lFyllywwW/6vyiMqbN2cMaSU7ZpMgqfaZ2S58p6xYZCS++qFzX6eC++6BUKj1sxbvLYtGXvwE8OqQ1AR41n/pZXOyBAWHYlX+O+XV7IsU6/VW2EEIIIaxfjRNTy5YtY+TIkQwZMuSK6w0dOpQRI0bw77//1jU2IS7i4exAn1bKF+LT54o4ln5e5YisU7FOz7MLDoARLpf6M5b/89yCA/LB2ga18W9CU1el19DuxHMYLsxcCuvy2mvQubNy/dAhpXJKWL1NxzLZEJcJQDNPZ6YNaqVyRJYv2NuVGzs3AyCroJR/9qeoHJEQQgihvhonpg4fPnzVpFSFoUOHcvjw4WuNSYgrGtahcna+tbFSrdMQlh8+Q15R2WWTUhWMQG5RGSuiz1xlTWFtNBoNvcqrpnKLdBzPkCSxVXNygt9+A/vyOVM++AB271Y3JtGgyvQG3lkaY7r94ugOuJT3RxJ1M21QmOn6D1viJbEvhBDC5tU4MZWdnU1gYM2mBg4ICCA7W4Z2iIYxPLwyMbX+qPSZagirj6SjreGES1oNrIqWBKEtqjqcL0qG81m/bt2UyikAvR4mT1b6TwmrNHd3sinh3C3Yi3Fdm6sckfXo0sKLvuXV3/GZBayTzzJCCCFsXI0TUyUlJTjUcIpoe3t7SqX/hGggIT6utPVvAsC+pHNknS9ROSLrk1NYelFPqcsxGCGnSF7vtqh3WGViao8kpmzDiy9Cz57K9dhYePVVdeMRDSK3SMeM1XGm26+N7YhGU8OzFaJGHhpcOSzyh83xKkYihBBCqM++NisnJiayb9++q66XkJBwzQEJURPDwgM4nnEeoxE2xGVyR88WaodkVbxcHdFqLm54filaDXi5ODZ8UMLsRDT3wMXBjiKdXmbmsxUODvDrr9Cjh9IA/dNPYfx4pUG6sBpfrz/OuUIdAOO6NqdHSNOrbCFqa0g7f9r4N+FExnmiErPZn3SO7vJ7FkIIYaNqlZh69dVXebUGZ0eNRqOcWRMNani4PzM3nQRgXWy6JKbq2ciIAFYeSavRugYjjOoUcPUVhdVxsNPSPcSL7SezSM0t5vS5Qlo0dVU7LNHQIiLg7bfh5ZfhlVeUIX7CaiScLeCX7YkAONlreWF0B3UDulZGIyxcCF9+CVlZ4O0NPj7V/2/RAu69t/p2ZWWVvdQakFarYdqgMF74n9KT9cctCXwzURJTQgghbFON33l//vnnhoxDiFrpHtIUbzdHsgtK2Xwsk5IyPU720pS1vjRxqtmhQQN4uNgzulOzhg1ImK3eod5sP5kFwO7EbElM2Ypnn4XRoytn6hNW4/3lsej0SrnsQ4NbEeTlonJE12DTJmUf3bv3yuu1bXtxYuq222DNGiVxVXGpSGRVvd6jR+Ww1mt0c7cgPl51jLPnS1gRfYakrEJCfOQYKoQQwvbUODE1efLkhoxDiFqx02oY0t6PhftSKCjVsys+m8Ht/NQOyyqsjD7Dk3P3X3U9Tfk/n47vhrODJAVtVWSVPlNRCee4tbtUL9oEOztJSlmh7SfPsjpGmczC392JR65rrXJE1ygpqXpSytFRGXp6IW/vi5dlZytN/VNTlcvlPPdc9cSUXg8eHuDldelEVtXrgweDry/ODnZMGRDKx6viMBjhp20JvDEu4pp/bCGE+op1epYfPsPqI+nkFJbi5erIyIgAbuzcTD4vC3EFDV+rLEQDGdYhgIX7UgBlOJ8kpupu0f4Unl1wEH15c6leLZtyLD2fvOIyU8+piv89XOz5dHw3hneUYXy2rHuIF/ZaDWUGI7ulAbptO3QIwsLA3V3tSMQ10BuMvL001nT7uVHtcath9azqLhx+d8898MEHSkLq3XeV6r7iYjh3ThnWl52tXFwuUQ3Wpg3k51euV1R06ef08al++9w5KCxULldKaAFs3Qq+vgBM7BNC9Pd/8Nqyr8j72Z2yT0Kw9/O9dGLLzw8GDarFL0YI0ZjWxKTz7IID5BVV/9y88kgab/x7hBnyuVmIy7KQTxxCXGxwO18c7DTo9EbWxmbwxjjpbVYXc6OSePmfwxjLG57f3qMFH97emTKDkRXRZ1gVnU5OUSleLo6M6hTA6E5y5keAq6M9EUGeHEzO4UTGebILSvF2k2b4NkWnU5IAb70FDzwA33+vdkTiGvy9N5nYM3mAMrHBHT0soPoxNhZeew00Gvjrr8rldnbKcLzAQNCWT0Dt4qJcmje/8mP+8kv120VFlYms7OzKhFWvXtXXKy5Wqggr1ikuvvxzVElqebk6coOfhmbns2h2PgsyEi+/na8vZGZWX/bss7B27aUrs6ouCw2FkJAr/+xCiGu2Jiadh+bsgfLP0YYL/s8vKmPanD3MmtSLEZKcEuIikpgSFsvd2YE+YT5sPXGWlJwi4tLz6RDooXZYFumnrQm8tTTGdPveviG8Na4TWq0Gezu4tXsLGaIlLisytCkHk3MA2JOYzciIQHUDEo0rNRU+/FCpWpk1S+nRM2qU2lGJWjhfUsbHq46Zbr92U0e0WjM+0ZOYCG++Cb/9BgaDsmzv3upD666WgKopFxcIClIuV9KihVI1WKEioVW1Qqvi+gWxDWzrR3oTb7yK8nDSl13+OS6s0gI4dqz6817Ogw/CDz9UXzZwIBonJ5p06AB33QUDBihJPSFErRTr9Dy74AAYTXmpixgBjRGeW3CAXS8Pl5O7QlxAElPCog0L92fribMArIvNkMTUNfhmwwk+XhVnuj1tUBgv3xgu1WeixnqFevPDlgRAaYAuiSkb07IlfPIJPPqocnvqVIiOVnrtCIvw7YYTnD1fAsDoToH0aXWJBIg5OHNGGZo3a5ZSqVchIEBJkNaxGXm9qmlCC/B56lEe9+nDskOpOJeV8NH1QYwLdrk4sdWkycUbazSX76FV1YX9tHQ62LYNDdBk/Xr49lulImvMGBg3DkaOvPTzCSEusvzwGfKKrpBULmcEcovKWBF9Rk74CnEBSUwJizY8PIA3/1UqfdbGpvP49W1UjshyGI1GPl4Vx7cbT5qWPT2sLc8MbytJKVErvUOrNEBPPKdiJEI1Dz8MCxcqw6dSUuDpp+HXX9WOStRAcnYhP25VEsuOdlpeGh2uckSXkJUFH30EX31VvedT06bwwgvwxBPg5qZefPXgwUFhLDt8hmIHZ748VsJNN/apWdXakiVgNCq9rS6szKp6/brrqm+XmwsODtUTfGfPKq/bX38FJycYOhRuvhkmTABPz/r9gYWwIquPpJt6Sl2NVgOrotMlMSXEBSQxJSxasLcr7QKacCz9PAeSczh7vgTfJk5qh2X2jEYjb/4bwy/bE03LXhrdgYctdQYmoSpvN0fa+DfhRMZ5jqTkUlhahqujvL3YFI0GZs+GTp0gL08ZYnX77UrlhTBrH6w8SmmZMhxuyoBQQnxcVY7oArNnw/Tpyn5Vwc0N/u//lP5KVlKZ1z2kKZGh3kQlZnMi4zwbj2UwtEMN+9BoNMrvxM0NgoNrto2vL5SUYEhPJ++vv/DctAnNqlVQUKDcX1ICK1Yol3HjJDElxBVkF5TWKCkFSvIqp+gqFY5C2CCt2gEIUVfDwpUPbkYjrD+aoXI05k9vMPLSwsPVklJv3RwhSSlRJxVVU2UGI/uTctQNRqgjOBi++KLy9kMPKdUawmztScxm2aEzAPi4OfL4UDOsOvb2rkxKOTkpCan4eHj7batJSlV4aHAr0/VZm+Mb/gk1GvD3p/jOOzEuWKBUTK1YoQzLrRiCGBkJzZpV3+7dd+HJJ5UKyasNIRTCip3IyOftpTHsT655tbhWA14uMkmMEBeSxJSweMPD/U3X18WmqxiJ+SvTG5j+1wHm7U4GlDfHj+7own39QtUNTFi8yLCmpuu7E7NVjESoavJkuOkm5Xp6Ojz+uLrxiMsyGIy8XWXSi+kj2+Hh7KBiRCjDytIveB+/5Rbo109JdJ44ATNmgL//JTe3dEM7+NPKTxmSuDM+m0Oncxo3AGdnuOEGpd9UcrLSUP7jj6uvYzQqTdS//lrpQ+XnpzRO/+MPZcigEFauqFTP33tPc8d32xk+YzOztyag09ewXAqlYmpUJ5mVT4gLSWJKWLxuwU1N09NvOX6WYp1e5YjMU0mZnsf/3MfiA6kA2Gs1fDGhO3f2qmHZvxBXULXPlCSmbJhGozSmblqeqJw/H/76S92YxCUtOpDCwdO5AHQIdOcuNd8L9HolsREeDvffX/0+jQY2b4bvv1dmvrNiWq2GaYMqq6YqJpVQhUYDPXrA4MHVlycmKo3mK+TlKa/xe+9VEobXXw+ffQYnTyKENTmSmsuri6KJfG8tzy04yJ5TlVVSDnYaHOyu3hNOA3i62DO6U7OrriuErZHElLB4dloN17dXzp4WlurZGS9DRy5UrNPz0G97WXVEORPtaKflu3t7MrZrPU2nLWxekJcLzTydAdh3Kged3qByREI1zZrBN98o18PDISxM3XjERQpLy/hoZeVsrP8d0xF7OxU+EhqNsGgRdOumJDZOnoSVK2HLlurr2dtOz7pbuwfh20Q52bb88BmSswtVjugCYWHKkL+KZFTTympZ9HrYuFHpCdamDWzdqlqYQtSH8yVlzI1K4uavtzLmy63M2XmK/OLK2ffaBTThtZs6svuV4Xw3sScajZJ8uiwNfDq+G84Odg0euxCWRhJTwipUHc4nfaaqO19Sxv0/R7HpWCYAzg5aZt/fixEdpYxY1B+NRmOqmirS6TmSmneVLYRVmzBBmdlr3z7o3VvtaMQFvt8UT1peMQDDOvgzsK1v4wZgNCr9ifr2hVtvhejoyvuGDQMPj8aNx4w4O9iZhtfrDUZ+2qZi1dTleHjA+PEwZw5kZFQmo1pX6VXp6Ql9+lTfbtMmZRbBQjNLtglRhdFo5GByDi/+7xCR767lpYWHTdWlAC4Odozv2YL/PdqfVc8M5oGBYXi5OjK8YwCzJvXCw0VJpF84qaaDnYYfJvViuHz+FuKSbOcUlLBqg9r54WinpVRvYF1sBm+OM6LR1GCaZSuXW6Tj/p+jTM2omzjZ89P9vYkM877yhkJcg95h3iw5qAzx2J2QTbdgL3UDEurRaOC++9SOQlzCmdwivt+sDLOy12p4eUx44wawfTu88oqSzKiqb1+lqfbQoY0bjxm6t29Lvt14gmKdgfm7k3lmWDs8XVXu/3U59vZw3XXK5ZNP4OhRJflUXAwOF8T88cewbJnSy2rECGW2v5tugsBAdWIXoorcIh2LD6QwNyqZ2DMXn1yLaO7BhMgQbu7W/LL9+EZ0DGDXy8NZEX2GVdHpZBeWsj/pnNKDygg9Wja95HZCCElMCSvRxMmePq282XL8LCk5RRxNyye8me2ecQVl6tpJs3eZKlc8nO35bWofSRaIBhNZpc9UVGI206rMMCUEZWWQn1996I9odB+vjKNYpwy1ndSvJa39mjTek7/4Inz4YfVlXbrAO+8oCQo5oQSAt5sj43sGM2fnKQpL9fwRdYrHhpjhjIkX0miU4bvhl0h2FhTA2rXK9eJi+Pdf5aLRKJVV48Ypl44dZT8QjcZoNLLn1DnmRiWx/PAZ07GxgpujHTd3D+Lu3iF0buFZo8d0drDj1u4tuLW70hPv3WUx/LAlAZ3ByMJ9p3lwkHw2EuJSZCifsBrDwytLY219dr6MvGLu+n6HKSnl4+bIvIf6SVJKNKi2/k3wdFHOIu5JzMZorPksNcLKxcbCgAEwcaIyjEuo4kByDgv3pwDg5erA08PaNm4Aw4ZVXm/bFubOhf37YexYSUZcYOrAMNOv5JdtiZSUWfjELg4O8PffMG1a9QopoxF27oSXX4ZOnZTeVJs2qRensAnZBaX8uCWeEZ9tZvzMHSzcl1ItKdUt2IsPb+9M1CvDee/WzjVOSl3KhMgQ0/W5UUny2UiIy5DElLAaw6r0mVoba7t9pk6fK2T89zs4nnEegAAPJ+Y/3I+OzW27gkw0PK1WQ+9QpRrmXKGOk5nnVY5ImIWyMqUaJioKVqyA2bPVjsgmGY1G3l4aY7r9zLC2eLk6NtwTnjoFMTHVlw0frjTM/vFH5b4JE0ArH0UvJdTXjRsilARORn4JSw6kXmULM+foqBwHZs2ClBTYtUsZ0tm5c/X14uMh+IIZIjMzITcXIerCYDCy/cRZnpy7n77vreOdZbGcyKj8nOLhbM/9/UNZ+cwgFj0+gLt6h+DmVPfBRa39mphaaJzMLGB34rmrbCGEbZKhfMJqtGjqSodAd46m5XPwdA6Z+SX4uTupHVajSjxbwD0/7CQ1V2lq26KpC38+2JcQH1eVIxO2oleotykxHJVwjjb+7ipHZL6KdXqWHz7DqiNpZOYU4Od1mlERgdzYuZl1zdhjbw9ffQVjxii3p09X+su0bKluXDZm6aEz7C2f3ry1nxsT+zbQ7z8tDd57D77/HiIjYfPmymoojUZpmC1qZNrgVqyITgPghy3x3NGzhXX0z9RqlX0jMlIZxpmQoAzrW7IEsrOh1QVDnT79FGbMgCFDlOF+Y8fK8UPUWEZ+MX/vPc383cmcyrq48X5kqDd39wlmdKeGe++9OzKYqIRsAOZFJUmvVyEuQU5TCasytINSNWU0wgYbm53vWHo+47/fYUpKtfJ146+H+0lSSjSq3lX6TO1OzFYxEvO2JiadyPfWMv2vg6yJSWdfynnWxKQz/a+DRL63lrUxVjYc+cYb4YEHlOv5+cp1g+HK24h6U6zT88GKo6bb/x3TEQe7ev4IeO6cMhyrdWslEVlaClu3wsqV9fs8NqRHSFN6lTdLPpZ+3jS7rtUJC4OnnlJ6UEVFXXz/kiWg0ykzOT75JISGQrdu8NprsGePHEvERfQGIxvjMnhkzl76v7+ej1bGVUtKebs5Mm1QGGunX8dfj/Tj1u4tGvSE0OhOzfBwVupBlh0+Q26hrsGeSwhLJYkpYVWGVekztdaG+kxFp+Ry1/c7yMwvAaB9gDvzH+5Hcy8XlSMTtqZzkCfODspbS8XZQVHdmph0Hpqzh/yiMgAM5e0mKv7PLypj2pw9rLG25NSMGZVDdNavh+++UzceGzJ7awIpOUUADGrry5D2fvX34OfPK7PphYXB++9DYfmXP1dXeOklpbG1uGZVJ5GYtTlexUgaif0Fgzl0OqXCMjS0+vKDB+Htt6F3b+W48sgjyjJh087kFvHF2uMM/mgD9/+8m5VH0igzVPZ0GtjGl6/v6c6Ol4byypiOtPFvnMkfnB3suK2H0gy9pMzAogMpjfK8QlgSSUwJq9It2AsfN6VnxpbjZynWWXiz0BrYe+ocd/+wk3PlZ186B3ky76G+NjeMUZgHR3utqcl+Sk4RqeVfhoWiWKfn2QUHQJk5+pKM5f88t+CAdR3DPD3hp58qbz//PJw4oV48NiIjv5hvNyi/Z61GqZaql+FgxcXw+efKsKv//reyB5Cjo1L9cvKkMqTPW4as1MXw8ADCfN0A2H4yi+gUG+u15OAAX3yh9J46dEgZ+hcZWX2d1FRl6GhSkjoxClWV6Q2siUln6i+7GfDBej5be8yUiAfwc3fi8etbs/k/1/P7g324qUtznOwbf7j8hMjK3mnSBF2Ii0liSlgVO62G68uH8xXp9OyIz1I5ooa142QWk2bvIr9Yqbzo1bIpf0zrQ1O3BmxoK8RVRMpwvstafvgMeUVll01KVTACuUVlrIg+0xhhNZ7hw+HRR5XrhYVw//2gt6Lkmxn6dNUxCkqV3/E9fUJoH1hPfd+mTIH/+z+lMTUofYMeeACOHVMSCVVnXhPXzE6rYerAMNPtH7bYQNXUpWg0SqP0V15RGqdXJKPGjAEnJ3BxqT7rI8Cff8LAgfDRR3D06KUfV1is5OxCPlkVx4AP1zPttz2sO5phqjzWauD69n58P6kn218cyn9GdVC9tUWHQA+6h3gBlPfDtbEksxBXIYkpYXWGV5mdb50VD+fbGJfB/T9HUVj+hWNAGx9+mxqJh7ODypEJW9c7TBJTl7MyOo2aFqtoNbAq2gqPYR99VNnceNs2pepGNIjolFz+2psMgLuzPf83vF39PfiTT1Zev+suZZa92bOlKXUDuL1HC7zLTzgtPXSmWjWIzWrWDB56CJYuhawsWLdOGT5a1aJFyjHmhRcgPBzat4f//Ae2bFFmCxUWp7TMwLJDZ5g0exeDP97A1xtOkJ5XYrq/uaczzwxvy9YXhvLzlEhGRQTWfz+9Ori7d4jp+txdUuEnRFUyK5+wOoPa+uFop6VUb2B9bAbGm43WMYtNFSuj03hy7j50euXU0NAO/nw7sYd1zeQlLFb3kKZoNUrPpN0JtjstcmFpGbFn8ohOyeNIai7RKXnEnMmr8fYGI+QUlTZghCpp0gR+/lmZYQuUL5Wi3hmNRt5ZFkPFaJGnhrbFp8k1DPE2GpUv/56eMHhw5fL+/eGtt5QZ0rp1q5eYxaW5ONoxqW9Lvlh3HL3ByM9bE/jvTR3VDst8uLlBv37VlxmNFw/tO3YMPvlEufj4KNVW48bByJHgLjPImrP4zPPM353M33tPk1VQ/X3RTqthWAd/7o4MYXA7P+y05vuZ/6auzXhraQznS8r491Aqr47tSBMn+TouBEhiSlghNyd7+rb2YfOxTFJzi4k5k0dEc0+1w6o3iw+kMP2vg+jL65XHdG7GZ3d1w9HefM4ICdvWxMmeiOaeHE7JJS49n5zCUrxcrXt4aW6hjiOpuRxJzSM6NZfolFzizxZQ1xYSJzMK2HQsk0FtfNGa8YftWhs8GD74QPkyOWiQ2tFYpdUx6eyMVyoWW/q4cl//a6hk2rBBmWlv507o3l2ZAU1b5b3m1VfrKVpxNff1a8nMTScpKTMwNyqJJ4e1xdNFKqQvS6NR9tvjx+Hff5WZ/bZsqZzBLysLfvtNubz7rrKfC7NSrNOzMjqNuVFJ7LrEZCoh3q7c1TuY8T1b4O/hrEKEtefqaM+4bs35c1cShaV6lhxI5Z4+IVffUAgbIIkpYZWGh/uzuXxa5XWxGVaTmJoXlcRL/xw2fdm9rUcQH93eBXszKlMWAqB3qDeHy5v07kk8x/COAVfZwnJk5pcQnZrLkZTKRFRy9tWH1mg14O/uTFpecc2f63wJk3+KopWvG5P6teT2ni2sZ7ju88+rHYHVKinT897yWNPtl0aH167Z765dSi+fdesql+3fD6tWwejR9RipqCmfJk7c0bMFf+xKoqBUz7yoJB6+rrXaYZm/tm1h+nTlkpUFK1YoSaoVK5QZJQFuvrn6NrGxsGCBUk3VtSs1Hn8t6sWx9HzmRiXxz/4Ucson9qngYKdhZEQg90SG0K+Vj0WesLm7dwh/lg/jm7c7SRJTQpSTxJSwSkM7+PPa4iOA0mfqqWFtVY6o7n7amsBbS2NMtyf2CeHtmztZ5JuysH6RYU35aVsCoPSZssTElNFoJCWnSBmCl5pLdGoe0Sm5ZOSXXHVbRzst7QPd6RTkQURzTyKae9Ah0AONBiLfW0t+DRqga6icuS/+bAFv/hvDx6viuK1HEPf1C6VdgBUOPTEYqlfkiGvy2/ZTnMoqBKBvK29GRdTw9Xf4sDLD3pIl1ZdHRCizod1wQz1HKmpj6sAw/oxKwmiEn7clMmVAmFRL14aPD9x7r3IpKYFNm2DzZuh4wbDIBQvg9deVS3CwMsvkU08pM06KBlFYWsbSQ2eYF5XEvqSci+5v5efG3b1DuK1H0LUNSTYjnVt40inIg+iUPA6dViqsOwVZxwl0IepCElPCKrVo6kqHQHfTrBcZecUWU+Z7Kd9sOMHHq+JMt6cNCuPlG8OtrneWsB69LGxmPoPBSEJWAUdS8ziSkqtURKXmXXS29lJcHe3o2MyDiOYeRAR50qm5J238m1z2C+OM8d2YNmcPGiOXTE5pyv+ZObEHRjT8tiOR7SeVPkyFpXp+35nE7zuT6N/ah/v6hTI83N/yqyYNBvjyS+UL4YYN8gWwDrLOl/Dl+uOAUujx6k0dr/5ecfy48iV83jyqjT9t1UrpIzVhAthJD0O1tfJrwojwAFbHpJOWV8y/B1O5vWcLtcOyTE5OSm+pkSMvvq9qYjY5WWmYPmsWzJih9KWSz171Jjoll7lRSSw5kEp+SfWG9E72WsZ0bsaEyBB6hza1qs+8E3qH8N+UaECpmnonqLPKEQmhPklMCas1PDyAo2n5AGyIy+Cu3pZXKms0GvlkdRzfbDhpWvbUsLb83/C2VvUGLayPbxMnWvm5EZ9ZwOGUXIp1erNpzq/TGziRcZ7o8qF4R1JziUnNo6B8hssr8XRxIKK5B52ClCqoiOaehPm61arZ6vCOAcya1IvnFhwgt6jM1Ci+4n8PF3s+Hd/NVGV2Q6dAjqXn89uORBbuSzHNxLn9ZBbbT2YR5OXCxL4hTOgdYpq5y+I8+qjyxQ+Ufi9vvqluPBbss7XHyC9WvuDd2TO4ZkPZn3uu+pfxoCClf9QDD4CDlQwdtRIPDW7F6hhlts4ftsRzW48g+TxQ3/75R2n4v3gxrF6tJGuPH1ca/Y8apcwk2qGD2lFarPxiHUsOpjIvKtk05L+qDoHuTOgdzK3dW+Dpap3Hn5u7NefdZbEU6fQs3p/KyzeG4+ooX8uFbdMYjXVtzWr98vLy8PT0JDc3Fw8PD7XDETW0P+kct367HYARHQP44b5eV1zfYDCQkZGBv78/WjMYSmI0GnlraQw/b0s0LXtxdAcekZ4SZsnc9h9z8MLfh5i/R5mqfu60vvRr7dPoMRTr9BxNyzfNinckNZejafmUlhmuuq2fuxOdLkhCtWjqUm9fAot1elZEn2FldBqZuQX4ebpxQ6dARndqdtkkXl6xjr/3nGbOzlMknC2odp+jvZaxXZozuX9LurTwqpcYG82+fdCnjzKFu52d0uOoZ0+1o7IIVY89xzMKGP3FZgxGcHO0Y8N/huDvXoNq4YMHlZn1fH3hpZeURKGLS4PHLmrPaDRy23fb2V8+3Om3ByIZ3M7vmh9P3ruu4sABZRjfli2Vy+zt4Ykn4I03lNkqbVRt9h2j0ciB5BzmRiXx78EzFOmqnwhydbRjbJfmTIgMpluwl00kW/+z4CAL9p4G4OM7ujC+V7DKETUuOfbYhtrkUSQ1K6xW1xZe+DZx4uz5ErYeP2tWFRtXozcY+e+iw8yNSjYte3NcBJP7h6oXlBC11DvM25SY2p2Y3eCJqfMlZcSU94GKLq+COp5x3jSD5ZW0aOqiVEI19zQlohp6+K+zgx23dm/BzV2b1/jDmYezAw8MDOP+/qFsOXGW37Ynsj4uA6MRSssM/G/faf637zTdgr24v38oozsH1q7ptVp69FCabb/5Juj1MHky7N2rDLcRNWI0GnlnWQwVu/tj17e5OCmVkwOffqok/W65pXJ5167w99/KsCZ3K+xdZkU0Gg0PDWrFo3/sA5SqqbokpsRVdOum9KJasECpLExOVhLoP/9sszP5Fev0LD98hlVH0sjMKcDP6zSjIgK5sfPFJ1VyC3X8s/8083Ynm0YxVNWlhScTeocwtmsz3K1lYo8amhAZYkpMzdudbHOJKSEuJBVTNSAVU5br+b8P8tce5aD/8/29ub6D/2XXNZfMfZnewHMLDrLoQCqgDO/54PYu3ClvWGbNXPYfc5KUVcjgjzcA4OPmSFv/Jni5OjIyIuCSH2BrI7uglCPlfaAqhuRdWEF0KRoNhPm6lSegKhuTe7mqNwSurvtOUlYhc3YmMn93MnnF1Xt0+DZx5O7IECb2aUmgp5n32dPplKqp/fuV2y+8AB98oG5MZuzCL4fY2ZuaBgd5ubDu2esqX2MFBfD11/Dhh3DuHLRvD9HRSuWHsDh6g5Ghn240Nbhf/tQgOja/ts+n8t5VC4WF8PHHyuvo/ffh6afVjqjRrYlJ59kFB8i7zDD0GeO7MSzcn6iEbObtTmb54TOUXFCh7O5kz83dmzOhd4hNN/02Go2M+nwzx9KV2SFX/99g65zU5DLk2GMbapNHkcRUDUhiynKtOpLGw3P2Asosdu/eevnmguZwgCwtM/DU3P2sPJIGgJ1Ww2d3dWNc1+aqxCNqzhz2H3Ozuvz1V/VN5sIPsFebrc9oNJKeV2IaildRCZWSU3TV57fXamgb4F5eCaUMyQtv5oGbk3l9Ga+vfaeoVM/iAyn8sj3xojPTdloNN0QEcl+/lkSGeZvvMInDh5VqHp1OmZ1v2zbo21ftqMzOpb4cVvXQ4Fa8fGO4MvPYDz8ofbvS0ipXcHBQqkD69WvcwEW9mbMjkVfLZx++rXsQM+7qdk2PI+9d1yA5GQIDq/dfO3sWnn9eGd4XYnk9TWtiTUw6D83ZA1eYuMMIBHg4kZ538ey1PVs2ZULvYMZ0aSb9lMr9vC2BN/9VZtx+YEAYr43teJUtrIcce2yDJKbqmSSmLFdBSRnd315DaZmBZp7ObH9x6GW/kKl9gCzW6Xnk971sjMsElOnmv76nOyMjAhs9FlF7au8/5qbiA+zl3mEqZp6bNakXI8qTU0ajkeTsIqJTc6s1Jj97vvSqz+dkr6VDM49qPaHaBbhbxPDd+t53jEYjuxPP8euORFZGp100lLFDoDuT+4dyc7fm5vnl4P33K4fItGunVFC5uqobkxm52pdDAHujnkUeCXT64TM4daryDq0W7rtPmYEvNLQxwhUNpKhUT/8P1nGuUIe9VsOWF66nmWft+4LJe1c9efRRmDlT6c32wgvKTH5WdNwq1umJfG8t+UVllz3uXIqniwO39Qji7sgQm6oGqqmcwlIi31tHaZkBL1cHdr40zCI+t9QHOfbYBklM1TNJTFm2yT9FsemYkuxZ+uTAy5YNq3mALCgp48Ff97AjXpkS3tlBy6xJvaRvhAWRN9hKNf0Aq0Hps3RX7xblDcrzTLOJXUkTJ3s6Nveo1hOqtZ8b9naW+XtvyH0nLbeYP3ed4s+opIsSfB7O9tzZK5hJ/VrS0setXp+3TsrKYMAAiIpSbj/zDHz2maohmYuavLZuiNvGc5vn0Cb7dPU77rgD3noLwsMbPE7ROGasjuPL9ScAeHhwK166sfZ/W3nvqgf5+UoSvWpVYkiIMuxv/HhlDLmFW7jvNNP/Oljj9Vv7ufHUsLaMigi0mUTLtXpm3n5T+44vJnTj5m5BKkfUOOTYYxtqk0eRvUBYveHhlX2l1sVmqBjJpeUW6Zg0e5cpKeXmaMevU+o2y44Qalp++Ax5NTiragSKdHp+2X6KnfHZl0xKNXV1YFBbXx65rjVf39OdDc8N4dDrI/nr4X68PjaC23u2oH2gu8UmpRpaoKcz00e2Z9uLQ/liQje6h3iZ7ssrLuPHrQkM+WQjD/yym41xGRhq0Ci+wdnbw6+/gnN5T6wlS5QeSaJGr60b47ZVT0qNHq00kl+wQJJSVmZSv1Ac7ZVj35+7ksgv1qkckY1yd4fYWCWJXtG3LSkJ7roLhgxRZvazcKuPpKOtYX5No4G2/u7c3C1IklI1MCGycujn3KgkFSMRQl1mWMMvRP0aGh5g6sOw7mg6Tw9vq3JElbILSpk0exdHUvMApYLht6l96BbspW5gQtRBxQfY2uY4Aj2c6RTkQcfmnqYhec08nc23H5IFcbK34+ZuQdzcLYhDp3P4bccplhxMpbTMgNEI649msP5oBqE+rkzqF8r4Xi3wUHOGpA4d4L33IC5OqTpwK6/oio6ubI5+JU2bwk03VV+2ejWkp19924gIZZbACgYD/PFHzeIeMULpPVPh9GnYsOHq22k0cO+91ZdFRSk/fxU52xK4LSW32hDZNHcfdrTsarr92cCJ3Hh0K/uCwtk8+Rmee+fBmsUuLI6fuxO39whiblQy+SVlzItKZtrgVmqHZZu8vJTKzocegv/7P1i1Slm+ebNyPJk2Dd55B/ws86RjTmFpjd/TjUbIKbr6EHyh6BPmTStfN+LPFrAzPpuEswWE+ZpRFbMQjUQSU8LqBXm5EN7Mg9gzeRw6nUt6XjEBDTwNfE1k5BVz7+xdptk4fNwcmTO1zzXPrCOEuajNB1hQeh79/mAffJs4NVxQwqRLCy8+Ge/FyzeGM393Mr/vPGVqJp+YVcjbS2P4dHUct3YP4r5+obQPVKkvyP/938XLli2DF1+8+rZdu16cmPrgg5oliZ5/vnpiSq9X+jLVxLp11RNTBw7UbFt7+4sTU3PmKDPpVfHApZ6yde9qiakE7yBGT/mK474h9A3xqVncwmJNHdiKuVHJAPy0LYH7B4TiIBWk6gkPhxUrlGPV//0fnDihZGpmzYKNG5XKKgsctuTl6ljjE05aDXi5qDfTraXRaDTc1TuY91ccBWDe7iReGi3VrcL2WN6RUYhrUHU43/qj6g/nS8kp4s7vd5iSUgEeTsx/uK8kpYRVqPgAWxNaDYT6uElSSgXebo48OqQ1m/4zhO8n9WRAm8okRmGpnj92JTHq881MmLWDldFnKNMbrvBooq6U5v+FLNqfwn8XHWbxgZRrfqzjfi3RajXy5dAGtPFvYvqMcya3mGWHzqgckUCjURLj0dHw0UfKUD9QGqJbYFIK4PoOfjU+4WQwwqhOV55xV1R3e88WONgpH5z+t/c0pWXyfitsj1RMCZswLDyAr8obhK6LTefuSPWm8k08W8DEH3eZKhSCvFz4c1of82o+LEQdjIwIYOWRtKuviHyANQf2dlpGRQQyKiKQ4+n5/LbjFP/bd5rCUj0AO+Oz2RmfTTNPZ+7t25IJvYPxUSuROGJE5Ze8K/G5RKXQ008rDcCvpnv36re1Wvjmm5rF165d9dudOl122zK9kTO5RSRlF3LqXBGfv7eOjPzKKdbjQvqwe0T1WVmdHbQU66p/YUnx9OdS5LVlOx4a3Jq15T00Z22O5+ZuzWUItDlwclKSUZMmKTP2TZlS/f60NKVxelvzaTFxKedLyvhnX80S5RrAw8We0Z2aNWxQVsa3iRMjOway7PAZzp4vZW1sOjd2lt+hsC0yK18NyKx8ls9gMNLn/XVk5pfg7KDlwGsjL2rI2BizQxxPz2fij7tMXz7CfN3448E+NPeq/RTPwrzI7CKVajMrn4eLPbteHm7TDVLNcd/JK9axcO9pfttxiviz1RuPO9ppualrMyb3C6Wr9MOrsXMFpexLOseeU+fYe+ocB5NzKLnCWXGtBtoHetCrZVN6ll/8mjgS+f46eW2JaoxGI7d8u52DyTkA/PFgHwa08a3RtuZ4/LEZkyfD3LnKkL9XXgEz/I6RU1jK5J93m/atK9GU//PDpF4M7yhJ8dracjyTSbOV2WgHtfVlztQ+KkfUsOTYYxtqk0eRiilhE7RaDUPb+zN/TzLFOgPbTpxlWHjjvmlGp+Ry309RZBcoDSHbB7gz58FI/N3V73clRH1ydrBjxvhuTJuzB42RS36BrvgA++n4bvLF2Qx5ODtw/4Aw7usXytYTZ/ltRyLrjmZgNEKp3sDCfSks3JdC12Av7u/fkhs7N8PJXv6OFYxGI/FnC9ibeI49p7LZe+ocJzOvPLNgEyd7uod4mZJQ3YK9cL9EA3p5bYkLaTQaHhrUisf/3AcoVVM1TUwJlURFwW+/Kdc/+ki5/v77Sk86M/mSnp5XzKQqvVA9XRx4bEhrvt14gtyiMlPPqYr/PVzs+XR8N0lKXaMBrX0J9nYhObuIrSfOkpxdSLC3q9phCdFopGKqBqRiyjqsPpLGQ3P2AnB3ZAjv39a52v0Nmbnfl3SO+3+KIq+4DIDOQZ789kAkTd2k/4e1kDM/F1sTk85zCw5c8gOsp3yANbGUfSc5u5A5O08xf3cyuUXVp6X3cXPk7sgQJvYNoZmn7VWAFuv0HDqdy55T2ewrr4g6V6i74jYtmroo1VCh3vQMaUr7QHfsaticTV5b4kJlegPXf7qR5GylTcDKZwbRIfDqn1kt5fhjdc6fVyZk+OQTKKkcwkvv3vDll9C3r3qxoRzvJ/64i6TsQkCZAXLO1Eg6BHpQrNOzIvoMK6PTyMwtwM/TjRs6BTK6UzNJhtfR1+uP88nqYwA8ObQNz45sr3JEDUeOPbahNnkUSUzVgCSmrENhaRnd3lpDaZmBAA8ndr40rFoPhoY6QO44mcWDv+6moLxfS8+WTfl5Sm91p2IX9U7eYC+t4gPsquh0copK8XJxZFSnAPkAW4Wl7TtFpXqWHEzhl+2niD2TV+0+O62GUREB3NcvlD5h3lbb5yYjv5i9iUoCas+pcxxJzUWnv/zHKXuthoggz2rD8uo6O6x8ORQX+mVbAm/8GwPA7T1a8OmdXa+yheUdf6xOQgI89xwsXFh9+b33wocfQvPmjR7SsfR87q3SdqJFUxf+ePDiXqiy79S/9Lxi+n+wHr3BSICHE9teGIq9lc6yKfuPbZDEVD2TxJT1mPJzFBviMgFY+uRAOgV5mu5riAPkxrgMHp6z19RHpH9rH36c3AtXRxlFa23kDVZcK0vdd4xGI3tOnePX7YmsjE6j7IIpm9oHuHNf/5bc2j3Ioo95eoORY+n57Dl1jn2nlKF5FVUpl+Pl6kDPkKb0aNmUXi2b0jXYq8GSRZa6/4j6V1BSRv8P1pNbpMPBTsOW54cS6HnlBKjsP2Zi/Xplgobo6Mplbm5KRdUjjzRaGAeTc5j8cxQ55RWfbfyb8PvUPpfcj2TfaRjTftvDmph0AH68z3r7dcn+Yxukx5QQlzEsPMCUmFobm14tMVXfVkan8eTcfaaz6EM7+PPtxB5yJlsIYRU0Gg29Q73pHepNel4xf+5K4s+oJDLLz7LHpefzyj/RfLDiKHf2CmZS35aE+pr/7KPnS8o4kJRTXg2VzYGkHPJLyq64TSs/tyrVUN608nVDW8NheULUFzcne+7tG8I3G06i0xv5ZXsiL47uoHZYoiaGDoX9+2HWLHj1VcjOhoKCRm2IfmGFf5cWnvwyJRJvaTvRqO6ODDYlpuZGJVltYkqIC0nFVA1IxZT1OJNbRL/31wNKn6d/nxxouq8+M/eLD6Qw/a+D6MsrCG7sHMjnd3XH0V7OCFgrOfMjrpU17TulZQZWRJ/htx2n2Hvq3EX3D2nvx+T+oVzX1s8sEjdGo5GUnCL2lveF2pN4jqNpeRiu8MnIyV5L1xZepmqoHi2bqvrFzZr2H1F3GXnFDPxwA6V6A+7O9ux4aRhNnC5/Hlr2HzOUnQ2vvw6HDsHGjVB1SLTB0CDN0dfGpPPYn/soLa/w7xPmzY+Te11yAobKUGTfaQh6g5GBH67nTG4xWg1se3GoVfZulP3HNkjFlBCX0czThYjmHhxJzeNwSi7pecV17vNxofm7k3hx4WEqUr63dQ/iozu6WO0YcSGEqOBor+XmbkHc3C2I6JRcft2eyOKDqaYvOxvjMtkYl0lLH1cm9W3J+F7BeLo0Xr89nd5ATGqeKRG199Q50vKKr7iNn7tTtd5QEc095SSDMFv+Hs7c2j2I+XuSyS8uY/7uZKYODFM7LFEb3t7w1VdQVlY9KQVwzz3g6wtvvaWsVw8W7U/h2QWVJ1OHdfDnG6nwrz+ZmdC0KdjX7Gu3nVbD+F7BfLnuOAYjLNhzmqeGtW3gIIVQnySmhM0ZFh7AkVSlYe+62Azu6RNSb4/987YE3ixvPAowsU8Ib9/cySwqA4QQojF1CvLk4/FdeenGcP7ak8ycHadIyVF6M53KKuSdZbF8uvoYt/YI4r5+LS+aQaxYp2f54TOsPpJOTmEpXq6OjIwI4MbONW/unVNYyv6kHPacymZP4jkOns6hWGe47PoajdIbq2fLpvQKbUqvlt60aOpitU3chXV6cFAY8/ckA/DT1gQm92spJ8cs0YWJjA0bYP585frcuUpy6uGHa5zwuJQ5OxJ5bckR08nUm7s155PxXXGQ/aXmDAY4cABWrAAvL3j88er3P/QQ7NkDU6cql+Dgqz7knb1a8NX64xiNMH93Mk9c30a+SwirJ0P5akCG8lmXQ6dzGPf1NkA5KzT7/t5A3UtKv914go9WxpluPzgwjFfGhMsXGhshJcniWtnKvqM3GFkXm85vO06x9cTZi+7vE+bN5P6hjOyo9AJ8dsEB8orK0GrAYMT0v4eLPTPGd7uo74bRaCThbEG1aqjjGeevGJObox3dqzQp7xbiZXEzptrK/iNq54FfdrP+aAYAX97dnXFdLz27m+w/FuSXX+CJJ5TeUxU6dYIvvlB6VNWC0Wjk240n+XhV5efW2p5Mtel959w5WLNGSUatXAlpacry9u3h6NHK9VJTISQE9ErfLrRauPFGJVk1evQVk4qTf4pi0zGlL+6vD0RyXTu/hvppVGHT+48NkaF8QlxBp+ae+Lk7kZlfwtYTZykq1ePieO3lykajkU9XH+PrDSdMy54a2ob/G9FOklJCCFHOTqthZEQgIyMCOZGRz287TvG/vadNjXZ3JWSzKyGbpq4OnCvUUXH0rOj3VPF/flEZ0+bs4Zu7e+Dv4cSe8iTUvlPnyCoovWIMQV4upmqoHiFN6RDoLpUkwipNG9TKlJiatfkkY7s0k88klu7++2HECHjxRfj9d2VZdDQMGwa33abM4Bd29WGbRqORD1Yc5fvN8aZljw1pzX9GtZd95HKMxsqqqBUrYMeOymRTVXFxkJSkJKMA8vNhzBhYulSprDIYlOtLl0KLFlesoro7MsSUmJoXlWR1iSkhLiQVUzUgFVPW58X/HWLebqXMvWIq1mvJ3BuNRt5eGstP2xJMy164oQOPDmndIHEL8yVnfsS1suV9J79Yx8J9Kfy6I5H4zIKrb1AL9loNEc09yquhvOnZsuklpzy3dLa8/4jLMxqNjPt6G4dTcgH4c1of+rf2vWg92X8s1I4d8PTTsHt35TInJ3j2WXjpJWjS5JKb6Q1G/rvoMHOjkk3LXhzdgUeuq/3nVpvad9asgZEjL32fq6uSHBw9WrmEhl68zunT8NNP8OOPkJxc/T6tVtnur7+Uxyqn0xvo9/56zp4vwV6rYcdLw/Bzd6q/n0llNrX/2LDa5FFkLxA2aVh45RCQdUfTr+kxDAYjL/8TXS0p9ea4CElKCSFEDbk7OzC5fyjrpl/HnKmRRDS/9pM/Hs72XN/ej/+Mas/caX059MZIFj8xkNfHRjCmSzOrTEoJcTkajYZpg1uZbv9QpTpGWIF+/WDnTvj5Zwgo/0xbUgLvvQfr119yk9IyA0/P229KSmk08N6tna8pKWWVjEY4eBA++ACWL69+36BB4FJlZrz27eH//g9Wr4asLFiyBB599NJJKVCqo157DRISlGqpceMqZ1c0GJQG6VWSUgAOdlrG92oBQJnByN97T9fTDyqEeZKhfMImDWzji5O9lpIyA+tiMzBcaW7wSyjTG/jP34f4Z38KoLy5f3hbF+7sffWGhkIIIarTaDQMauvHHzuTiD2TR00PyUFeLjw5tA09WzaltV8TaQ4rRBU3dgrkQy8XUnKK2BCXybH0fNoFuKsdlqgvWq0yvO+22+Ddd+Gzz2DwYBg79qJVi0r1PPrHXjbGKUPD7LUaZtzV7bK9x2xGbi6sXVvZKypF+VzP7bcrvaAqODsrQyh9fJTqplatLv14V2NnpwztGzOmehXVQw9VX89ohCeeYEq/65hlcEavtWP+7iQeua6VDLcUVksSU8ImuTjaMaCNL+uPZpCRX0J0ai6danimvuKM04popdGhnVbDjDu7cnO3oIYMWQghrF5OYWmNk1IAwd4uTIisv5lVhbAm9nZapg4M462lymzBP26J56M7uqoclah3Hh7w4Yfw4IPK7QsSF8Uff8pThvZsPKcsd7LXMvPenlzfwb+xI1Wf0aj05VqxQqmK2rYNysouXm/NGtDpwKHKZBivvVa/sVRUUb3yilI1VdWOHfDtt/h/+y1RXn783nE487uOYEd81iWH5AphDWQon7BZw8Ir35DXxmbUaJtinZ6H5+wxJaUc7bR8N7GHJKWEEKIeeLk6UtOiJ60GvFwcGzYgISzcnb2D8XBWzkMv2p9KRl6xyhGJBtO2rXKpIu/vRTg//xwzXruTh3b9Dy97I789EGmbSSmAb7+FLl3ghRdg06bqSSkXF6VK6quvYN++6kmphmRnd/FzzZ9vuuqTk8nT2+eyZeaDeIy/VRk2eKlkmhAWThJTwmYN61Clz1Ts1ftMFZSUMeXn3WwoL4N2dtDyw+RejIwIbLAYhRDCloyMCKhxxZTBCKM6BVx9RSFsWBMneyb2bQlAqd7ArzsS1Q1INJrUnCJSpr8EgHtpES9v/Jldfz5Dn5gdSuWQtaqoivr4Y+X/qoYOrX67TRt46imlgiorC5YtgyeegNYq992aMUOJZdw4jOW9qOyMBjrt3wo33wwtWyrVVklJ6sYpRD2SxJSwWYGeznQKUobvHUnN40xu0WXXzS3Scd9PUeyIzwLAzdGOX6dEytStQghRj27s3AwPF3uuVjSlATxd7BndqVljhCWERbu/fygOdsqr6vedSRSUSLWFtUs4W8D4mTuYeMur/Nn1Bgzlw/ucEk4qPahGj4ajR1WOsh7l58OiRfDww0rSpnNneP55WLCg+nodOsB998GXX8Lx48rliy/ghhuqNzdXm52dUr21eDGapCQ2TnyCFPcq3zlSU+Htt5UZGIWwEpKYEjatatXU+qOZl1wnu6CUiT/uZO+pc4Ay89PvD/ahTyufRolRCCFshbODHTPGdwMNl01Oacr/+XR8N5wd7BovOCEsVICHs6nlQG6Rjr/2JF9lC2HJYlLzGD9zByk5RWS7ejJr4vNkbNimzCxXYdUqJXkzfTrk5KgW6zUzGiEmBj75BIYNU5qS33orzJoFyVX27xUrqm+n0cCvv8KTTyrVUpYgKIgWM95j0CM/cv8dr7M9YoCpioqHH66+blGRVFEJiyWJKWHThodXGc539OI+Uxn5xUyYtYPolDwAvN0cmftQX7qHNG20GIUQwpYM7xjArEm98HBR+uJU9Jyq+N/DxZ4fJvVieEcZxidETU0bVDmL2OytCZTpDVdYW1iqvaeymTBrB2fPlwDQIdCdvx7pR+B1/ZSeSvPnQ3D5DNJlZcpMfm3bQlqailFfg+eeg4gI+M9/YP16pVF5BScnGDkSPv8cfv9dtRDrUxt/d3q28mVj697cc9NLHNp2UPn5qiYbAf76C0JDlVn/Fi+WXlTCosisfMKmdQrywN/dkYz8UjYdy+Th/CICm55mVEQg3UK8eODn3SRmFQLg7+7En9P60MZfploWQoiGNKJjALteHs6K6DOsik4np6gULxdHRnUKYHSnZlIpJUQttQ9057p2fmw6lsnpc0WsPJLGTV2aqx2WqEdbjmfy0G97KdLpAege4sUv90fi6VreWFujgTvvhJtuUvovffihUmHTvz8EmmG/VKNRGW64fDk88AA0rXJSuF+/6uuGhSlD30aPhiFDwM2tUUNtDBN6h7A7URm98VuSnk+ffvrilWbNUn5vy5crl+bNYepU5dKyZSNHLETtaIxGa+5+Vz/y8vLw9PQkNzcXDw8PtcMR9WhNTDqP/bEXnb7yZaDVKE11NZrK3pBBXi78Oa0PLX2s741O1A+DwUBGRgb+/v5otVKMKmpO9h1RF7L/iJraduIsE3/cBUDXFp4senwARqNR9h8rsDL6DE/NPUBpeSXcwDa+fD+pJ25OV6hBSEpSehS9+Wb1YW1Go1JB1ezKPfwa5NhTUKBUQK1YoSRWTp1Sls+fryTVKuTmwl13Kb2hRo+Gdu2UD+5WrFinJ/LdteQVl+HsoGXXy8PxdKkym5/BAO+9Bz/8cPFwPo1G+V09/LBSTWWvfm2KvHfZhtrkUWQvEDZrTUw6D83ZUy0pBZhmhKpISvm7O7HgkX6SlBJCCCGExerf2oeI5soXg4Onc4lKyFY5IlEfFuxJ5rE/9pmSUjdEBDL7/l5XTkoBhITAH39c3Gvp77+VWenefBMKCxso6nIVVVGffaYMv/P2hnHj4LvvKpNScHGvKE9PWLkSnnkG2re3+qQUKD0Yb+2u9Ior1hlYfCCl+gpaLfz3vxAfryT1brlFaaIOyu95xQplWcuWSvJPCDMjiSlhk4p1ep5dcABqUC9YpNPj7ebY4DEJIYQQQjQUjUbDQ4Mre029tfQIj/6xj8cWxPHoH/tYuO80xeXDwIRl+GlrAv/5+5DppOodPVvw9T3dcbK/xuHOhYVK/6aiInjjDQgPV/oWNdQAmzvuUJ5j+nRYswZKSyvvc3BQGpt/+im8+GLDPL+FmRAZYro+NyqZSw58srNTqsj++UdJ7r39tpKErJCWpvQVE8LMSGJK2KTlh8+QV1RWk7wU+cVlrIg+0+AxCSGEEEI0pBs7N8O7vOfQkdR8Vseksy/lPGti0pn+10Ei31vL2ph0laMUV2M0GvlszTHeWhpjWjZlQCgf3d4Fe7s6fL0zGOC22yqHeiUlKUPmhgyBAweuNVg4dgxmzrw4wdWlS/XbISHwyCNK4+7sbFi7VklatW9/bc9tZcKbedA12AuA2DN5HDqde+UNgoIurqIaN66yAX6Fzz6DV1+tXqUmVFGs07Nw32kembOXCd/v4JE5e23mpIEkpoRNWn0k3TTD09VoNbAqWj6kCSGEEMKybYzLJLuwcgazijxBRcVNflEZ0+bsYY0kp8yWwWDkzX9j+GLdcdOyZ4a35bWbOqKt6Yfby2nSRElSHDoEo0ZVLt+8GXr2VJJGmZlXf5zCQiUR8sQTylDB9u3h0UchJqb6ejfdBEOHwiefwJEjkJioDOMbN06JRVzk7t6VSaV5u5OusGYVVauo/v67+n06ndIM/513KpvIy4x+qlgTk07ke2uZ/tdBVseksTMhm9UxaTZz0kASU8Im5RSWmj6EXY3BCDlFpVdfUQghhBDCTFW0MbhS6sJY/s9zCw7YxBl6S1OmN/Cfvw/xy/ZE07LXburIM8PboanPPkvh4UpPon//rexBZTDA998rw8C++OLi6qfjx+HLL5UEiI+P0mT7m2+Uap0KF/aK6tkT1q2DZ5+Fjh1toldUXY3t2hw3R2Wo5pIDqRSU1DKBZHfBMM+9eyEjQ7l+YS8qqaJqNBW9j/OLlL+nwQZPGkhiStgkL1fHWlVMeblIjykhhBBCWK6atjEwArlF0sbA3JSU6Xn8z338b99pQPl8+vEdXXhgYFjDPKFGo1Q0RUfDRx+Bu7uyPDcXdu6sTCIZjdC7tzIz3tNPK03Ji4srH8feXhkK+NFHSsJD1Imbkz3juilN0AtK9fx7MLVuD9i3rzJk88JeVKmp1auoFi2SKqoGUrX38eWOz7Zw0kASU7VQWlr95IBeryy78DVaWtow6+p0ynKDoXKZwaAs0+nMb92yMmW5Xn9t6xqNlb+f+l73+nYB6Ms01X7vRgMY9RqMhurr6ss0DG0fYHZ/e2veTxryb38t66r5t5djxOXXVetvb477iRwj1F1XjhFyjADzP0asOJhRrVqq8nNP9TN1Rr0GjUHDykOVZ+YtbT+xtmNEbkEZU3/Zw6ojyt/EATu+uLMHd/QMrtPj1ugY4eBE6dP/QXfkGEyZAm5u8NFHlesaNUryAjCgoRQHdM1bwoMPwsKFkJWFbvUGSp/+D4ZWlTMAyjGiZute6u95R7dg07pzo5Lq/rdv3hzdC/+l9Gg8hqWVM/rp0VJqtKdsxWqYOtW0kTm87q3pGLF43xlyCytPGlzu2GzQa8g5r2f54cqTBpbwOaKmrjKPqKjq00+V/nFubsrtbduU2TZ79FCGQlf4+GPlD/HMM+DlpSzbvVs5gdC5M9x+e+W6n3+uDMN+7DHw91eWHTigVM526AATJlSu+803kJMD06YpvexAOYmxcCG0agX33Ve57qxZyhDw+++H0FBl2bFjMG+e0u9u6tTKdX/+WUmK33OPcrIDICEB5syBwEBlOHmFP/5Qhn+PHw8REcqy06fhp5+UGV6feqpy3fnzlareW26Bbt2UZRkZSu9Dd3elarfCwoXKsPMbb4TISGVZdjZ89RU4O1efjGPpUuV3NGIEDBigLMvPhxkzlJlSX3utct1Vq5Tf/ZAhygWgpAQOL21O8e5iXCLjqPiUVnzKl5KUpjgFncMl7CwAGiMU7W7HIefmjOuixAKwZQts3KicIBozpvL5PvhAeXFOnw4eyozM7NypTDTSrVv1E0UzZignlJ58Uql4BqWadvlypZr5zjsr1/3yS+VnfOQR5W8CcPiwcvKibVuYOLFy3e++U353DzxQeeIjNhYWLFD2hfvvr1x39mxlco5Jk5SZgQFOnIA//4TmzeGhhyrX/e03SE5W9skOHZRlSUnwyy/g5wePP1657ty5SuX2bbdV9rU8cwZ++EF5TTzzTOW6f/+tzBQ8dqxS0Q3Kvvvtt+DqCs8/X7nu4sXKz33DDcoJHlBO3H3+uTJ5yyuvVK67fDns26e0Lhg8WFlWWKi8PkGZbKbC2rXK32nQIGUCGFBew++9p1x/+WVwLC+a27hR+fv37avEUeH99zUUFDTh9dcrTyrKMUJZZonHiA8+UK6/+mpl1fu6dbB9O/Tvr8xqDcrrvWI/efHFaz9GLF7chP79lddMBTlGKKzlGFGx7n/+U7+fI774AjIzm/Dcc5V/ezlGKMus6RhRH58jdmzwoyw0G7smJQDoMj0oPB6AfdMCmkRUVl3k72+JodiBVO980zI5RijL1DhGLF+lZ2PWcdK8lM+mLg52DCwYxN7FbgwKa8zPEYHc99NPyk7q788PXxtITGzCY49Bq3HjICODYz0nMq9wHME9/Zn6YOWX6p9nyTEC6u8Yodd70s67KcfPnePg6VzmLi3gxH63eviuYccjj4wmcMxoSE3l8LvLWPT7edrm7WHi5ABTcKbPET0PEnJDR3BwqPUx4o8/NDRp4lLtb2Srx4ilB7Vo22owapTMUHGSDyWnvXFqnoNLq0zTY+TuaIMGWNY+k9t6tADM/7vG6dPUmFRMCZtkb6dlVEQgaLhsrwVN+T+jIgLrNsOJEEIIIYTKnB3satXCR683Xno6etFozhWW8Pfe08RnngfAw9me3x+MJNTHTb2gKr65VnXvvUoWZdo0CAiQXlENTKPRML5nkOn2utgG6DvUvLny93z6afjP80oj+6oKCpSsUMuWSuVGSkr9x2AjinX6Gvc+VoZa16IMyYJojPKOc1V5eXl4enqSmZmLj4+H6Vir1ysXrbZyVlWoLFlzcKBe19XplBI7e3vlPlCy7GVlyrYODua1blmZcp+dXeWZgtqsazRWlgRWnGWq73U3Hk/nP38fILeoDI0RDAYNWq0RowY8Xez55I5uXNc2oMZ/o8b821vzftIYf/varFuTv1FxsYGMjAyCgvyxK09kmsN+Yml/e3PbTy71e6/LfnKpv6dOZ+DMmQwCA/1xdNRecV05Rlz8e7eUY0RDve5rc+wxh7+nHCOqr9uY7w8L953m+YUHK1sDGQCjcoZOo638OmDUl6+gNdK5hQePXteGkR0DMRo0FrOfWMMxIjm7kHt/2EXi2SLQgJ+HA7890IeOzT3M4nNESYmB9PQMmjf3x95ee8V15RhR/fdeH/tJkV5Hn/fWUqwz0MTRnm3PD8fN2a7xvmt88in2L/8HbfkANANaykbeiObBqTjcMsb0y7/c37O01EBmpvLepS2/w1aPEY//sY+1cWeqDeW73LFZq4GRnQL4/r6eV/wbmcMxQqeD3Nw8/Pw8yc3NxaOiDPgyJDFVAxWJqZr8QoXlKdbpWRF9hpXRaWTmFuDn6cYNnQIZ3akZzg52aocnLITBoHw59PevfIMVoiZk3xF1IfuPqKlinZ7I99aSX4MG6Bdq5evGw9e14pbuQTjZy2ejhnYiI597f4wiLU9pIh7k5cLvD/YhzFfFSqkLyLFHfc/+ddDUDP/T8V25vWeLxnvyLVvgs89gyZLqjZMAmjVT+gU8+GDlWPALyP5TaeG+00z/62CN1//srq7c2r0R/9Z1UJs8im3vBUKglLbf2r0F303swbd3tOe7iT24tXsLSUoJIYQQwmo4O9gxY3y3q7Yx0Gjg0eta0TnI07Q8/mwBL/zvMNd9tJEft8TXfop6UWOHT+dy5/c7TUmp1n5u/P1oP7NKSgnzcE+fYNP1ebuTGvfJBw1SGgslJyuz97VsWXnfmTPw7rtK06Gnn27cuCzQjZ2b4ep49e+dGpQRPaM7NWv4oFQgiSkhhBBCCCFswPCOAcya1AsPF2VshrZi1F75/x4u9vwwqRcvjA5nyRMDmDM1kv6tfUzbp+UV886yWPp/sJ4Za46RXWCdvU7Usis+i7t/2Gn6vXYK8uCvh/vRzNNF5ciEOeoR0pS2/k0A2J14juPp+VfZogE0a6Z0BI+PVzpr33pr9bFqFV3MxWVpNRrcna88J11F7+NPx3ez2uIJSUwJIYQQQghhI0Z0DGDXy8P57K6ujOgYQI8WTRjRMYDP7urKrpeHM7yj0ltTo9EwqK0ff07ryz+P9Wdk+XKA3CIdX647zoAP1vPmv0dIzSlS68exGhuOZnDfT1GcL69Giwz15s9pffFp4qRyZMJcaTQaJkSGmG7P252sXjBaLYwaVb2KKiJCmYqxqj17YPRo+OefymZMNm721gTS85TZUu3Kmzxd7qTB8CrHYWsjPaZqQHpM2QYZ6yzqQvYfca1k3xF1IfuPqIva7j8nMvL5bmM8iw+kUFZlGikHOw23dAvi4eta06a8gkPU3JKDqUyff8D0Ox3S3o/vJvbEpQbDe9Qixx7zcK6glD7vraNUb6CpqwM7Xx5mPn3gjMaLZ2icNg1+/FG529kZOnRA06GDUlnVoQOEh0PbtuBiG1WCqTlFDPt0E0U6PVoN/P1If05lF7AqOp2colK8XBwZ1SnAYnsf1yaPcuWaMSGEEEIIIYQA2vi78+mdXfm/EW35cUsC83YnUawzoNMbWbD3NH/vO82ojoE8dn1rurTwUjtci/DnriReWXSYilKBm7o0Y8ad3XC0l2SPuLqmbo7c0CmQJQdTOVeoY9WRdMZ1ba52WIoLk1IGA+zcWXl3cTEcOKBcLtzuuefgo4+qL8/KAh8frMk7y2Io0inN4+/t25IeLZvSo2VTi2luXp/kiCeEEEIIIYSosRZNXXljXATbXhjKk0Pb4FHeH8VohJVH0hj39TYm/riTbSfOIoMzLm/mppO8/E9lUuruyBC+mNBdklKiViZEVmmCHtXITdBrQ6uFgwdh5UqMd91FWevWGO0uUQVkNIK/f/VleXng66tcBg5UZvz75BNYuhROnLh4ZkALsPlYJssPpwHg4+bIsyPaqxyRuqRiSgghhBBCCFFrPk2ceHZkex4a3Iq5UUn8uCWBjHylV8q2E1lsO5FF1xaePDqkDSM7BqDVXm4+QNtiNBr5aFUc3208aVr28HWtePGGDmgurDIR4ir6tfIh1MeVxKxCtp/MIvFsAaHmOotjeS8q44gRnM3IwN/LC01CAhw9CrGxyv9Hj0KXLtW3i4tT/s/Kgm3blEtVjo7Qrp0yHPDLL5Wm7GaspEzPG0uOmG6/OLoDnq4OKkakPrNMx3/zzTeEhobi7OxMnz59iIqKuuy6Q4YMQaPRXHQZM2aMaR2j0chrr71Gs2bNcHFxYfjw4Rw/frwxfhQhhBBCCCGsmruzAw8Nbs3m56/nvVs709LH1XTfwdO5PPL7XkZ8tokFe5IpLTOoGKn6DAYj/10UXS0p9fwN7XlpdLgkpcQ1Masm6LXl6Kj0lbr1Vnj5ZfjtN4iKgpEjL153+HBocZkhbqWlEB0Nf/8N7u7V7/vxR6Ux+9NPw3ffwYYNcOYMqFjN+eOWBOLPFgDQs2VTbu9he0P3LmR2FVPz589n+vTpzJw5kz59+vD5558zatQo4uLi8L+wpA9YuHAhpaWVU9VmZWXRtWtXxo8fb1r20Ucf8eWXX/Lrr78SFhbGq6++yqhRo4iJicHZ2blRfi4hhBBCCCGsmbODHff0CeGu3sEsP3yGbzeeJPZMHgAnMwv4z9+H+GzNMR4c1IoJkcG4OprdV5EGpdMbeG7BQRYfSAWUVjpv3dyJSX1bqhyZsHS392jBJ6viKDMY+XvvaZ4d2Q4HO7OsQbk2vXvDmjXK9fx8pYKqorqqotLq+HEICIAmF0zAsH07rF6tXKry9Kxsut6hA/TrB9dd1+A/SkpOEV+vPwEos+69dXOEVJNihompGTNmMG3aNKZMmQLAzJkzWbZsGT/99BMvvvjiRet7e3tXuz1v3jxcXV1NiSmj0cjnn3/Of//7X26++WYAfvvtNwICAli0aBETJkxo4J9ICCGEEEII22Gn1TC2a3Nu6tKMTccy+XbjSaISsgFIzS3mraUxfLX+OFMGhHFfv5Z4uTqqHHHDK9bpefyPfaw7mgEov6NPx3fllu5BKkcmrIGfuxMjOgawIjqNs+dLWBebzg2dzHs42zVzd4devZRLVWVlkJ5+8fqnT1/6cXJzYdcu5QIwadLFiakPPoDmzZXEVfv2SjKrjt5ZWtnw/L5+oUQ0r/tjWgOzSkyVlpayd+9eXnrpJdMyrVbL8OHD2bFjR40eY/bs2UyYMAE3N2VcbUJCAmlpaQwfPty0jqenJ3369GHHjh2XTEyVlJRQUlJiup2Xp5zpMRgMGAy2XX5szQwGA0ajUf7G4prI/iOulew7oi5k/xF10Rj7z+C2vgxu68veU+eYuSnelJg5V6hjxppjfL/pJHdHhjB1YCgBHtY5kiG/WMdDc/axqzw552iv5Zu7uzEsPMBiX7ty7DE/d/VqwYpopZn23KgkRnYMUDmiy2uQ/UerVXpLXfiYK1ZAZqapskoTF6dcj4tDc+pUZUwdOlTftrAQzcsvo6ky5M9YJUllrEhWdeigDDGswVDczccyTX8jHzdHnhnWxqpfQ7X52cwqMXX27Fn0ej0BAdVfRAEBARw9evSq20dFRREdHc3s2bNNy9LS0kyPceFjVtx3offff58333zzouWZmZkUFxdfNQ5hmQwGA7m5uRiNRrRaKyp9FY1C9h9xrWTfEXUh+4+oi8bcf4Jd4N0bgpnSy5ff96SxJi4bvREKSvX8uDWBX3ckMjrch3t7BhDS1HoSVDlFZfzfouPEphcC4Oqg5eNxbejsoyEjI0Pl6K6dHHvMTztPI4HujqTll7L52FkOnkimmYeT2mFdkir7T3i4cqmqsBD7+Hjsjx9H17Ej+iqvSfvoaHwv6EOlSU2F1FRYv56qaaisf/9FV6WCS5uRgfbcOcpCQ8FJ+RuUlhl4dVGMaZ3HBjSnOP8cxfn19hOanfz8mv9wZpWYqqvZs2fTuXNnIiMj6/Q4L730EtOnTzfdzsvLIzg4GD8/Pzw8POoapjBTBoMBjUaDn5+fvMGKWpP9R1wr2XdEXcj+I+pCjf3H3x/6d2xJcnYhP2xJYMHe05SUGdDpjSyJPsvSI2cZ3SmQR65rZfFDXNJyi3nijyhOZCpJKS8XB36e0ouuLbzUDaweyLHHPN3TJ58Za49jBNYnFvN/w4PVDumSzGr/CQ2FoUMvXt6rF4alS5Uqq6NHlb5WsbFozp69aNWm/fpB06aVC+bORTt9OkY7O2jVCtq3Z59rIH3zXfHzDsa9WycmD+5g9b2latPP26wSU76+vtjZ2ZF+wdjQ9PR0AgMDr7htQUEB8+bN46233qq2vGK79PR0mlWZNjI9PZ1u3bpd8rGcnJxwcro4u6zVatV/4YgGpdFo5O8srpnsP+Jayb4j6kL2H1EXau0/LX2b8M6tnXl6eDt+3pbAnB2nyC8pw2CEZYfTWHY4jcHt/Hj0utb0beVtcTPWncoqYOKPuzh9rgiAAA8n5kztQ7sA96tsaTnk2GN+7uwdwufrjmMwwoI9p3l6WFvszbQJutnvP15eMGaMcqnq7NnK5uuxsZCaitbHp/o6cXEAaPR6pSn78eP0BHpW3P8H8LE/jBsHP/xQfVujsUbDAi1Bbf62ZrUXODo60rNnT9atW2daZjAYWLduHf369bvitgsWLKCkpIR777232vKwsDACAwOrPWZeXh67du266mMKIYQQQgghGo6fuxPP39CBbS8N5fkb2uPbpLIR+uZjmdz9w05u+247a2LSMRjUm969No6m5XHHzB2mpFSItyt/P9LfqpJSwjwFejoztIMyk31aXjGbjmWqHJEV8vWFAQNg6lT45BP488+L1xkwAO65B3r0AFfXSz9ORgYUFFy8vHt3GDGifmO2AGZVMQUwffp0Jk+eTK9evYiMjOTzzz+noKDANEvffffdR1BQEO+//3617WbPns0tt9yCzwXZSo1GwzPPPMM777xD27ZtCQsL49VXX6V58+bccsstjfVjCSGEEEIIIS7Dw9mBx4a04YEBYSzYe5pZm0+SnK0kdvYn5TDttz20C2jCI9e1ZmzX5jiYaRXI/qRz3P/zbnKLdAC0D3BnztRI/K20sbswPxN6h7A2VumVNDcqmWHh5tsE3WpNmqRcgI2xabz81QpaZ52my/k0nmpehtOJY0rFVYcO1bcrKYHoaCWxZWPMLjF11113kZmZyWuvvUZaWhrdunVj5cqVpublSUlJF5WExcXFsXXrVlavXn3Jx3z++ecpKCjgoYceIicnh4EDB7Jy5cpajXkUQgghhBBCNCxnBzsm9W3J3b2DWXb4DN9tPMnRNKWB7rH080z/6yCfrj7Gw9e14s5ewTg72KkccaVtJ84y7bc9FJYqU8F3Dfbi1ym98XJ1vMqWQtSfIe39CPBwIj2vhA1xGaTnFVvtjJfmrqRMzxtLY0n18CfVw59b7+yKU48WlStcOGtdZia0aQOdOjVuoGZAYzQaLaMmVkV5eXl4enqSm5srzc+tmMFgICMjA39/f/Md6yzMluw/4lrJviPqQvYfUReWsP8YjUbWH83g240n2XvqXLX7fNwceWBgGPf2bYmni4NKESpWHUnjyT/3U6pXvmj2b+3DrPt60cTJ7OoA6oUl7Du2bMbqOL5cfwKA50a244mhbVWOqDpb2X++Xn+cT1YfA6B3aFP+erhfzfrlWUmfqdrkUax3LxBCCCGEEEJYNI1Gw7DwAP73aH/+ergfQ9r7me7LKijl41VxDPhgPe+viCUjv1iVGBfuO81jf+wzJaVGdAzgp/t7W21SSpi/O3sHm/Ia83YnW0x/NmuSnF3I1xuU5KCdVsNbN3eq+SQOVpCUqi1JTAkhhBBCCCHMXmSYN79MiWTZUwMZ27U5FTOtny8p4/tN8Qz8cAOv/HOYpKzCRovpl20JTP/rIPryL/63dQ/iu4k9zGqIobA9LZq6MqitksQ9fa6IrSfOqhyR7Xl7aQzFOiVZfV+/loQ3k5FXVyKJKSGEEEIIIYTFiGjuyVd3d2f9s0O4OzIEx/JG6KVlBv7YlcSQTzbw1Nz9xJ7Ja7AYjEYjX607zhv/xpiWTe7Xkk/Gd8XeTBuzC9tyd+9g0/V5u5NUjMT2bDiaweqYdAB8mzjxfyPaqRyR+ZOjphBCCCGEEMLihPq68f5tndn6wvU8PLgVbo5KlZLBCEsOpjL6iy088Mtudidm1+vzGo1G3l0Wy6drjpmWPTm0DW+Mi0Crtb0hOMI8DQsPwLeJ0nh/TUw6Z8+XqM4oRGwAACqASURBVByRbSjW6Xnj3yOm26+M6YCHs7o98CyBJKaEEEIIIYQQFsvfw5mXbgxn+4vDeG5kO7zdKmfBW380g/EzdzB+5nY2HM2grvM+6Q1GXvjfIX7cmmBa9t8x4Tw7sn3N+8cI0Qgc7bXc3lOZAU6nN/K/vadVjsg2zNocz6ny4cSRod7c0i1I5YgsgySmhBBCCCGEEBbP09WBJ4a2ZdsLQ3ljbEeCvFxM9+1OPMeUX3Yz+ostLD6QQpnecIVHurSSMj1Pzt3HX3uUL/haDXx4e2ceHNSq3n4GIerThN4hpuvzdifXOTErriw5u5BvqjY8vyVCEtY1JFNFCCGEEEIIIayGi6Md9w8IY2Lfliw5kMp3m05yIuM8AEfT8nl63gE+XX2Mhwa34o6eLS5qVF6s07P88BlWH0knp7AUL1dHhrT349+DqWw7mQWAg52GLyZ058bOzRr95xOipsJ83ejXyocd8VkknC1gZ3w2/Vr7qB2W1XpraQwlZUrS+/7+oXQIlIbnNSWJKSGEEEIIIYTVcbBThjLd2j2INbHpfLvxJAeTcwBIyi7kv4ui+XztcaYODOPeviG4OzuwJiadZxccIK+oDK1G6Vel1cDKI2mmx3V20PL9pF5c185PpZ9MiJqbEBnMjngloTpvd5IkphrI+qPprClveO7n7sQzw9uqHJFlkcSUEEIIIYQQwmpptRpGRQQysmMAO+Kz+G7jSbYcPwvA2fMlfLjyKN9uPMGgtr6sOFyZgDIYq/9f4alhbSUpJSzGqIhAvFwdyCnUsSI6jTfLqwBF/SnW6XljSeUMna/cGI67NDyvFekxJYQQQgghhLB6Go2G/q19mTO1D/8+MZAbOwdS0f4lv7iM5YfTMAJX6sKjAb7fdJJinb4RIhai7pwd7Litu9IEvbTMwMJ9KSpHZH2+3xRPUnZ5w/Mwb27u1lzliCyPJKaEEEIIIYQQNqVzC0++ndiTtdOv465ewdjVsD+xEcgtKmNF9JkGjU+I+nR3ZLDp+rzdSdIEvR4lZRXy7cbKhudv39xJGp5fA0lMCSGEEEIIIWxSa78mfHhHFwbVYmieVgOrotMbMCoh6lfbAHd6tWwKwLH08+xLylE3ICvy1tIjpobnU/qH0j7QXeWILJMkpoQQQgghhBA2rbi05kPzDEbIKSptwGiEqH8TIkNM1+dGJakYifVYF5vO2tgMAPzdnXhaGp5fM0lMCSGEEEIIIWyal6sj2hqOvtFqwMtFmkcLyzKmczPcnZW5z5YeSiWvWKdyRJatWKfnjX+PmG6/MkYanteFJKaEEEIIIYQQNm1kRMBFs+9djsEIozoFNGxAQtQzF0c7bukWBECxzsDiA6kqR2TZZm46SXJ2EQB9W3kzrqs0PK8LSUwJIYQQQgghbNqNnZvh4WLP1YqmNICniz2jOzVrjLCEqFcTqjZBl+F810xpeH4SAHuthrek4XmdSWJKCCGEEEIIYdOcHeyYMb4baLhsckpT/s+n47vh7GDXeMEJUU8imnvSpYUnAEdS8zh8OlfliCzTm/8eobSi4fmAUNoFSMPzupLElBBCCCGEEMLmDe8YwKxJvfBwUfrwVPScqvjfw8WeHyb1YnhHGcYnLNfdVZug75aqqdpaG5POuqNKw/MADyeeHt5O5Yisg73aAQghhBBCCCGEORjRMYBdLw9nRfQZVkWnk1NUipeLI6M6BTC6UzOplBIWb2zX5ry9NIbCUj2L96fwyo3huDlJWqAmLm543pEm8rurF/JbFEIIIYQQQohyzg523Nq9Bbd2b6F2KELUuyZO9ozr2px5u5MpKNWz9FAqd/UOufqGgu82nuT0OaXheb9WPoztIr3m6osM5RNCCCGEEEIIIWzEhKrD+aKSVYzEcpzKKuC7TVUbnkdIw/N6JIkpIYQQQgghhBDCRnRt4UmHQKVh94HkHI6m5akckXkzGo28saSy4fnUgWG0lYbn9UoSU0IIIYQQQgghhI3QaDTVmqDPk6qpK1obm8GGuEwAAj2ceXJYW5Ujsj6SmBJCCCGEEEIIIWzILd2DcLJX0gEL952mWKdXOSLzVFSq540llQ3P/3tTuDQ8bwCSmBJCCCGEEEIIIWyIp4sDY8qbd+cVl7H88BmVIzJP3208QUqO0vC8f2sfxnSWhucNQRJTQgghhBBCCCGEjZHhfFeWeLaAmZviAWl43tAkMSWEEEIIIYQQQtiYXi2b0sa/CQBRidmcyDivckTmw2g08sa/RyjVlzc8HxRGG39peN5QJDElhBBCCCGEEELYGI1Gw4Tewabb83cnqRiNeVkTk87GKg3PnxoqDc8bkiSmhBBCCCGEEEIIG3RbjxY42ilpgf/tS6GkTJqgF5XqefPfGNPtV2/qiJs0PG9QkpgSQgghhBBCCCFskLebI6M6BQKQXVDKmph0lSNS37dVGp4PbOPLjZ0DVY7I+kliSgghhBBCCCGEsFF3VxnONzfKtofzJZwt4PvyhucOdhreGCcNzxuDJKaEEEIIIYQQQggb1beVDy19XAHYdiKLU1kFKkekDqPRyOtLqjQ8H9jK1BxeNCxJTAkhhBBCCCGEEDZKq9VwV7Um6MkqRqOeVUfS2XxMaXjezNOZJ4e2UTki2yGJKSGEEEIIIYQQwobd0bMF9lplyNqCvafRlVcN2YqiUj1vL5WG52qRxJQQQgghhBBCCGHD/N2dGR4eAEBmfgnrj2aoHFHj+mZDZcPzQW19Gd1JGp43JklMCSGEEEIIIYQQNm5CZOVwvnk21AQ9PvM8szZLw3M1SWJKCCGEEEIIIYSwcYPa+hHk5QLAxmOZpgoia3Zhw/Npg1rR2k8anjc2SUwJIYQQQgghhBA2zk6r4c5eStWU0Qh/2UAT9FVH0thy/CwAzT2deUIanqtCElNCCCGEEEIIIYTgzt4tKO+BzoI9yegNRnUDakCFpWW89W9lw/PXxnbE1VEanqtBElNCCCGEEEIIIYSgmacLQ9r7A5CaW8zmY5kqR9Rwvl5/gtTcYkBpeD4qQhqeq0USU0IIIYQQQgghhADg7sgQ0/W5VtoE/WTmeX7YUtnw/E1peK4qSUwJIYQQQgghhBACgOvb+xHg4QTAuqMZZOQVqxxR/TIajbyx5Ag6vTJM8aHBrWglDc9VJYkpIYQQQgghhBBCAGBvp2V8T6UJut5gZMHe0ypHVL9WRlc2PA/ycuHx66XhudokMSWEEEIIIYQQQgiTu3oHm67P252EwUqaoBeWlvHW0sqG56/eJA3PzYEkpoQQQgghhBBCCGES7O3KoLa+ACRnF7H9ZJbKEdWPr9af4Ex5w/Pr2vkxKiJA5YgESGJKCCGEEEIIIYQQF5jQu0oT9N2W3wT9RMZ5fixveO5op+UNaXhuNiQxJYQQQgghhBBCiGpGdAzAx80RgNVH0sg6X6JyRNfuwobnD1/XijBfN5WjEhUkMSWEEEIIIYQQQohqHO213NGzBQA6vZH/7bPcJujLD6ex9URlw/PHhkjDc3MiiSkhhBBCCCGEEEJcpHoT9GSMRstrgl5QUsbbVRqevza2Iy6OdipGJC4kiSkhhBBCCCGEEEJcpJVfE/qEeQMQn1lAVEK2yhHV3lfrT5CWpzQ8H9Lej5EdpeG5uZHElBBCCCGEEEIIIS7p7sjKJujzdierGEntncjIr97wfKw0PDdHkpgSQgghhBBCCCHEJd3QKRBPFwcAlh8+Q26hTuWIasZoNPL6kiOUGZThh49c14pQaXhuliQxJYQQQgghhBBCiEtydrDjth5BAJSUGfhnv2U0QV92+AzbTmQB0KKpC49Kw3OzJYkpIYQQQgghhBBCXFbV4Xxzo8y/Cfr5Cxqevz42QhqemzFJTAkhhBBCCCGEEOKy2gW40yPEC4C49Hz2J+eoGs/VfLXuOOl5JQBc396P4eH+KkckrkQSU0IIIYQQQgghhLiiCVWboEclqRjJlR1Pz2f21gQAHO21vDFOGp6bO0lMCSGEEEIIIYQQ4opu6tIMdyd7AP49eIb8YvNrgn5xw/PWtPSRhufmThJTQgghhBBCCCGEuCJXR3vGdWsOQJFOz5KDqSpHdLGlh86w/WRlw/PHhrRWOSJRE5KYEkIIIYQQQgghxFXdXW04X7KKkVzsfEkZ7yyrbHj+xtgInB2k4bklkMSUEEIIIYQQQgghrqpTkCedgzwBOJySS3RKrsoRVfqySsPzYR38Gd4xQOWIRE1JYkoIIYQQQgghhBA1MiEy2HR9rpk0QT+Wns9PVRqevz42QuWIRG1IYkoIIYQQQgghhBA1Mq5rc1zKh8gtPpBKYWmZqvEYjUZeWxxtanj+2JDWhPi4qhqTqB1JTAkhhBBCCCGEEKJG3J0dGNu1GaD0dVp66Iyq8Sw5mMrO+GwAgr1deOQ6aXhuaSQxJYQQQgghhBBCiBqr3gRdveF850vKeHdZrOm2NDy3TJKYEkIIIYQQQgghRI11C/aiQ6A7APuScohLy1clji/WHiMjX2l4Pjzcn2Hh0vDcEkliSgghhBBCCCGEEDWm0WiY0FvdJuhxafn8tC0RACdpeG7RJDElhBBCCCGEEEKIWrm1ewuc7JWUwj/7UyjW6RvtuSsanutNDc/bEOwtDc8tlSSmhBBCCCGEEEIIUSuerg7c2Flpgp5bpGNldFqjPfeSg6nsSlAanod4u/Lwda0a7blF/ZPElBBCCCGEEEIIIWpNjeF8+cU63qna8HxcR2l4buEkMSWEEEIIIYQQQohaiwzzppWfGwC7ErKJzzzf4M/5+drjZJY3PB/RMYChHaThuaWTxJQQQgghhBBCCCFqTaPRcHfvENPt+buTG/T5jqbl8cv2REBpeP7aTR0b9PlE45DElBBCCCGEEEIIIa7JbT2CcLDTAPD33tOUlhka5HmUhudHTA3PH79eGp5bC0lMCSGEEEIIIYQQ4pr4NHFiZEQgAFkFpayJSW+Q51l8IJWo8obnLX1ceWiwNDy3FpKYEkIIIYQQQgghxDWrOpxv3u76b4KeV6zj3eVVG55HSMNzKyKJKSGEEEIIIYQQQlyz/q19CPZ2AWDL8bMkZxfW6+N/vqay4fnIjgFc396/Xh9fqEsSU0IIIYQQQgghhLhmWq2GCQ3UBD32TB6/7kgEwNlBy6vS8NzqSGJKCCGEEEIIIYQQdTK+ZwvstEoT9L/2JFOmr3sTdKXhebSp4fkT0vDcKkliSgghhBBCCCGEEHXi7+HMsA7KELuM/BLWH82o82P+sz+F3YnnAAj1cWWaNDy3SpKYEkIIIYQQQgghRJ3dHVm1CXrdhvPlFet4b/lR0+03xkXgZC8Nz62RJKaEEEIIIYQQQghRZ4Pb+dHc0xmAjXEZnMktuubH+mzNMc6eVxqej4oIYIg0PLdakpgSQgghhBBCCCFEndlpNYzvFQyAwQh/7T59TY8Tk5rHr9sTAWl4bgskMSWEEEIIIYQQQoh6cWfvYMp7oPPXnmRT4/Kaqmh4XrHZk0Pb0qKpNDy3ZpKYEkIIIYQQQgghRL0I8nLhunZ+AKTkFLH5eGattl+4L4U9p5SG52G+bjw4KKzeYxTmRRJTQgghhBBCCCGEqDcTqjZBj0qq8Xa5RTreXxFrui0Nz22DJKaEEEIIIYQQQghRb4Z28MfP3QmAdbEZZOQX12g7peF5KQCjOwWaKq+EdZPElBBCCCGEEEIIIeqNg52W8T1bAFBmMPL33qs3QY9JzeO3HYkAuDjY8V9peG4zJDElhBBCCCGEEEKIenVX72DT9fm7kzFcoQm6wVC94fkTQ9sQ5OXS0CEKMyGJKSGEEEIIIYQQQtSrlj5uDGzjC8CprEJ2xmeZ7jMYDdXWXbi/suF5K2l4bnPs1Q5ACCGEEEIIIYQQ1mdCZDBbT5ylRHOCR5bOQet8lJjMGHQGHQ5aBzr6dSQyaABb9kcALQFpeG6LzK5i6ptvviE0NBRnZ2f69OlDVFTUFdfPycnh8ccfp1mzZjg5OdGuXTuWL19uul+v1/Pqq68SFhaGi4sLrVu35u2338ZovHwZoRBCCCGEEEIIIeqmVWA+Z11eIs35GQ7n/M3B9IPoDDoAdAYdB9MPMnvf9xw1Pk6a4wsMaK9jsDQ8tzlmVTE1f/58pk+fzsyZM+nTpw+ff/45o0aNIi4uDn9//4vWLy0tZcSIEfj7+/P3338TFBTEqVOn8PLyMq3z4Ycf8t133/Hrr78SERHBnj17mDJlCp6enjz11FON+NMJIYQQQgghhBC24c/Df/LA4gfQUaYs0OgvuZ4BZXmJNpa/UyZw0+Gfubvz3Y0VpjADZpWYmjFjBtOmTWPKlCkAzJw5k2XLlvHTTz/x4osvXrT+Tz/9RHZ2Ntu3b8fBwQGA0NDQauts376dm2++mTFjxpjunzt37lUrsYQQQgghhBBCCFF7fx7+k3sX3ouRWoxU0hgo1ZcwceFEjBi5p/M9DRegMCtmk5gqLS1l7969vPTSS6ZlWq2W4cOHs2PHjktus2TJEvr168fjjz/O4sWL8fPz45577uGFF17Azk4Zk9q/f39mzZrFsWPHaNeuHQcPHmTr1q3MmDHjsrGUlJRQUlJiup2XlweAwWDAYDBcbjNh4QwGA0ajUf7G4prI/iOulew7oi5k/xF1IfuPuFay74grOZ51nAcWP1C7pFQVRow8sPgBejXrRRvvNvUcnWgstTk+mE1i6uzZs+j1egICAqotDwgI4OjRo5fcJj4+nvXr1zNx4kSWL1/OiRMneOyxx9DpdLz++usAvPj/7d17UJTX/cfxz7LAggpeiFzWQEW0avAKGCsYL1UbGGO0SWsk0SCdab3gBU2sJBW8a700k6pRo3XAxJAmMz/RqjHGeIs6ao2ETDVGcbylGgStAkqcILu/P1KoKygKyLOr79dM/tizz3P2s+Q7K34952xKioqKitSuXTuZzWaVlZVp7ty5euWVV+6aZf78+Zo5c2al8YKCAt28ebMW7xLOzGazqbCwUHa7XW5uTnf8Gpwc9YOaonZQG9QPaoP6QU1RO7iXkRtH6pbtVq3muGW7pYT/S1DW4Kw6SoX6VlxcfN/XOk1jqiZsNpv8/f21atUqmc1mRUZG6sKFC1q0aFFFY+rjjz/WBx98oMzMTIWHhysnJ0fJycmyWq1KSEioct433nhDkydPrnhcVFSk4OBgNW/eXL6+vvXy3lD/bDabTCaTmjdvzh+weGDUD2qK2kFtUD+oDeoHNUXt4G6OfH9EB/MO1nqeMnuZDuYd1L/L/q2IoIg6SIb65uXldd/XOk1j6oknnpDZbNalS5ccxi9duqTAwMAq7wkKCpKHh0fFtj1Jat++vfLy8vTjjz/K09NTU6ZMUUpKioYNGyZJ6tixo86dO6f58+fftTFlsVhksVgqjbu5ufHB+4gzmUz8f0aNUT+oKWoHtUH9oDaoH9QUtYOqvPf1e3J3c6/1iilJcndz19qv1yqqRVQdJEN9e5DPBqf5FPH09FRkZKR27NhRMWaz2bRjxw716NGjyntiYmJ06tQph72LJ0+eVFBQkDw9PSVJJSUllX4gZrOZ/dAAAAAAANShvef31klTSvppO9++7/bVyVxwbk7TmJKkyZMna/Xq1Vq7dq2OHz+uMWPG6MaNGxXf0vfqq686HI4+ZswY/ec//9HEiRN18uRJbdmyRfPmzVNSUlLFNYMGDdLcuXO1ZcsWnT17VllZWXrrrbf061//ut7fHwAAAAAAj6pvCr6p0/mO5R+r0/ngnJxmK58kvfTSSyooKFBaWpry8vLUpUsXffrppxUHop8/f95h9VNwcLC2bdumSZMmqVOnTmrRooUmTpyoqVOnVlyzdOlSpaamauzYscrPz5fVatWoUaOUlpZW7+8PAAAAAIBHkc1uU6mttE7nLLWVyma3yc3kVGtqUMdMdru9Zt/h+BgpKipS48aNVVhYyOHnjzCbzab8/Hz5+/uzVx4PjPpBTVE7qA3qB7VB/aCmqB3cjedszzptTnm4eejH1B/rbD7Unwfpo/ApAgAAAAAAau2p5k/V6Xzh/uF1Oh+cE40pAAAAAABQa8+EPCN3t7o5McjdzV09g3vWyVxwbjSmAAAAAABArSV2TazTb+VL7JpYJ3PBudGYAgAAAAAAtRYRFKFeIb1qvWrK3c1dvUJ6KSIooo6SwZnRmAIAAAAAAHVizeA1MpvMtZrDbDJrzeA1dZQIzo7GFAAAAAAAqBOtm7VW+uB0mWSq0f0mmZQ+OF2tm7Wu42RwVjSmAAAAAABAnYnvGK91L6yTxWy572197m7uspgt+uCFDxTfMf4hJ4QzoTEFAAAAAADq1MsdX9bRsUcV/WS0JN21QVU+HhMco6Njj9KUegzVzfc4AgAAAAAA3KZ1s9bak7hH2d9nK/2rdO07v0/HCo6p1FYqDzcPhfuHq2dwTyV2TeSg88cYjSkAAAAAAPDQRARFVDSebDab8i7lKTAgUG5ubOICW/kAAAAAAEA9cjPRisD/UA0AAAAAAAAwBI0pAAAAAAAAGILGFAAAAAAAAAxBYwoAAAAAAACGoDEFAAAAAAAAQ9CYAgAAAAAAgCFoTAEAAAAAAMAQNKYAAAAAAABgCBpTAAAAAAAAMIS70QFcgd1ulyQVFRUZnAQPk81mU3Fxsby8vOTmRs8WD4b6QU1RO6gN6ge1Qf2gpqgd1Ab183go75+U91PuhcbUfSguLpYkBQcHG5wEAAAAAADANRQXF6tx48b3vMZkv5/21WPOZrPp4sWL8vHxkclkMjoOHpKioiIFBwfru+++k6+vr9Fx4GKoH9QUtYPaoH5QG9QPaoraQW1QP48Hu92u4uJiWa3WalfGsWLqPri5uenJJ580Ogbqia+vLx+QqDHqBzVF7aA2qB/UBvWDmqJ2UBvUz6OvupVS5djQCQAAAAAAAEPQmAIAAAAAAIAhaEwB/2WxWDR9+nRZLBajo8AFUT+oKWoHtUH9oDaoH9QUtYPaoH5wJw4/BwAAAAAAgCFYMQUAAAAAAABD0JgCAAAAAACAIWhMAQAAAAAAwBA0pvDYmz9/vrp16yYfHx/5+/tryJAhOnHihNGx4IL+/Oc/y2QyKTk52egocBEXLlzQ8OHD5efnJ29vb3Xs2FFffvml0bHgAsrKypSamqrQ0FB5e3srLCxMs2fPFkeH4k5ffPGFBg0aJKvVKpPJpA0bNjg8b7fblZaWpqCgIHl7e6t///7Kzc01Jiyczr3qp7S0VFOnTlXHjh3VsGFDWa1Wvfrqq7p48aJxgeFUqvv8ud3o0aNlMpn09ttv11s+OA8aU3js7dmzR0lJSTp48KC2b9+u0tJS/epXv9KNGzeMjgYXcvjwYb377rvq1KmT0VHgIq5evaqYmBh5eHho69at+uabb/SXv/xFTZs2NToaXMCCBQu0YsUKLVu2TMePH9eCBQu0cOFCLV261OhocDI3btxQ586d9c4771T5/MKFC7VkyRKtXLlShw4dUsOGDfXss8/q5s2b9ZwUzuhe9VNSUqLs7GylpqYqOztb69ev14kTJ/T8888bkBTOqLrPn3JZWVk6ePCgrFZrPSWDs+Fb+YA7FBQUyN/fX3v27FGvXr2MjgMXcP36dUVERGj58uWaM2eOunTpwr/2oFopKSnav3+/9u7da3QUuKDnnntOAQEBWrNmTcXYiy++KG9vb61bt87AZHBmJpNJWVlZGjJkiKSfVktZrVa99tprev311yVJhYWFCggIUEZGhoYNG2ZgWjibO+unKocPH9bTTz+tc+fOKSQkpP7CwendrX4uXLig7t27a9u2bRo4cKCSk5PZffAYYsUUcIfCwkJJUrNmzQxOAleRlJSkgQMHqn///kZHgQv5xz/+oaioKP32t7+Vv7+/unbtqtWrVxsdCy4iOjpaO3bs0MmTJyVJX3/9tfbt26e4uDiDk8GVnDlzRnl5eQ5/fjVu3Fjdu3fXgQMHDEwGV1VYWCiTyaQmTZoYHQUuwGazacSIEZoyZYrCw8ONjgMDuRsdAHAmNptNycnJiomJUYcOHYyOAxfw97//XdnZ2Tp8+LDRUeBiTp8+rRUrVmjy5Ml68803dfjwYU2YMEGenp5KSEgwOh6cXEpKioqKitSuXTuZzWaVlZVp7ty5euWVV4yOBheSl5cnSQoICHAYDwgIqHgOuF83b97U1KlTFR8fL19fX6PjwAUsWLBA7u7umjBhgtFRYDAaU8BtkpKSdPToUe3bt8/oKHAB3333nSZOnKjt27fLy8vL6DhwMTabTVFRUZo3b54kqWvXrjp69KhWrlxJYwrV+vjjj/XBBx8oMzNT4eHhysnJUXJysqxWK/UDoN6VlpZq6NChstvtWrFihdFx4AKOHDmiv/71r8rOzpbJZDI6DgzGVj7gv8aNG6fNmzdr165devLJJ42OAxdw5MgR5efnKyIiQu7u7nJ3d9eePXu0ZMkSubu7q6yszOiIcGJBQUF66qmnHMbat2+v8+fPG5QIrmTKlClKSUnRsGHD1LFjR40YMUKTJk3S/PnzjY4GFxIYGChJunTpksP4pUuXKp4DqlPelDp37py2b9/Oaincl7179yo/P18hISEVv0efO3dOr732mlq2bGl0PNQzVkzhsWe32zV+/HhlZWVp9+7dCg0NNToSXES/fv30r3/9y2EsMTFR7dq109SpU2U2mw1KBlcQExOjEydOOIydPHlSP/vZzwxKBFdSUlIiNzfHf180m82y2WwGJYIrCg0NVWBgoHbs2KEuXbpIkoqKinTo0CGNGTPG2HBwCeVNqdzcXO3atUt+fn5GR4KLGDFiRKXzWZ999lmNGDFCiYmJBqWCUWhM4bGXlJSkzMxMbdy4UT4+PhVnKjRu3Fje3t4Gp4Mz8/HxqXQWWcOGDeXn58cZZajWpEmTFB0drXnz5mno0KH65z//qVWrVmnVqlVGR4MLGDRokObOnauQkBCFh4frq6++0ltvvaXf/e53RkeDk7l+/bpOnTpV8fjMmTPKyclRs2bNFBISouTkZM2ZM0dt2rRRaGioUlNTZbVa7/nNa3h83Kt+goKC9Jvf/EbZ2dnavHmzysrKKn6PbtasmTw9PY2KDSdR3efPnY1MDw8PBQYGqm3btvUdFQYz2e12u9EhACPdbU9zenq6Ro4cWb9h4PL69OmjLl266O233zY6ClzA5s2b9cYbbyg3N1ehoaGaPHmyfv/73xsdCy6guLhYqampysrKUn5+vqxWq+Lj45WWlsZfBuFg9+7d6tu3b6XxhIQEZWRkyG63a/r06Vq1apWuXbumnj17avny5fr5z39uQFo4m3vVz4wZM+6602DXrl3q06fPQ04HZ1fd58+dWrZsqeTkZCUnJz/8cHAqNKYAAAAAAABgCA4/BwAAAAAAgCFoTAEAAAAAAMAQNKYAAAAAAABgCBpTAAAAAAAAMASNKQAAAAAAABiCxhQAAAAAAAAMQWMKAAAAAAAAhqAxBQAAAAAAAEPQmAIAAKhDI0eOVMuWLWt074wZM2Qymeo2EAAAgBOjMQUAAB4LJpPpvv7bvXu30VENs2nTJvXu3Vv+/v5q0KCBWrVqpaFDh+rTTz+tuObixYuaMWOGcnJyjAsKAAAeGSa73W43OgQAAMDDtm7dOofH7733nrZv367333/fYXzAgAEKCAio8euUlpbKZrPJYrE88L23bt3SrVu35OXlVePXr6nFixdrypQp6t27twYPHqwGDRro1KlT+vzzz9W5c2dlZGRIkr788kt169ZN6enpGjlyZL3nBAAAjxZ3owMAAADUh+HDhzs8PnjwoLZv315p/E4lJSVq0KDBfb+Oh4dHjfJJkru7u9zd6//Xs1u3bmn27NkaMGCAPvvss0rP5+fn13smAADweGArHwAAwH/16dNHHTp00JEjR9SrVy81aNBAb775piRp48aNGjhwoKxWqywWi8LCwjR79myVlZU5zHHnGVNnz56VyWTS4sWLtWrVKoWFhclisahbt246fPiww71VnTFlMpk0btw4bdiwQR06dJDFYlF4eLjD9rpyu3fvVlRUlLy8vBQWFqZ33333vs6tunz5soqKihQTE1Pl8/7+/hXzd+vWTZKUmJhYsf2xfDWVJB06dEixsbFq3LixGjRooN69e2v//v1Vvs9vv/1WQ4cOla+vr/z8/DRx4kTdvHnznlkBAMCjhRVTAAAAt7ly5Yri4uI0bNgwDR8+vGJbX0ZGhho1aqTJkyerUaNG2rlzp9LS0lRUVKRFixZVO29mZqaKi4s1atQomUwmLVy4UC+88IJOnz5d7Sqrffv2af369Ro7dqx8fHy0ZMkSvfjiizp//rz8/PwkSV999ZViY2MVFBSkmTNnqqysTLNmzVLz5s2rzebv7y9vb29t2rRJ48ePV7Nmzaq8rn379po1a5bS0tL0hz/8Qc8884wkKTo6WpK0c+dOxcXFKTIyUtOnT5ebm5vS09P1y1/+Unv37tXTTz/tMN/QoUPVsmVLzZ8/XwcPHtSSJUt09epVvffee9VmBgAAjwYaUwAAALfJy8vTypUrNWrUKIfxzMxMeXt7VzwePXq0Ro8ereXLl2vOnDnVnil1/vx55ebmqmnTppKktm3bavDgwdq2bZuee+65e957/PhxffPNNwoLC5Mk9e3bV507d9aHH36ocePGSZKmT58us9ms/fv3y2q1Svqp8dO+fftq37Obm5umTJmiWbNmKSQkRL169VLPnj0VGxuriIiIiusCAgIUFxentLQ09ejRw2EbpN1u1+jRo9W3b19t3bq1YpXWqFGjFB4ermnTplXaJhgaGqqNGzdKkpKSkuTr66vly5fr9ddfV6dOnarNDQAAXB9b+QAAAG5jsViUmJhYafz2plRxcbEuX76sZ555RiUlJfr222+rnfell16qaEpJqlhtdPr06Wrv7d+/f0VTSpI6deokX1/finvLysr0+eefa8iQIRVNKUlq3bq14uLiqp1fkmbOnKnMzEx17dpV27Zt05/+9CdFRkYqIiJCx48fr/b+nJwc5ebm6uWXX9aVK1d0+fJlXb58WTdu3FC/fv30xRdfyGazOdyTlJTk8Hj8+PGSpE8++eS+MgMAANfHiikAAIDbtGjRQp6enpXGjx07pmnTpmnnzp0qKipyeK6wsLDaeUNCQhwelzeprl69+sD3lt9ffm9+fr5++OEHtW7dutJ1VY3dTXx8vOLj41VUVKRDhw4pIyNDmZmZGjRokI4ePXrPbwvMzc2VJCUkJNz1msLCQofmXJs2bRyeDwsLk5ubm86ePXvfmQEAgGujMQUAAHCb21dGlbt27Zp69+4tX19fzZo1S2FhYfLy8lJ2dramTp1aaSVQVcxmc5Xjdrv9od5bE76+vhowYIAGDBggDw8PrV27VocOHVLv3r3vek/5z2DRokXq0qVLldc0atTonq9b3SHtAADg0UNjCgAAoBq7d+/WlStXtH79evXq1ati/MyZMwam+h9/f395eXnp1KlTlZ6rauxBREVFae3atfr+++8l3b15VL7V0NfXV/3797+vuXNzcxUaGuqQ1WazOXyrIQAAeLRxxhQAAEA1ylcs3b5C6ccff9Ty5cuNiuTAbDarf//+2rBhgy5evFgxfurUKW3durXa+0tKSnTgwIEqnyu/v23btpKkhg0bSvppFdntIiMjFRYWpsWLF+v69euV5ikoKKg09s477zg8Xrp0qSTd97lYAADA9bFiCgAAoBrR0dFq2rSpEhISNGHCBJlMJr3//vsPbStdTcyYMUOfffaZYmJiNGbMGJWVlWnZsmXq0KGDcnJy7nlvSUmJoqOj9Ytf/EKxsbEKDg7WtWvXtGHDBu3du1dDhgxR165dJf20MqpJkyZauXKlfHx81LBhQ3Xv3l2hoaH629/+pri4OIWHhysxMVEtWrTQhQsXtGvXLvn6+mrTpk0Or3vmzBk9//zzio2N1YEDB7Ru3Tq9/PLL6ty588P6MQEAACfDiikAAIBq+Pn5afPmzQoKCtK0adO0ePFiDRgwQAsXLjQ6WoXIyEht3bpVTZs2VWpqqtasWaNZs2apX79+9zy0XJKaNGmi1atXKzAwUOnp6Ro7dqxSU1N1/fp1LVq0SB999FHFteVnTpnNZo0ePVrx8fHas2ePJKlPnz46cOCAoqKitGzZMo0fP14ZGRkKDAzUpEmTKr3uRx99JIvFopSUFG3ZskXjxo3TmjVr6vYHAwAAnJrJ7kz/1AcAAIA6NWTIEB07dqziW/OcwYwZMzRz5kwVFBToiSeeMDoOAAAwECumAAAAHhE//PCDw+Pc3Fx98skn6tOnjzGBAAAAqsEZUwAAAI+IVq1aaeTIkWrVqpXOnTunFStWyNPTU3/84x+NjgYAAFAlGlMAAACPiNjYWH344YfKy8uTxWJRjx49NG/ePLVp08boaAAAAFXijCkAAAAAAAAYgjOmAAAAAAAAYAgaUwAAAAAAADAEjSkAAAAAAAAYgsYUAAAAAAAADEFjCgAAAAAAAIagMQUAAAAAAABD0JgCAAAAAACAIWhMAQAAAAAAwBA0pgAAAAAAAGCI/wd0xyaiXGyIYQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DPO Training Loss Statistics\n",
            "Initial loss: 0.7517\n",
            "Final loss: 0.7030\n",
            "Lowest loss: 0.6790 (Step 14)\n",
            "Highest loss: 0.7702 (Step 4)\n",
            "Average loss: 0.7148\n",
            "Loss standard deviation: 0.0216\n",
            "Overall improvement: 6.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FastVLM DPO vs SFT Evaluation"
      ],
      "metadata": {
        "id": "MV_3T0Td57Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HF_HUB_OFFLINE\"] = \"1\"\n",
        "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
        "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
        "\n",
        "PROJECT = \"/content/drive/MyDrive/FastVLM_RLHF\"\n",
        "GT_DIR = f\"{PROJECT}/gt_json\"\n",
        "SFT_PRED_DIR = f\"{PROJECT}/preds_1.5b\"\n",
        "DPO_PRED_DIR = f\"{PROJECT}/preds_dpo\"\n",
        "OUT_DIR = f\"{PROJECT}/outputs\"\n",
        "os.makedirs(DPO_PRED_DIR, exist_ok=True)\n",
        "\n",
        "# Step 1: Validate model and tokenizer\n",
        "print(\"Validating model:\")\n",
        "\n",
        "if 'model' not in globals() or model is None:\n",
        "    raise RuntimeError(\"Model not found! Please run DPO training first.\")\n",
        "\n",
        "if 'tokenizer' not in globals() or tokenizer is None:\n",
        "    raise RuntimeError(\"Tokenizer not found!\")\n",
        "\n",
        "print(f\"Model: {type(model).__name__}\")\n",
        "print(f\"Tokenizer: {type(tokenizer).__name__}\")\n",
        "print(f\"Device: {model.device}\")\n",
        "\n",
        "# Extract base model\n",
        "print(\"\\nExtracting base model...\")\n",
        "if hasattr(model, 'get_base_model'):\n",
        "    base_model = model.get_base_model()\n",
        "    print(f\"Using get_base_model(): {type(base_model).__name__}\")\n",
        "elif hasattr(model, 'model') and hasattr(model.model, 'model'):\n",
        "    base_model = model.model.model\n",
        "    print(f\"Using model.model.model: {type(base_model).__name__}\")\n",
        "elif hasattr(model, 'base_model'):\n",
        "    if hasattr(model.base_model, 'model'):\n",
        "        base_model = model.base_model.model\n",
        "    else:\n",
        "        base_model = model.base_model\n",
        "    print(f\"Using base_model: {type(base_model).__name__}\")\n",
        "else:\n",
        "    base_model = model\n",
        "    print(f\"Using model directly: {type(base_model).__name__}\")\n",
        "\n",
        "dpo_model = base_model\n",
        "dpo_model.eval()\n",
        "\n",
        "# Step 2: Create a reliable image processing pipeline\n",
        "print(\"\\nCreating image processor:\")\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "class VisionPreprocessor:\n",
        "    def __init__(self, image_size=336):\n",
        "        self.image_size = image_size\n",
        "        self.transform = T.Compose([\n",
        "            T.Resize(image_size, interpolation=T.InterpolationMode.BICUBIC),\n",
        "            T.CenterCrop(image_size),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(\n",
        "                mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                std=[0.26862954, 0.26130258, 0.27577711]\n",
        "            ),\n",
        "        ])\n",
        "\n",
        "    def __call__(self, image):\n",
        "        \"\"\"\n",
        "        Process a single image.\n",
        "        Input:  PIL Image\n",
        "        Output: torch.Tensor, shape=(1, 3, H, W), dtype=float32\n",
        "        \"\"\"\n",
        "        if isinstance(image, str):\n",
        "            image = Image.open(image).convert(\"RGB\")\n",
        "\n",
        "        # PIL -> Tensor (3, H, W)\n",
        "        tensor = self.transform(image)\n",
        "\n",
        "        # Add batch dimension: (3, H, W) -> (1, 3, H, W)\n",
        "        tensor = tensor.unsqueeze(0)\n",
        "\n",
        "        return tensor\n",
        "\n",
        "vision_proc = VisionPreprocessor(image_size=336)\n",
        "print(\"Image processor created successfully\")\n",
        "\n",
        "# Smoke test\n",
        "IMG_DIR = f\"{PROJECT}/images\"\n",
        "test_files = [f for f in os.listdir(IMG_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "if test_files:\n",
        "    test_img_path = os.path.join(IMG_DIR, test_files[0])\n",
        "    test_img = Image.open(test_img_path).convert(\"RGB\")\n",
        "    test_tensor = vision_proc(test_img)\n",
        "    print(f\"Test passed: {test_files[0]}\")\n",
        "    print(f\"Input size: {test_img.size}\")\n",
        "    print(f\"Output shape: {test_tensor.shape}\")\n",
        "    print(f\"Output dtype: {test_tensor.dtype}\")\n",
        "else:\n",
        "    raise RuntimeError(f\"No images found in: {IMG_DIR}\")\n",
        "\n",
        "# Step 3: Define inference functions\n",
        "print(\"\\nDefining inference functions:\")\n",
        "\n",
        "def generate_with_images(model, tokenizer, image_tensor, prompt, device):\n",
        "    # Use the `images` argument\n",
        "    full_prompt = f\"<image>\\n{prompt}\"\n",
        "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
        "    image_tensor = image_tensor.to(device, dtype=model.dtype)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            images=image_tensor,\n",
        "            max_new_tokens=256,\n",
        "            do_sample=False,\n",
        "            pad_token_id=tokenizer.pad_token_id or tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def generate_with_pixel_values(model, tokenizer, image_tensor, prompt, device):\n",
        "    # Use the `pixel_values` argument\n",
        "    full_prompt = f\"<image>\\n{prompt}\"\n",
        "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
        "    image_tensor = image_tensor.to(device, dtype=model.dtype)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            pixel_values=image_tensor,\n",
        "            max_new_tokens=256,\n",
        "            do_sample=False,\n",
        "            pad_token_id=tokenizer.pad_token_id or tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def generate_with_manual_forward(model, tokenizer, image_tensor, prompt, device):\n",
        "    # Manually call forward + decode\n",
        "    full_prompt = f\"<image>\\n{prompt}\"\n",
        "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
        "    image_tensor = image_tensor.to(device, dtype=model.dtype)\n",
        "\n",
        "    # Simple greedy decoding\n",
        "    with torch.no_grad():\n",
        "        input_ids = inputs[\"input_ids\"]\n",
        "\n",
        "        for _ in range(256):\n",
        "            try:\n",
        "                outputs = model(\n",
        "                    input_ids=input_ids,\n",
        "                    images=image_tensor,\n",
        "                    use_cache=False,\n",
        "                )\n",
        "            except:\n",
        "                outputs = model(\n",
        "                    input_ids=input_ids,\n",
        "                    pixel_values=image_tensor,\n",
        "                    use_cache=False,\n",
        "                )\n",
        "\n",
        "            logits = outputs.logits\n",
        "            next_token = logits[:, -1, :].argmax(dim=-1, keepdim=True)\n",
        "\n",
        "            if next_token.item() == tokenizer.eos_token_id:\n",
        "                break\n",
        "\n",
        "            input_ids = torch.cat([input_ids, next_token], dim=1)\n",
        "\n",
        "        return tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
        "\n",
        "def predict_with_fallback(image_path, prompt=\"Describe all parking rules and info in this image.\"):\n",
        "    try:\n",
        "        # Load and process image\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        image_tensor = vision_proc(image)\n",
        "\n",
        "        # Method 1: `images` argument\n",
        "        try:\n",
        "            full_text = generate_with_images(dpo_model, tokenizer, image_tensor, prompt, dpo_model.device)\n",
        "            answer = full_text.split(prompt)[-1].strip() if prompt in full_text else full_text.strip()\n",
        "            return True, answer, \"method1_images\"\n",
        "        except Exception as e1:\n",
        "            error1 = str(e1)\n",
        "\n",
        "        # Method 2: `pixel_values` argument\n",
        "        try:\n",
        "            full_text = generate_with_pixel_values(dpo_model, tokenizer, image_tensor, prompt, dpo_model.device)\n",
        "            answer = full_text.split(prompt)[-1].strip() if prompt in full_text else full_text.strip()\n",
        "            return True, answer, \"method2_pixel_values\"\n",
        "        except Exception as e2:\n",
        "            error2 = str(e2)\n",
        "\n",
        "        # Method 3: manual forward\n",
        "        try:\n",
        "            full_text = generate_with_manual_forward(dpo_model, tokenizer, image_tensor, prompt, dpo_model.device)\n",
        "            answer = full_text.split(prompt)[-1].strip() if prompt in full_text else full_text.strip()\n",
        "            return True, answer, \"method3_manual\"\n",
        "        except Exception as e3:\n",
        "            error3 = str(e3)\n",
        "\n",
        "        # All methods failed\n",
        "        error_msg = f\"All methods failed:\\n1. {error1[:50]}\\n2. {error2[:50]}\\n3. {error3[:50]}\"\n",
        "        return False, error_msg, \"all_failed\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return False, f\"Image processing failed: {str(e)[:100]}\", \"preprocessing_failed\"\n",
        "\n",
        "# Inference smoke test\n",
        "print(\"\\nRunning inference test...\")\n",
        "test_success, test_result, test_method = predict_with_fallback(test_img_path)\n",
        "\n",
        "if test_success:\n",
        "    print(f\"Test succeeded! Method: {test_method}\")\n",
        "    print(f\"Output preview: {test_result[:100]}...\")\n",
        "else:\n",
        "    print(f\"Test failed: {test_method}\")\n",
        "    print(f\"Error: {test_result}\")\n",
        "    raise RuntimeError(\"Inference test failed!\")\n",
        "\n",
        "# Step 4: Batch prediction\n",
        "image_files = sorted([f for f in os.listdir(IMG_DIR)\n",
        "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "\n",
        "print(f\"Total images: {len(image_files)}\")\n",
        "\n",
        "success_count = 0\n",
        "method_stats = Counter()\n",
        "failed_images = []\n",
        "\n",
        "for img_file in tqdm(image_files, desc=\"DPO Prediction\"):\n",
        "    base_name = Path(img_file).stem\n",
        "    pred_path = os.path.join(DPO_PRED_DIR, f\"{base_name}.json\")\n",
        "\n",
        "    # Skip if already exists\n",
        "    if os.path.exists(pred_path):\n",
        "        success_count += 1\n",
        "        continue\n",
        "\n",
        "    # Generate prediction\n",
        "    img_path = os.path.join(IMG_DIR, img_file)\n",
        "    success, result, method = predict_with_fallback(img_path)\n",
        "\n",
        "    if success:\n",
        "        # Save prediction\n",
        "        try:\n",
        "            pred_data = json.loads(result)\n",
        "        except json.JSONDecodeError:\n",
        "            pred_data = {\"text\": result}\n",
        "\n",
        "        with open(pred_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(pred_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        success_count += 1\n",
        "        method_stats[method] += 1\n",
        "    else:\n",
        "        failed_images.append((img_file, result))\n",
        "\n",
        "print(f\"\\nPrediction finished: {success_count}/{len(image_files)}\")\n",
        "print(f\"Method stats: {dict(method_stats)}\")\n",
        "\n",
        "if failed_images:\n",
        "    print(f\"\\nFailed images ({len(failed_images)}):\")\n",
        "    for img, err in failed_images[:5]:\n",
        "        print(f\"  - {img}: {err[:80]}\")\n",
        "\n",
        "if success_count == 0:\n",
        "    print(\"All predictions failed!\")\n",
        "    print(\"\\nFinal diagnostics:\")\n",
        "    print(f\"Model type: {type(dpo_model).__name__}\")\n",
        "    print(f\"Model device: {dpo_model.device}\")\n",
        "    print(f\"Test result: {test_result[:200]}\")\n",
        "\n",
        "    # Try to inspect model signature\n",
        "    import inspect\n",
        "    if hasattr(dpo_model, 'generate'):\n",
        "        try:\n",
        "            sig = str(inspect.signature(dpo_model.generate))\n",
        "            print(f\"generate signature: {sig[:200]}\")\n",
        "        except:\n",
        "            print(\"Unable to get generate signature\")\n",
        "\n",
        "    raise RuntimeError(\"Prediction failed! Please check the model and image processing logic.\")\n",
        "\n",
        "# Step 5: Evaluation\n",
        "KEYS = [\n",
        "    \"NO STOPPING\", \"NO PARKING\", \"DISABLE\", \"DISABLED\", \"DISABLE PEOPLE ONLY\",\n",
        "    \"1P\", \"2P\", \"3P\", \"TICKET\", \"PERMIT\", \"BUS\", \"PARALLEL\", \"ANGLED\",\n",
        "    \"AM\", \"PM\", \"MON\", \"TUE\", \"WED\", \"THU\", \"FRI\", \"SAT\", \"SUN\",\n",
        "    \"LEFT\", \"RIGHT\", \"BOTH\", \"↔\", \"→\", \"←\", \"AREA\", \"ZONE\"\n",
        "]\n",
        "\n",
        "def norm_text(s):\n",
        "    s = unicodedata.normalize(\"NFKC\", s)\n",
        "    s = re.sub(r\"[\\s,;:|/]+\", \" \", s).upper()\n",
        "    s = s.replace(\"DISABLED\", \"DISABLE\")\n",
        "    s = s.replace(\"↔\", \"BOTH\").replace(\"→\", \"RIGHT\").replace(\"←\", \"LEFT\")\n",
        "    return s.replace(\"  \", \" \").strip()\n",
        "\n",
        "def load_json_any(path):\n",
        "    try:\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def flatten_gt(path):\n",
        "    obj = load_json_any(path)\n",
        "    if not obj:\n",
        "        return \"\"\n",
        "    pieces = []\n",
        "    if isinstance(obj, list):\n",
        "        for item in obj:\n",
        "            if isinstance(item, dict):\n",
        "                for k, v in item.items():\n",
        "                    if isinstance(v, str) and \"=\" in v:\n",
        "                        kk, vv = v.split(\"=\", 1)\n",
        "                        pieces += [kk, vv]\n",
        "                    else:\n",
        "                        pieces += [str(k), str(v)]\n",
        "            else:\n",
        "                pieces.append(str(item))\n",
        "    elif isinstance(obj, dict):\n",
        "        for k, v in obj.items():\n",
        "            pieces += [str(k), str(v)]\n",
        "    else:\n",
        "        pieces.append(str(obj))\n",
        "    return norm_text(\" \".join(pieces))\n",
        "\n",
        "def flatten_pred(path):\n",
        "    obj = load_json_any(path)\n",
        "    if not obj:\n",
        "        try:\n",
        "            return norm_text(open(path, \"r\", encoding=\"utf-8\").read())\n",
        "        except:\n",
        "            return \"\"\n",
        "    if isinstance(obj, dict) and \"text\" in obj:\n",
        "        return norm_text(obj[\"text\"])\n",
        "    return norm_text(json.dumps(obj, ensure_ascii=False))\n",
        "\n",
        "def extract_keys(norm_str):\n",
        "    return set(k for k in KEYS if k in norm_str)\n",
        "\n",
        "def evaluate_predictions(pred_dir, model_name):\n",
        "    print(f\"\\nEvaluating model {model_name}...\")\n",
        "\n",
        "    rows = []\n",
        "    per_key_tp = Counter()\n",
        "    per_key_fp = Counter()\n",
        "    per_key_fn = Counter()\n",
        "\n",
        "    gt_files = sorted(glob.glob(f\"{GT_DIR}/*.json\"))\n",
        "    matched = 0\n",
        "\n",
        "    for gt_path in gt_files:\n",
        "        base = Path(gt_path).stem\n",
        "\n",
        "        # Find matching prediction\n",
        "        pred_path = None\n",
        "        for cand in [f\"{base}.json\", f\"{base}.JPG.json\", f\"{base}.jpg.json\"]:\n",
        "            p = os.path.join(pred_dir, cand)\n",
        "            if os.path.exists(p):\n",
        "                pred_path = p\n",
        "                break\n",
        "\n",
        "        if not pred_path:\n",
        "            continue\n",
        "\n",
        "        matched += 1\n",
        "\n",
        "        # Extract keywords\n",
        "        gset = extract_keys(flatten_gt(gt_path))\n",
        "        pset = extract_keys(flatten_pred(pred_path))\n",
        "\n",
        "        # Metrics\n",
        "        tp = len(gset & pset)\n",
        "        fp = len(pset - gset)\n",
        "        fn = len(gset - pset)\n",
        "\n",
        "        prec = tp / (tp + fp) if (tp + fp) else 0.0\n",
        "        rec = tp / (tp + fn) if (tp + fn) else 0.0\n",
        "        f1 = 2 * prec * rec / (prec + rec) if (prec + rec) else 0.0\n",
        "\n",
        "        rows.append([base, tp, fp, fn, prec, rec, f1, gset, pset])\n",
        "\n",
        "        # Per-key counters\n",
        "        for k in (gset & pset):\n",
        "            per_key_tp[k] += 1\n",
        "        for k in (pset - gset):\n",
        "            per_key_fp[k] += 1\n",
        "        for k in (gset - pset):\n",
        "            per_key_fn[k] += 1\n",
        "\n",
        "    print(f\"Matched samples: {matched}/{len(gt_files)}\")\n",
        "\n",
        "    if matched == 0:\n",
        "        print(\"No matched samples!\")\n",
        "        return None\n",
        "\n",
        "    # Micro metrics\n",
        "    micro_tp = sum(r[1] for r in rows)\n",
        "    micro_fp = sum(r[2] for r in rows)\n",
        "    micro_fn = sum(r[3] for r in rows)\n",
        "    micro_prec = micro_tp / (micro_tp + micro_fp) if (micro_tp + micro_fp) else 0.0\n",
        "    micro_rec = micro_tp / (micro_tp + micro_fn) if (micro_tp + micro_fn) else 0.0\n",
        "    micro_f1 = 2 * micro_prec * micro_rec / (micro_prec + micro_rec) if (micro_prec + micro_rec) else 0.0\n",
        "\n",
        "    # Macro metrics\n",
        "    avg_prec = sum(r[4] for r in rows) / len(rows)\n",
        "    avg_rec = sum(r[5] for r in rows) / len(rows)\n",
        "    avg_f1 = sum(r[6] for r in rows) / len(rows)\n",
        "\n",
        "    # Per-key stats\n",
        "    key_stats = []\n",
        "    for k in sorted(set(list(per_key_tp) + list(per_key_fp) + list(per_key_fn))):\n",
        "        tp, fp, fn = per_key_tp[k], per_key_fp[k], per_key_fn[k]\n",
        "        p = tp / (tp + fp) if (tp + fp) else 0.0\n",
        "        r = tp / (tp + fn) if (tp + fn) else 0.0\n",
        "        f1_k = 2 * p * r / (p + r) if (p + r) else 0.0\n",
        "        key_stats.append([k, tp, fp, fn, p, r, f1_k])\n",
        "\n",
        "    return {\n",
        "        \"model_name\": model_name,\n",
        "        \"rows\": rows,\n",
        "        \"micro\": {\"precision\": micro_prec, \"recall\": micro_rec, \"f1\": micro_f1},\n",
        "        \"macro\": {\"precision\": avg_prec, \"recall\": avg_rec, \"f1\": avg_f1},\n",
        "        \"per_key\": key_stats,\n",
        "        \"per_key_counters\": (per_key_tp, per_key_fp, per_key_fn)\n",
        "    }\n",
        "\n",
        "# Evaluate both models\n",
        "sft_results = evaluate_predictions(SFT_PRED_DIR, \"SFT\")\n",
        "dpo_results = evaluate_predictions(DPO_PRED_DIR, \"DPO\")\n",
        "\n",
        "if not sft_results or not dpo_results:\n",
        "    raise RuntimeError(\"Evaluation failed!\")\n",
        "\n",
        "# Step 6: Print results\n",
        "def print_results(results):\n",
        "    name = results[\"model_name\"]\n",
        "    micro = results[\"micro\"]\n",
        "    macro = results[\"macro\"]\n",
        "\n",
        "    print(f\"[{name} Model]\")\n",
        "    print(f\"Samples: {len(results['rows'])}\")\n",
        "    print(f\"\\nMicro metrics:\")\n",
        "    print(f\"Precision: {micro['precision']:.3f}\")\n",
        "    print(f\"Recall:    {micro['recall']:.3f}\")\n",
        "    print(f\"F1 Score:  {micro['f1']:.3f}\")\n",
        "    print(f\"\\nMacro metrics:\")\n",
        "    print(f\"Precision: {macro['precision']:.3f}\")\n",
        "    print(f\"Recall:    {macro['recall']:.3f}\")\n",
        "    print(f\"F1 Score:  {macro['f1']:.3f}\")\n",
        "\n",
        "    print(f\"\\nPer-key stats (sorted by frequency)\")\n",
        "    for line in sorted(results['per_key'], key=lambda x: x[1]+x[2]+x[3], reverse=True)[:15]:\n",
        "        print(f\"{line[0]:>20s} | TP:{line[1]:2d} FP:{line[2]:2d} FN:{line[3]:2d} | \"\n",
        "              f\"P/R/F1={line[4]:.3f}/{line[5]:.3f}/{line[6]:.3f}\")\n",
        "\n",
        "print_results(sft_results)\n",
        "print_results(dpo_results)\n",
        "\n",
        "# Comparative analysis\n",
        "print(\"SFT vs DPO Comparative Analysis\")\n",
        "\n",
        "sft_micro = sft_results[\"micro\"]\n",
        "dpo_micro = dpo_results[\"micro\"]\n",
        "sft_macro = sft_results[\"macro\"]\n",
        "dpo_macro = dpo_results[\"macro\"]\n",
        "\n",
        "print(f\"\\n{'Metric':<20s} {'SFT':<12s} {'DPO':<12s} {'Change':<20s}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "metrics = [\n",
        "    (\"Micro Precision\", sft_micro[\"precision\"], dpo_micro[\"precision\"]),\n",
        "    (\"Micro Recall\", sft_micro[\"recall\"], dpo_micro[\"recall\"]),\n",
        "    (\"Micro F1\", sft_micro[\"f1\"], dpo_micro[\"f1\"]),\n",
        "    (\"Macro Precision\", sft_macro[\"precision\"], dpo_macro[\"precision\"]),\n",
        "    (\"Macro Recall\", sft_macro[\"recall\"], dpo_macro[\"recall\"]),\n",
        "    (\"Macro F1\", sft_macro[\"f1\"], dpo_macro[\"f1\"]),\n",
        "]\n",
        "\n",
        "for name, sft_val, dpo_val in metrics:\n",
        "    delta = dpo_val - sft_val\n",
        "    delta_pct = (delta / sft_val * 100) if sft_val > 0 else 0\n",
        "    arrow = \"↑\" if delta > 0 else \"↓\" if delta < 0 else \"=\"\n",
        "    print(f\"{name:<20s} {sft_val:>6.3f}       {dpo_val:>6.3f}       \"\n",
        "          f\"{arrow} {delta:+.3f} ({delta_pct:+.1f}%)\")\n",
        "\n",
        "# Key improvements\n",
        "print(\"\\nKey improvement analysis:\")\n",
        "\n",
        "# Hallucination control\n",
        "hallucination_keys = [\"AREA\", \"BUS\", \"ZONE\", \"PERMIT\", \"TICKET\"]\n",
        "sft_tp, sft_fp, sft_fn = sft_results[\"per_key_counters\"]\n",
        "dpo_tp, dpo_fp, dpo_fn = dpo_results[\"per_key_counters\"]\n",
        "\n",
        "print(\"\\nHallucination control (False Positives):\")\n",
        "for key in hallucination_keys:\n",
        "    sft_fp_val = sft_fp[key]\n",
        "    dpo_fp_val = dpo_fp[key]\n",
        "    if sft_fp_val > 0 or dpo_fp_val > 0:\n",
        "        reduction = sft_fp_val - dpo_fp_val\n",
        "        status = \"Yes\" if reduction > 0 else \"No\" if reduction < 0 else \"=\"\n",
        "        print(f\"  {status} {key:>10s}: {sft_fp_val:2d} → {dpo_fp_val:2d} ({reduction:+2d})\")\n",
        "\n",
        "# Missing reduction\n",
        "missing_keys = [\"RIGHT\", \"SUN\", \"SAT\", \"3P\", \"PARALLEL\"]\n",
        "print(\"\\nMissing reduction (False Negatives):\")\n",
        "for key in missing_keys:\n",
        "    sft_fn_val = sft_fn[key]\n",
        "    dpo_fn_val = dpo_fn[key]\n",
        "    if sft_fn_val > 0 or dpo_fn_val > 0:\n",
        "        reduction = sft_fn_val - dpo_fn_val\n",
        "        status = \"Yes\" if reduction > 0 else \"No\" if reduction < 0 else \"=\"\n",
        "        print(f\"  {status} {key:>10s}: {sft_fn_val:2d} → {dpo_fn_val:2d} ({reduction:+2d})\")\n",
        "\n",
        "# Overall tallies\n",
        "total_sft_fp = sum(sft_fp.values())\n",
        "total_dpo_fp = sum(dpo_fp.values())\n",
        "total_sft_fn = sum(sft_fn.values())\n",
        "total_dpo_fn = sum(dpo_fn.values())\n",
        "\n",
        "print(f\"\\nOverall error counts:\")\n",
        "fp_change = total_dpo_fp - total_sft_fp\n",
        "fn_change = total_dpo_fn - total_sft_fn\n",
        "print(f\"  False Positives: {total_sft_fp} → {total_dpo_fp} \"\n",
        "      f\"({fp_change:+d}, {fp_change/total_sft_fp*100:+.1f}%)\")\n",
        "print(f\"  False Negatives: {total_sft_fn} → {total_dpo_fn} \"\n",
        "      f\"({fn_change:+d}, {fn_change/total_sft_fn*100:+.1f}%)\")\n",
        "\n",
        "# Step 7: Export results\n",
        "for prefix, results in [(\"sft\", sft_results), (\"dpo\", dpo_results)]:\n",
        "    # By image\n",
        "    csv_image = f\"{OUT_DIR}/eval_{prefix}_by_image.csv\"\n",
        "    with open(csv_image, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow([\"id\", \"TP\", \"FP\", \"FN\", \"Precision\", \"Recall\", \"F1\", \"GT_Keys\", \"Pred_Keys\"])\n",
        "        for row in results[\"rows\"]:\n",
        "            w.writerow([\n",
        "                row[0], row[1], row[2], row[3],\n",
        "                f\"{row[4]:.4f}\", f\"{row[5]:.4f}\", f\"{row[6]:.4f}\",\n",
        "                \";\".join(sorted(row[7])), \";\".join(sorted(row[8]))\n",
        "            ])\n",
        "\n",
        "    # By key\n",
        "    csv_key = f\"{OUT_DIR}/eval_{prefix}_by_key.csv\"\n",
        "    with open(csv_key, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow([\"Key\", \"TP\", \"FP\", \"FN\", \"Precision\", \"Recall\", \"F1\"])\n",
        "        for row in results[\"per_key\"]:\n",
        "            w.writerow([\n",
        "                row[0], row[1], row[2], row[3],\n",
        "                f\"{row[4]:.3f}\", f\"{row[5]:.3f}\", f\"{row[6]:.3f}\"\n",
        "            ])\n",
        "\n",
        "# Comparison table\n",
        "csv_compare = f\"{OUT_DIR}/eval_sft_vs_dpo_comparison.csv\"\n",
        "with open(csv_compare, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    w = csv.writer(f)\n",
        "    w.writerow([\"Metric\", \"SFT\", \"DPO\", \"Delta\", \"Delta_%\"])\n",
        "    for name, sft_val, dpo_val in metrics:\n",
        "        delta = dpo_val - sft_val\n",
        "        delta_pct = (delta / sft_val * 100) if sft_val > 0 else 0\n",
        "        w.writerow([name, f\"{sft_val:.4f}\", f\"{dpo_val:.4f}\",\n",
        "                   f\"{delta:+.4f}\", f\"{delta_pct:+.2f}%\"])\n",
        "\n",
        "print(f\"\\nDetailed outputs:\")\n",
        "print(f\"SFT by-image: {OUT_DIR}/eval_sft_by_image.csv\")\n",
        "print(f\"SFT by-key:   {OUT_DIR}/eval_sft_by_key.csv\")\n",
        "print(f\"DPO by-image: {OUT_DIR}/eval_dpo_by_image.csv\")\n",
        "print(f\"DPO by-key:   {OUT_DIR}/eval_dpo_by_key.csv\")\n",
        "print(f\"Comparison:   {OUT_DIR}/eval_sft_vs_dpo_comparison.csv\")\n",
        "\n",
        "# Step 8: Summary\n",
        "improvement = dpo_micro[\"f1\"] - sft_micro[\"f1\"]\n",
        "improvement_pct = (improvement / sft_micro[\"f1\"] * 100) if sft_micro[\"f1\"] > 0 else 0\n",
        "\n",
        "if improvement > 0.05:\n",
        "    verdict = \"DPO training significantly improved model performance!\"\n",
        "elif improvement > 0:\n",
        "    verdict = \"DPO training brought a moderate improvement.\"\n",
        "elif improvement > -0.05:\n",
        "    verdict = \"DPO training had limited effect.\"\n",
        "else:\n",
        "    verdict = \"DPO training did not improve performance.\"\n",
        "\n",
        "print(f\"\"\"\n",
        "{verdict}\n",
        "\n",
        "Key metric comparison:\n",
        "  - SFT F1: {sft_micro['f1']:.3f}\n",
        "  - DPO F1: {dpo_micro['f1']:.3f}\n",
        "  - Delta:  {improvement:+.3f} ({improvement_pct:+.1f}%)\n",
        "\n",
        "Main changes:\n",
        "  - Precision: {sft_micro['precision']:.3f} → {dpo_micro['precision']:.3f}\n",
        "  - Recall:    {sft_micro['recall']:.3f} → {dpo_micro['recall']:.3f}\n",
        "  - Hallucination reduction (FP): {fp_change:+d} ({fp_change/total_sft_fp*100:+.1f}%)\n",
        "\n",
        "All results exported to: {OUT_DIR}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg4ErRyrShgb",
        "outputId": "04c91868-a742-4af9-80b8-e3b207c3b4e2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating model:\n",
            "Model: PeftModelForCausalLM\n",
            "Tokenizer: Qwen2Tokenizer\n",
            "Device: cuda:0\n",
            "\n",
            "Extracting base model...\n",
            "Using get_base_model(): LlavaQwen2ForCausalLM\n",
            "\n",
            "Creating image processor:\n",
            "Image processor created successfully\n",
            "Test passed: IMG_6460.JPG\n",
            "Input size: (2160, 2880)\n",
            "Output shape: torch.Size([1, 3, 336, 336])\n",
            "Output dtype: torch.float32\n",
            "\n",
            "Defining inference functions:\n",
            "\n",
            "Running inference test...\n",
            "Test succeeded! Method: method3_manual\n",
            "Output preview: No parking...\n",
            "Total images: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DPO Prediction: 100%|██████████| 20/20 [00:00<00:00, 103.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prediction finished: 20/20\n",
            "Method stats: {}\n",
            "\n",
            "Evaluating model SFT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched samples: 20/20\n",
            "\n",
            "Evaluating model DPO...\n",
            "Matched samples: 20/20\n",
            "[SFT Model]\n",
            "Samples: 20\n",
            "\n",
            "Micro metrics:\n",
            "Precision: 0.305\n",
            "Recall:    0.736\n",
            "F1 Score:  0.431\n",
            "\n",
            "Macro metrics:\n",
            "Precision: 0.306\n",
            "Recall:    0.752\n",
            "F1 Score:  0.407\n",
            "\n",
            "Per-key stats (sorted by frequency)\n",
            "                  2P | TP:10 FP:10 FN: 0 | P/R/F1=0.500/1.000/0.667\n",
            "                  AM | TP:11 FP: 9 FN: 0 | P/R/F1=0.550/1.000/0.710\n",
            "                AREA | TP: 0 FP:20 FN: 0 | P/R/F1=0.000/0.000/0.000\n",
            "                 BUS | TP: 0 FP:20 FN: 0 | P/R/F1=0.000/0.000/0.000\n",
            "             DISABLE | TP: 4 FP:16 FN: 0 | P/R/F1=0.200/1.000/0.333\n",
            " DISABLE PEOPLE ONLY | TP: 4 FP:16 FN: 0 | P/R/F1=0.200/1.000/0.333\n",
            "                LEFT | TP:13 FP: 6 FN: 1 | P/R/F1=0.684/0.929/0.788\n",
            "                 MON | TP: 5 FP:15 FN: 0 | P/R/F1=0.250/1.000/0.400\n",
            "              PERMIT | TP: 2 FP:18 FN: 0 | P/R/F1=0.100/1.000/0.182\n",
            "                  PM | TP:11 FP: 9 FN: 0 | P/R/F1=0.550/1.000/0.710\n",
            "              TICKET | TP: 9 FP:11 FN: 0 | P/R/F1=0.450/1.000/0.621\n",
            "                ZONE | TP: 1 FP:19 FN: 0 | P/R/F1=0.050/1.000/0.095\n",
            "                 FRI | TP: 5 FP:13 FN: 0 | P/R/F1=0.278/1.000/0.435\n",
            "               RIGHT | TP: 0 FP: 1 FN:10 | P/R/F1=0.000/0.000/0.000\n",
            "         NO STOPPING | TP: 3 FP: 0 FN: 3 | P/R/F1=1.000/0.500/0.667\n",
            "[DPO Model]\n",
            "Samples: 20\n",
            "\n",
            "Micro metrics:\n",
            "Precision: 0.250\n",
            "Recall:    0.045\n",
            "F1 Score:  0.077\n",
            "\n",
            "Macro metrics:\n",
            "Precision: 0.250\n",
            "Recall:    0.077\n",
            "F1 Score:  0.112\n",
            "\n",
            "Per-key stats (sorted by frequency)\n",
            "          NO PARKING | TP: 5 FP:15 FN: 0 | P/R/F1=0.250/1.000/0.400\n",
            "                LEFT | TP: 0 FP: 0 FN:14 | P/R/F1=0.000/0.000/0.000\n",
            "                  AM | TP: 0 FP: 0 FN:11 | P/R/F1=0.000/0.000/0.000\n",
            "                  PM | TP: 0 FP: 0 FN:11 | P/R/F1=0.000/0.000/0.000\n",
            "                  2P | TP: 0 FP: 0 FN:10 | P/R/F1=0.000/0.000/0.000\n",
            "               RIGHT | TP: 0 FP: 0 FN:10 | P/R/F1=0.000/0.000/0.000\n",
            "              TICKET | TP: 0 FP: 0 FN: 9 | P/R/F1=0.000/0.000/0.000\n",
            "         NO STOPPING | TP: 0 FP: 0 FN: 6 | P/R/F1=0.000/0.000/0.000\n",
            "                 FRI | TP: 0 FP: 0 FN: 5 | P/R/F1=0.000/0.000/0.000\n",
            "                 MON | TP: 0 FP: 0 FN: 5 | P/R/F1=0.000/0.000/0.000\n",
            "             DISABLE | TP: 0 FP: 0 FN: 4 | P/R/F1=0.000/0.000/0.000\n",
            " DISABLE PEOPLE ONLY | TP: 0 FP: 0 FN: 4 | P/R/F1=0.000/0.000/0.000\n",
            "                 SAT | TP: 0 FP: 0 FN: 4 | P/R/F1=0.000/0.000/0.000\n",
            "                 SUN | TP: 0 FP: 0 FN: 4 | P/R/F1=0.000/0.000/0.000\n",
            "                  3P | TP: 0 FP: 0 FN: 3 | P/R/F1=0.000/0.000/0.000\n",
            "SFT vs DPO Comparative Analysis\n",
            "\n",
            "Metric               SFT          DPO          Change              \n",
            "----------------------------------------------------------------------\n",
            "Micro Precision       0.305        0.250       ↓ -0.055 (-17.9%)\n",
            "Micro Recall          0.736        0.045       ↓ -0.691 (-93.8%)\n",
            "Micro F1              0.431        0.077       ↓ -0.354 (-82.1%)\n",
            "Macro Precision       0.306        0.250       ↓ -0.056 (-18.4%)\n",
            "Macro Recall          0.752        0.077       ↓ -0.675 (-89.8%)\n",
            "Macro F1              0.407        0.112       ↓ -0.296 (-72.6%)\n",
            "\n",
            "Key improvement analysis:\n",
            "\n",
            "Hallucination control (False Positives):\n",
            "  Yes       AREA: 20 →  0 (+20)\n",
            "  Yes        BUS: 20 →  0 (+20)\n",
            "  Yes       ZONE: 19 →  0 (+19)\n",
            "  Yes     PERMIT: 18 →  0 (+18)\n",
            "  Yes     TICKET: 11 →  0 (+11)\n",
            "\n",
            "Missing reduction (False Negatives):\n",
            "  =      RIGHT: 10 → 10 (+0)\n",
            "  =        SUN:  4 →  4 (+0)\n",
            "  =        SAT:  4 →  4 (+0)\n",
            "  =         3P:  3 →  3 (+0)\n",
            "  =   PARALLEL:  2 →  2 (+0)\n",
            "\n",
            "Overall error counts:\n",
            "  False Positives: 185 → 15 (-170, -91.9%)\n",
            "  False Negatives: 29 → 105 (+76, +262.1%)\n",
            "\n",
            "Detailed outputs:\n",
            "SFT by-image: /content/drive/MyDrive/FastVLM_RLHF/outputs/eval_sft_by_image.csv\n",
            "SFT by-key:   /content/drive/MyDrive/FastVLM_RLHF/outputs/eval_sft_by_key.csv\n",
            "DPO by-image: /content/drive/MyDrive/FastVLM_RLHF/outputs/eval_dpo_by_image.csv\n",
            "DPO by-key:   /content/drive/MyDrive/FastVLM_RLHF/outputs/eval_dpo_by_key.csv\n",
            "Comparison:   /content/drive/MyDrive/FastVLM_RLHF/outputs/eval_sft_vs_dpo_comparison.csv\n",
            "\n",
            "DPO training did not improve performance.\n",
            "\n",
            "Key metric comparison:\n",
            "  - SFT F1: 0.431\n",
            "  - DPO F1: 0.077\n",
            "  - Delta:  -0.354 (-82.1%)\n",
            "\n",
            "Main changes:\n",
            "  - Precision: 0.305 → 0.250\n",
            "  - Recall:    0.736 → 0.045\n",
            "  - Hallucination reduction (FP): -170 (-91.9%)\n",
            "\n",
            "All results exported to: /content/drive/MyDrive/FastVLM_RLHF/outputs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate prediction timing"
      ],
      "metadata": {
        "id": "ToyBGcKmdEC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output directory\n",
        "OUT_DIR = \"/content/drive/MyDrive/FastVLM_RLHF/preds_timed\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "total_time = 0.0\n",
        "n = len(files)\n",
        "print(f\"Total number of images: {n}\")\n",
        "\n",
        "for i, img_path in enumerate(files, 1):\n",
        "    base = Path(img_path).stem\n",
        "    print(f\"\\n[{i}/{n}] Starting prediction: {base}\")\n",
        "\n",
        "    # Timing for a single image\n",
        "    t0 = time.time()\n",
        "    pred_text = generate_prediction(img_path)\n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "    t1 = time.time()\n",
        "\n",
        "    dt = t1 - t0\n",
        "    total_time += dt\n",
        "    print(f\"Done: {base}  |  Time taken: {dt:.2f} seconds\")\n",
        "\n",
        "    # Save the result (to prevent data loss)\n",
        "    try:\n",
        "        obj = json.loads(pred_text) if isinstance(pred_text, str) else pred_text\n",
        "        if not isinstance(obj, (dict, list)):\n",
        "            obj = {\"text\": pred_text}\n",
        "    except Exception:\n",
        "        obj = {\"text\": pred_text}\n",
        "\n",
        "    out_path = os.path.join(OUT_DIR, f\"{base}.json\")\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(obj, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\nTotal inference time: {total_time:.2f} seconds\")\n",
        "print(f\"Average per image: {total_time / max(n,1):.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ow4ePiwZO_5",
        "outputId": "fb0d3e0e-0058-40b5-a9d5-38ecea911ef6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images: 20\n",
            "\n",
            "[1/20] Starting prediction: IMG_6460\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6460.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6460  |  Time taken: 0.05 seconds\n",
            "\n",
            "[2/20] Starting prediction: IMG_6462\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6462.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6462  |  Time taken: 0.04 seconds\n",
            "\n",
            "[3/20] Starting prediction: IMG_6464\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6464.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6464  |  Time taken: 0.05 seconds\n",
            "\n",
            "[4/20] Starting prediction: IMG_6468\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6468.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6468  |  Time taken: 0.05 seconds\n",
            "\n",
            "[5/20] Starting prediction: IMG_6470\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6470.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6470  |  Time taken: 0.05 seconds\n",
            "\n",
            "[6/20] Starting prediction: IMG_6472\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6472.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6472  |  Time taken: 0.07 seconds\n",
            "\n",
            "[7/20] Starting prediction: IMG_6474\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6474.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6474  |  Time taken: 0.05 seconds\n",
            "\n",
            "[8/20] Starting prediction: IMG_6476\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6476.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6476  |  Time taken: 0.06 seconds\n",
            "\n",
            "[9/20] Starting prediction: IMG_6478\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6478.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6478  |  Time taken: 0.07 seconds\n",
            "\n",
            "[10/20] Starting prediction: IMG_6480\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6480.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6480  |  Time taken: 0.07 seconds\n",
            "\n",
            "[11/20] Starting prediction: IMG_6482\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6482.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6482  |  Time taken: 0.07 seconds\n",
            "\n",
            "[12/20] Starting prediction: IMG_6484\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6484.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6484  |  Time taken: 0.07 seconds\n",
            "\n",
            "[13/20] Starting prediction: IMG_6486\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6486.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6486  |  Time taken: 0.08 seconds\n",
            "\n",
            "[14/20] Starting prediction: IMG_6488\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6488.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6488  |  Time taken: 0.15 seconds\n",
            "\n",
            "[15/20] Starting prediction: IMG_6490\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6490.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6490  |  Time taken: 0.08 seconds\n",
            "\n",
            "[16/20] Starting prediction: IMG_6492\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6492.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6492  |  Time taken: 0.06 seconds\n",
            "\n",
            "[17/20] Starting prediction: IMG_6494\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6494.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6494  |  Time taken: 0.09 seconds\n",
            "\n",
            "[18/20] Starting prediction: IMG_6496\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6496.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6496  |  Time taken: 0.12 seconds\n",
            "\n",
            "[19/20] Starting prediction: IMG_6498\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6498.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6498  |  Time taken: 0.17 seconds\n",
            "\n",
            "[20/20] Starting prediction: IMG_6500\n",
            "Failed to process /content/drive/MyDrive/FastVLM_RLHF/images/IMG_6500.JPG: 'NoneType' object is not callable\n",
            "Done: IMG_6500  |  Time taken: 0.17 seconds\n",
            "\n",
            "Total inference time: 1.61 seconds\n",
            "Average per image: 0.08 seconds\n"
          ]
        }
      ]
    }
  ]
}